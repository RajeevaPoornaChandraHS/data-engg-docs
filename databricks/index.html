
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/">
      
      
        <link rel="prev" href="../astronomer/">
      
      
        <link rel="next" href="../Spark_Databricks_Course/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Azure Databricks - Data Engineering Docs by Rajeeva</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#databricks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Data Engineering Docs by Rajeeva" class="md-header__button md-logo" aria-label="Data Engineering Docs by Rajeeva" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Data Engineering Docs by Rajeeva
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Azure Databricks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../astronomer/" class="md-tabs__link">
        
  
  
    
  
  Astronomer and Airflow

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  Azure Databricks

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../Spark_Databricks_Course/" class="md-tabs__link">
        
  
  
    
  
  Spark Databricks Course

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../Spark_YT/" class="md-tabs__link">
        
  
  
    
  
  Spark YouTube

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../Azure/" class="md-tabs__link">
        
  
  
    
  
  Microsoft Azure - DP 203

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../streaming/" class="md-tabs__link">
        
  
  
    
  
  Streaming Architecture

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Data Engineering Docs by Rajeeva" class="md-nav__button md-logo" aria-label="Data Engineering Docs by Rajeeva" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Data Engineering Docs by Rajeeva
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../astronomer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Astronomer and Airflow
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Azure Databricks
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Azure Databricks
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-access" class="md-nav__link">
    <span class="md-ellipsis">
      Quick Access
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#databricks-lakehouse-fundamentals" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Lakehouse Fundamentals
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Databricks Lakehouse Fundamentals">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-a-data-warehouse" class="md-nav__link">
    <span class="md-ellipsis">
      What is a Data Warehouse?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-lakes" class="md-nav__link">
    <span class="md-ellipsis">
      Data lakes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data lakes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-does-the-lakehouse-solve-this-problem" class="md-nav__link">
    <span class="md-ellipsis">
      How does the Lakehouse Solve this Problem?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems-with-data-lake" class="md-nav__link">
    <span class="md-ellipsis">
      Problems with Data Lake
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delta-lake" class="md-nav__link">
    <span class="md-ellipsis">
      Delta Lake
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#photon" class="md-nav__link">
    <span class="md-ellipsis">
      Photon
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-is-a-unified-governance-and-security-model-structure-important" class="md-nav__link">
    <span class="md-ellipsis">
      Why is a Unified governance and security model structure important?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-sharing-with-delta-sharing" class="md-nav__link">
    <span class="md-ellipsis">
      Data Sharing With Delta Sharing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#divided-security-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Divided Security Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Divided Security Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#control-plane" class="md-nav__link">
    <span class="md-ellipsis">
      Control Plane
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-plane" class="md-nav__link">
    <span class="md-ellipsis">
      Data Plane
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#user-access-and-identity" class="md-nav__link">
    <span class="md-ellipsis">
      User Access and Identity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instant-compute-and-serverless" class="md-nav__link">
    <span class="md-ellipsis">
      Instant Compute and Serverless
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-data-lakehouse-terminology" class="md-nav__link">
    <span class="md-ellipsis">
      Common Data Lakehouse Terminology
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Data Lakehouse Terminology">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unity-catalog-components" class="md-nav__link">
    <span class="md-ellipsis">
      Unity Catalog Components
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenges-in-data-engineering-workload" class="md-nav__link">
    <span class="md-ellipsis">
      Challenges in Data Engineering Workload
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Challenges in Data Engineering Workload">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#capabilities-of-de-in-lake-house" class="md-nav__link">
    <span class="md-ellipsis">
      Capabilities of DE in Lake House
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoloader" class="md-nav__link">
    <span class="md-ellipsis">
      Autoloader
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delta-live-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Delta Live Tables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workflows" class="md-nav__link">
    <span class="md-ellipsis">
      Workflows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-streaming-workloads" class="md-nav__link">
    <span class="md-ellipsis">
      Data Streaming Workloads
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ml-workloads" class="md-nav__link">
    <span class="md-ellipsis">
      ML Workloads
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#credential" class="md-nav__link">
    <span class="md-ellipsis">
      Credential
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#databricks-academy-data-engineer-learning-plan" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Academy : Data Engineer Learning Plan
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Databricks Academy : Data Engineer Learning Plan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#course-1-data-engineering-with-databricks" class="md-nav__link">
    <span class="md-ellipsis">
      Course 1 : Data Engineering with Databricks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Course 1 : Data Engineering with Databricks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goals" class="md-nav__link">
    <span class="md-ellipsis">
      Goals
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getting-started-with-the-workspace" class="md-nav__link">
    <span class="md-ellipsis">
      Getting Started With the Workspace
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Compute Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compute Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cluster-types" class="md-nav__link">
    <span class="md-ellipsis">
      Cluster Types
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cluster-mode" class="md-nav__link">
    <span class="md-ellipsis">
      Cluster Mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#databricks-runtime-version" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Runtime Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#access-mode" class="md-nav__link">
    <span class="md-ellipsis">
      Access Mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cluster-policies" class="md-nav__link">
    <span class="md-ellipsis">
      Cluster Policies
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#access-control-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Access Control Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-use-databricks-notebooks" class="md-nav__link">
    <span class="md-ellipsis">
      Why Use Databricks Notebooks?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#databricks-utilities" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Utilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#databricks-repos" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Repos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform-data-with-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Transform Data With Spark
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transform Data With Spark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-objects-in-the-lakehouse" class="md-nav__link">
    <span class="md-ellipsis">
      Data Objects in the Lakehouse
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#managed-vs-external-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Managed vs External Storage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#extracting-data-directly-from-files-with-spark-sql" class="md-nav__link">
    <span class="md-ellipsis">
      Extracting Data Directly from Files with Spark SQL
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-with-binary-files" class="md-nav__link">
    <span class="md-ellipsis">
      Working with Binary Files
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#providing-options-when-dealing-with-external-data-sources" class="md-nav__link">
    <span class="md-ellipsis">
      Providing Options When Dealing with External Data Sources
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limits-of-tables-with-external-data-sources" class="md-nav__link">
    <span class="md-ellipsis">
      Limits of Tables with External Data Sources
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-jdbc-to-extract-data-from-sql-databases" class="md-nav__link">
    <span class="md-ellipsis">
      Using JDBC to extract data from SQL Databases
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-does-spark-interact-with-external-databases" class="md-nav__link">
    <span class="md-ellipsis">
      How does Spark Interact with External Databases
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cleaning-data-using-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Cleaning Data using Spark
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cleaning Data using Spark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deduplicating-the-rows-based-on-specific-columns" class="md-nav__link">
    <span class="md-ellipsis">
      Deduplicating the Rows Based on Specific Columns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validating-duplicates" class="md-nav__link">
    <span class="md-ellipsis">
      Validating Duplicates
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Validating Duplicates">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#working-with-regex" class="md-nav__link">
    <span class="md-ellipsis">
      Working with RegEx
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#complex-transformations-on-json-data" class="md-nav__link">
    <span class="md-ellipsis">
      Complex Transformations on JSON data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Complex Transformations on JSON data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#working-with-nested-data" class="md-nav__link">
    <span class="md-ellipsis">
      Working With Nested Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#array-manipulation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Array Manipulation Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#complex-array-manipulation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Complex Array Manipulation Functions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sql-udf-functions" class="md-nav__link">
    <span class="md-ellipsis">
      SQL UDF Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SQL UDF Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#case-when-statements-in-sql-udf" class="md-nav__link">
    <span class="md-ellipsis">
      Case When Statements in SQL UDF
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-udfs" class="md-nav__link">
    <span class="md-ellipsis">
      Python UDFs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#user-defined-function-udf" class="md-nav__link">
    <span class="md-ellipsis">
      User-Defined Function (UDF)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="User-Defined Function (UDF)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#normal-python-udfs-vs-pandas-udfs" class="md-nav__link">
    <span class="md-ellipsis">
      Normal Python UDFs vs Pandas UDFs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#managing-data-with-delta-lake" class="md-nav__link">
    <span class="md-ellipsis">
      Managing Data with Delta Lake
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Managing Data with Delta Lake">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#problems-solved-by-acid" class="md-nav__link">
    <span class="md-ellipsis">
      Problems Solved by ACID
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#schemas-and-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Schemas and Tables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Schemas and Tables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-managed-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Managed Tables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-external-tables" class="md-nav__link">
    <span class="md-ellipsis">
      ⚠️ Creating External Tables
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-up-delta-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Setting Up Delta Tables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting Up Delta Tables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ctas-statements" class="md-nav__link">
    <span class="md-ellipsis">
      CTAS Statements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ingesting-csv-with-ctas" class="md-nav__link">
    <span class="md-ellipsis">
      Ingesting csv with CTAS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filtering-and-renaming-columns-from-existing-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Filtering and Renaming columns from existing tables
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#declare-schema-with-generated-columns" class="md-nav__link">
    <span class="md-ellipsis">
      Declare Schema with Generated Columns
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Declare Schema with Generated Columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mergin-data" class="md-nav__link">
    <span class="md-ellipsis">
      Mergin Data
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adding-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      Adding Constraints
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#additional-options-and-metadata" class="md-nav__link">
    <span class="md-ellipsis">
      Additional Options and Metadata
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cloning-delta-lake-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Cloning Delta Lake Tables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-data-into-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Loading Data Into Tables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Loading Data Into Tables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-overwrites" class="md-nav__link">
    <span class="md-ellipsis">
      Complete Overwrites
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#insert-overwrite" class="md-nav__link">
    <span class="md-ellipsis">
      Insert Overwrite
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#appending-data" class="md-nav__link">
    <span class="md-ellipsis">
      Appending Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#merging-updates" class="md-nav__link">
    <span class="md-ellipsis">
      Merging Updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#insert-only-merge-for-data-deduplication" class="md-nav__link">
    <span class="md-ellipsis">
      Insert-Only Merge For Data Deduplication ⚠️
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#incremental-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Incremental Loading
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#versioning-optimizing-and-vacuuming" class="md-nav__link">
    <span class="md-ellipsis">
      Versioning, Optimizing and Vacuuming
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimizing-and-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizing and Indexing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rollback-to-previous-version" class="md-nav__link">
    <span class="md-ellipsis">
      Rollback to Previous Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cleaning-up-stale-files-and-vacuum" class="md-nav__link">
    <span class="md-ellipsis">
      Cleaning Up Stale Files and Vacuum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-pipelines-with-delta-live-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Data Pipelines with Delta Live Tables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Pipelines with Delta Live Tables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-medallion-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      The Medallion Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Medallion Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-bronze-layer" class="md-nav__link">
    <span class="md-ellipsis">
      The Bronze Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-silver-layer" class="md-nav__link">
    <span class="md-ellipsis">
      The Silver Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-gold-layer" class="md-nav__link">
    <span class="md-ellipsis">
      The Gold Layer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-multi-hop-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      The Multi Hop Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-dlt-solves-problems" class="md-nav__link">
    <span class="md-ellipsis">
      How DLT Solves Problems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-exactly-is-a-live-table" class="md-nav__link">
    <span class="md-ellipsis">
      What exactly is a live table?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps-to-create-a-dlt-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Steps to Create a DLT Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#development-vs-production-pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      Development Vs Production pipelines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dependencies-in-the-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Dependencies in the Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-quality-with-expectations" class="md-nav__link">
    <span class="md-ellipsis">
      Data Quality with Expectations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-event-logs-are-important" class="md-nav__link">
    <span class="md-ellipsis">
      Why Event Logs are Important
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spark-structured-streaming-ingest-from-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      Spark Structured Streaming [Ingest From Cloud]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#streaming-from-an-existing-table" class="md-nav__link">
    <span class="md-ellipsis">
      Streaming from an existing table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters-in-dlt" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters in DLT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#change-data-capture" class="md-nav__link">
    <span class="md-ellipsis">
      Change Data Capture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-does-dlt-automate" class="md-nav__link">
    <span class="md-ellipsis">
      What does DLT automate?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Pipelines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fundamental-dlt-sql-syntax" class="md-nav__link">
    <span class="md-ellipsis">
      Fundamental DLT SQL Syntax
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fundamental DLT SQL Syntax">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#table-as-query-results" class="md-nav__link">
    <span class="md-ellipsis">
      Table as Query Results
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-loader" class="md-nav__link">
    <span class="md-ellipsis">
      Auto Loader
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validating-and-enriching-the-data" class="md-nav__link">
    <span class="md-ellipsis">
      Validating and Enriching the Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#live-tables-vs-streaming-live-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Live Tables vs. Streaming Live Tables ⚠️
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-the-gold-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Creating The Gold Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orders-pipeline-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Orders Pipeline in Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Orders Pipeline in Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#importing-the-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Importing the libraries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-the-bronze-table" class="md-nav__link">
    <span class="md-ellipsis">
      Creating the Bronze Table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-the-silver-table" class="md-nav__link">
    <span class="md-ellipsis">
      Creating the Silver Table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#defining-the-gold-table" class="md-nav__link">
    <span class="md-ellipsis">
      Defining the Gold Table
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#customers-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Customers Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Objectives
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Objectives">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-slowly-changing-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      What are Slowly Changing Dimensions?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#type-1-scd" class="md-nav__link">
    <span class="md-ellipsis">
      Type 1 SCD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ingest-data-with-auto-loader" class="md-nav__link">
    <span class="md-ellipsis">
      Ingest Data with Auto Loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quality-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Quality Checks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requirements-that-apply-changes-into-provides" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements that APPLY CHANGES INTO Provides
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#processing-cdc-data-from-bronze_cleaned-to-customers_silver-table" class="md-nav__link">
    <span class="md-ellipsis">
      Processing CDC Data From bronze_cleaned to customers_silver table
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#querying-tables-with-applied-changes" class="md-nav__link">
    <span class="md-ellipsis">
      Querying Tables with Applied Changes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Querying Tables with Applied Changes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-downstream-table-cant-perform-streaming-operations" class="md-nav__link">
    <span class="md-ellipsis">
      Why Downstream Table Can't Perform Streaming Operations?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#views-in-dlt" class="md-nav__link">
    <span class="md-ellipsis">
      Views in DLT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#joining-and-referencing-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Joining and Referencing Tables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Final Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-vs-sql" class="md-nav__link">
    <span class="md-ellipsis">
      Python vs SQL
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-results-and-internals-of-dlt" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Results and Internals of DLT
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pipeline Results and Internals of DLT">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#checking-list-of-all-tables" class="md-nav__link">
    <span class="md-ellipsis">
      Checking List of All Tables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#querying-orders-bronze-table" class="md-nav__link">
    <span class="md-ellipsis">
      Querying Orders Bronze Table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#querying-customers_silver-table" class="md-nav__link">
    <span class="md-ellipsis">
      Querying customers_silver table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#checking-the-__apply_changes_storage_customer_silver-table-records" class="md-nav__link">
    <span class="md-ellipsis">
      Checking the __apply_changes_storage_customer_silver table records
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-is-in-the-storage-location" class="md-nav__link">
    <span class="md-ellipsis">
      What is in the storage location?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="What is in the storage location?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#event-logs" class="md-nav__link">
    <span class="md-ellipsis">
      Event Logs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-event-logs-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Event Logs Deep Dive
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pipeline Event Logs Deep Dive">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#query-the-event-log" class="md-nav__link">
    <span class="md-ellipsis">
      Query the Event Log
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check-the-latest-update-id" class="md-nav__link">
    <span class="md-ellipsis">
      Check the Latest Update Id
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perform-audit-logging" class="md-nav__link">
    <span class="md-ellipsis">
      Perform Audit Logging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#examining-data-lineage" class="md-nav__link">
    <span class="md-ellipsis">
      Examining Data Lineage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#checking-data-quality-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Checking Data Quality Metrics ⚠️
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#databricks-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      Databricks Workflows
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Databricks Workflows">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#workflows-vs-dlt-pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      Workflows vs DLT Pipelines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#differences" class="md-nav__link">
    <span class="md-ellipsis">
      Differences
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Use Cases
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#features-of-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      Features of Workflows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-leverage-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      How to Leverage Workflows?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-workflow-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Common Workflow Patterns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Example Pipeline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workflow-job-components" class="md-nav__link">
    <span class="md-ellipsis">
      Workflow Job Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#defining-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Defining Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduling-and-alerts" class="md-nav__link">
    <span class="md-ellipsis">
      Scheduling and Alerts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#access-controls" class="md-nav__link">
    <span class="md-ellipsis">
      Access Controls
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#job-rrun-history" class="md-nav__link">
    <span class="md-ellipsis">
      Job Rrun History
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#repairing-jobs" class="md-nav__link">
    <span class="md-ellipsis">
      Repairing Jobs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#demo-of-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Demo of Workflow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Unity Catalog
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Unity Catalog">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#components-of-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Components of Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unity-catalog-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Unity Catalog Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#query-lifecycle" class="md-nav__link">
    <span class="md-ellipsis">
      Query Lifecycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute-resources-and-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Compute Resources and Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roles-and-admins-in-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Roles and Admins in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identities-in-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Identities in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#groups-in-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Groups in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-nested-groups" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple Nested Groups
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identity-federation" class="md-nav__link">
    <span class="md-ellipsis">
      Identity Federation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-access-privileges" class="md-nav__link">
    <span class="md-ellipsis">
      Data Access Privileges
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Access Privileges">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#privilege-on-various-objects" class="md-nav__link">
    <span class="md-ellipsis">
      Privilege on various objects
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-views" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Views
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#external-locations-and-storage-credentials" class="md-nav__link">
    <span class="md-ellipsis">
      External Locations and Storage Credentials
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-practices-using-unity-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices using Unity Catalog
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-segregation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Segregation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Segregation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#methods-of-data-segregation" class="md-nav__link">
    <span class="md-ellipsis">
      Methods of Data Segregation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storage-credential-vs-external-location" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Credential vs External Location
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Unity Catalog
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Unity Catalog">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#components-of-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Components of Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unity-catalog-architecture_1" class="md-nav__link">
    <span class="md-ellipsis">
      Unity Catalog Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#query-lifecycle_1" class="md-nav__link">
    <span class="md-ellipsis">
      Query Lifecycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute-resources-and-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Compute Resources and Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roles-and-admins-in-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Roles and Admins in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identities-in-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Identities in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#groups-in-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Groups in Unity Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-nested-groups_1" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple Nested Groups
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identity-federation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Identity Federation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-access-privileges_1" class="md-nav__link">
    <span class="md-ellipsis">
      Data Access Privileges
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Access Privileges">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#privilege-on-various-objects_1" class="md-nav__link">
    <span class="md-ellipsis">
      Privilege on various objects
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-views_1" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Views
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#external-locations-and-storage-credentials_1" class="md-nav__link">
    <span class="md-ellipsis">
      External Locations and Storage Credentials
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-practices-using-unity-catalog_1" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices using Unity Catalog
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-segregation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Data Segregation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Segregation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#methods-of-data-segregation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Methods of Data Segregation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storage-credential-vs-external-location_1" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Credential vs External Location
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-example" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Example
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Example">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create-a-new-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Create a New Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selecting-the-default-catalog" class="md-nav__link">
    <span class="md-ellipsis">
      Selecting the Default Catalog
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#create-a-new-schema" class="md-nav__link">
    <span class="md-ellipsis">
      Create a New Schema
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-up-tables-and-views" class="md-nav__link">
    <span class="md-ellipsis">
      Set Up Tables and Views
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-accounts_user_group" class="md-nav__link">
    <span class="md-ellipsis">
      The accounts_user_group
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grant-access-to-data-objects" class="md-nav__link">
    <span class="md-ellipsis">
      Grant Access to Data Objects
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate-a-query-and-access-the-data" class="md-nav__link">
    <span class="md-ellipsis">
      Generate a Query and access the data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#can-we-query-the-silver-table" class="md-nav__link">
    <span class="md-ellipsis">
      Can we query the silver table?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#granting-access-to-udf" class="md-nav__link">
    <span class="md-ellipsis">
      Granting Access to UDF
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Spark_Databricks_Course/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Spark Databricks Course
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Spark_YT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Spark YouTube
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Azure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Microsoft Azure - DP 203
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../streaming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Streaming Architecture
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="databricks">Databricks</h1>
<h2 id="quick-access">Quick Access</h2>
<ol>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#databricks-lakehouse-fundamentals">Databricks Lakehouse Fundamentals</a></p>
</li>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#course-1-data-engineering-with-databricks">Data Engineering with Databricks</a></p>
<ul>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#getting-started-with-the-workspace">Getting Started with Workspace</a></p>
</li>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#transform-data-with-spark">Transform Data with Spark</a></p>
</li>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#managing-data-with-delta-lake">Manage Data with Delta Lake</a></p>
</li>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/#data-pipelines-with-delta-live-tables">Building Data Pipelines wit DLT</a></p>
</li>
<li>
<p><a href="https://rajeevapoornachandrahs.github.io/data-engg-docs/databricks/?h=workflow#databricks-workflows">Workflows in Databricks</a></p>
</li>
<li>
<p><a href="">Data Access with Unity Catelog</a></p>
</li>
</ul>
</li>
<li>
<p>Brian Cafferky Training Material</p>
<ul>
<li>
<p><a href="">Dimension Modelling Concepts</a></p>
</li>
<li>
<p><a href="">Understanding Delta Event Logs</a></p>
</li>
<li>
<p><a href="">Delta Live Table Pipeline Example</a></p>
</li>
<li>
<p><a href="">Databricks Workflows Features</a></p>
</li>
</ul>
</li>
</ol>
<p>Databricks Workspace <a href="https://community.cloud.databricks.com/?o=446238005128756">link</a></p>
<h2 id="databricks-lakehouse-fundamentals">Databricks Lakehouse Fundamentals</h2>
<p><img alt="Alt text" src="../image-62.png" /></p>
<h3 id="what-is-a-data-warehouse">What is a Data Warehouse?</h3>
<ul>
<li>Data Warehouse unlike relational databases provided Business Intelligence, analytics and pre defined schema logic.</li>
<li>They were not designed for semi and unstructured data. They can't handle upticks in volume and velocity and had long processing times.</li>
</ul>
<h3 id="data-lakes">Data lakes</h3>
<ul>
<li>Data Lakes had flexible data storage capabilities, streaming support and AI ML capabilities.</li>
<li>But it introduced concerns and are not supported for transactional data. There is no data reliability and data governance is still a concern.</li>
</ul>
<p>Hence businesses required two different data platforms. </p>
<ul>
<li>The data warehouse had structured tables for BI and SQL Analytics, whereas data lakes had unstructured data for Data Science and Data Streaming.</li>
<li>They also had different governance and security models and most important there were two separate copies of data.</li>
</ul>
<h4 id="how-does-the-lakehouse-solve-this-problem">How does the Lakehouse Solve this Problem?</h4>
<ul>
<li>It can serve all ML, SQL and BI, streaming use cases.</li>
<li>One security and governance approach for all data assets on cloud.</li>
<li>An open and reliable data platform to efficiently handle all data types.</li>
</ul>
<h4 id="key-features">Key Features</h4>
<ul>
<li>Transaction Support</li>
<li>Schema Enforcement and Governance </li>
<li>BI Support </li>
<li>Data Governance</li>
<li>Decoupled Storage from Compute and Separate Clusters.</li>
<li>Support for Diverse data workload in the same data repository.</li>
</ul>
<h4 id="problems-with-data-lake">Problems with Data Lake</h4>
<ul>
<li>Lack of ACID Transaction support</li>
<li>Lack of Schema Enforcement</li>
<li>Lack of Integration with Data Catalog</li>
</ul>
<h4 id="delta-lake">Delta Lake</h4>
<ul>
<li>File based open data format that provides ACID transaction guarantees. We can handle metadata for petabytes of data.</li>
<li>Audit history and time travel capabilities.</li>
<li>Schema Enforcement ensures there is no wrong data that is in the tables and schema evolution to accommodate ever changing data.</li>
<li>Supports Change Data Capture, Slowly Changing Dimensions and  Streaming Upserts.</li>
<li>Delta Tables are based on Apache Parquet, common format for structuring data.</li>
<li>It has a transaction log and acts as a single source of truth.</li>
</ul>
<h4 id="photon">Photon</h4>
<ul>
<li>Next Gen query engine that saves costs, its compatible with Spark APIs. Loading and querying data becomes increasingly faster.</li>
<li>Each Spark Executor can have a photon engine that accelerates portion of spark and sql queries.</li>
</ul>
<h3 id="why-is-a-unified-governance-and-security-model-structure-important">Why is a Unified governance and security model structure important?</h3>
<p>The more individual access points added to the system like users, groups or external connectors, the higher the risk of data breaches.</p>
<p>Some challenges are diversity of data assets, using two incompatible platforms and fragmented tool usage.</p>
<p>Databricks overcomes these challenges by using Unity Catalog for Data Governance, delta sharing to share data across any computing platform.</p>
<p>Unlike a few years back when each workspace/team had different Access Controls, User Management and Metastores, with Unity Catalog we can have centralized access controls and user management, including row and column level access permission privileges.</p>
<p>We can control access to multiple data items at one time eg. personal info can be tagged and a single rule can be defined to provide access as needed.</p>
<p>Unity provides highly detailed audit trails that define who has accessed what data at what time and also highlights the changes made.</p>
<p>Data Lineage is provided by Unity Catalog and it includes the history of data, what datasets it came from, who created it and when + the transformations performed on it.</p>
<h3 id="data-sharing-with-delta-sharing">Data Sharing With Delta Sharing</h3>
<p>Usually the data is shared as tables and not files. So this system is not scalable.</p>
<p>We cannot share data across platforms using traditional technology.</p>
<p>Delta Sharing allows the data to be moved to any cloud platform securely.</p>
<p><strong>Advantages</strong></p>
<ul>
<li>No new ingestion processes needed to share data and integrates with PowerBI, Tableau, Spark and Pandas.</li>
<li>Data is shared live without copying it.</li>
<li>Centralized Admin and Governance.</li>
<li>The data products can be built and packaged via a central marketplace.</li>
<li>There are privacy safe clean rooms to secure data and collaboration between vendors. </li>
</ul>
<h3 id="divided-security-architecture">Divided Security Architecture</h3>
<h4 id="control-plane">Control Plane</h4>
<ul>
<li>Consists of managed backend services that Databricks provides.</li>
<li>These live in Databricks own cloud account.</li>
<li>It runs the web application and manages the notebooks, applications and clusters.</li>
</ul>
<h4 id="data-plane">Data Plane</h4>
<p>Data plane is where the data is computed. Unless we use serverless compute, the clusters run in the business owner's own cloud account.</p>
<p>The information in the control plane is encrypted at rest and in transit.</p>
<p>Databricks clusters are shortlived and do not persist after job termination.</p>
<p>If there are any security issues coming up, the service request can be generated and the Databricks employees are given access to the workspace for a certain duration of time.</p>
<h3 id="user-access-and-identity">User Access and Identity</h3>
<ul>
<li>Table ACL feature</li>
<li>IAM Instance Profiles</li>
<li>Securely Store access keys</li>
<li>The Secrets API</li>
</ul>
<h3 id="instant-compute-and-serverless">Instant Compute and Serverless</h3>
<p>In normal scenario, we run clusters on the dataplane that's connected to an external storage.</p>
<p>But some challenges with this are that:</p>
<ul>
<li>Cluster Creation is complicated.</li>
<li>Environment Setup is slow</li>
<li>Capacity and costs of the business cloud account should be managed.</li>
</ul>
<p>In Serverless Compute, Databricks allows us to run the clusters on their cloud account instead of the business.</p>
<p>The environment starts immediately and can scale in seconds.</p>
<p>These servers are unassigned to any user, always in a warm state and waiting to run jobs given by the users.</p>
<p>The three layers of isolation in the container that is hosting the runtime, virtual machine hosting the container and the virtual network for the workspace.</p>
<p>Each of the parts is isolated with no sharing or cross network traffic allowed.</p>
<p>Once the job is done, the VM is terminated and not used again for other compute tasks.</p>
<h3 id="common-data-lakehouse-terminology">Common Data Lakehouse Terminology</h3>
<h4 id="unity-catalog-components">Unity Catalog Components</h4>
<ol>
<li>Metastore: Top level logical container in Unity Catalog. It's a construct that represents the metadata. They offer improved security and other useful features like auditing.</li>
<li>Catalog : Top most container for data objects in Unity Catalog. Data Analysts use this to reference data objects in UC.</li>
</ol>
<p>There are three main namespaces to address the data location names in UC. The format is <code>SELECT * FROM catalog.schema.table</code></p>
<ol>
<li>
<p>Schema : Contains tables and views and is unchanged by UC. Forms the second part of the three level namespace. Catalogs can contain many schemas as desired.</p>
</li>
<li>
<p>Tables : SQL relations with ordered list of columns. They have metadata like comments, tags and list of columns.</p>
</li>
<li>
<p>Views : They are stored queries that are executed when we query the view. They are read only.</p>
</li>
</ol>
<p>Other components are Storage Credentials created by admins and used to authenticate with cloud storage containers.</p>
<p>Shares and recipients is related to delta sharing for low overhead sharing over different channels inside or outside organization by linking metastores in different parts of the world. </p>
<p>The metastore is essentially a logical construct with Control Plane and Cloud Storage.</p>
<p>The metadata information about the data objects and the ACLs are stored in control plane and data related to objects maintained by the metastore is stored in cloud storage.</p>
<h3 id="challenges-in-data-engineering-workload">Challenges in Data Engineering Workload</h3>
<ul>
<li>Complex Data Ingestion Methods</li>
<li>Support For data engineering principles</li>
<li>Third Party Orchestration Tools</li>
<li>Pipeline Performance Tuning</li>
<li>Inconsistencies between partners.</li>
</ul>
<p>The Databricks Lakehouse platform provides us with managed data ingestion, schema detection, enforcement and evaluation along with declarative and auto scaling data flow with a native orchestrator.</p>
<h4 id="capabilities-of-de-in-lake-house">Capabilities of DE in Lake House</h4>
<ul>
<li>easy data ingestion</li>
<li>auto etl pipelines</li>
<li>data quality checks</li>
<li>batch and stream tuning</li>
</ul>
<h4 id="autoloader">Autoloader</h4>
<p>As data loads in the lakehouse, Databricks can infer the schema after processing the data as they arrive in the cloud storage.</p>
<p>It auto detects the schema and enforces it guaranteeing data quality.</p>
<p>The <code>COPY INTO</code> command is used by data analysts to load data from a folder to the Delta Lake Table.</p>
<h3 id="delta-live-tables">Delta Live Tables</h3>
<p>ETL framework that uses a simple declarative approach to build reliable pipelines and automatically auto scales the infra so that data folks can spend less time on tooling and get value from data.</p>
<ul>
<li>We can declaratively express entire data flows in Python.</li>
<li>Natively enable software engineering best practices such as separate dev and prod environments and test before deployment in a single API.</li>
</ul>
<h3 id="workflows">Workflows</h3>
<p>Orchestration service embedded in Databricks Lakehouse platform. Allow data teams to build reliable data workflows on any cloud.</p>
<p>We can orchestrate pipelines written in DLT or dbt, ML pipelines etc.</p>
<p>We can use external tools like Apache Airflow to manage the workflows or even use the API.</p>
<p>One example of delta live tables pipeline is using Twitter Stream API to retrieve live tweets to S3, then use delta live tables to ingest, clean and transform tweets and finally do sentiment analysis.</p>
<h3 id="data-streaming-workloads">Data Streaming Workloads</h3>
<ul>
<li>
<p>Every organization generates large amounts of real time data. This data includes transaction records, third party news, weather, market data and real time feeds, web clicks, social posts, emails and instant messages.</p>
</li>
<li>
<p>Some applications of real time data are Fraud Detection, Personalized Offers, Smart Pricing, Smart Devices and Predictive maintainence.</p>
</li>
</ul>
<p>Databricks supports real time analytics, real time ML and real time applications.</p>
<p>Specific use cases include Retail, Industrial Automation, Healthcare and Financial Instituitions.</p>
<h3 id="ml-workloads">ML Workloads</h3>
<p>Problems</p>
<ul>
<li>Multiple Tools Available</li>
<li>Hard to track experiments</li>
<li>Reproducing Results is hard</li>
<li>ML Models are hard to deploy</li>
</ul>
<p>Solutions</p>
<ul>
<li>Built in ML Frameworks and model explainability</li>
<li>Support for Distributed Training</li>
<li>AutoML and Hyperparameter Tuning</li>
<li>Support for hardware accelerators</li>
</ul>
<h2 id="credential">Credential</h2>
<p><img alt="Alt text" src="../image-63.png" /></p>
<h2 id="databricks-academy-data-engineer-learning-plan">Databricks Academy : Data Engineer Learning Plan</h2>
<p><img alt="Alt text" src="../image-46.png" /></p>
<p>Link to the course : <a href="https://customer-academy.databricks.com/learn/lp/10/Data%2520Engineer%2520Learning%2520Plan">click here</a></p>
<h3 id="course-1-data-engineering-with-databricks">Course 1 : Data Engineering with Databricks</h3>
<h4 id="goals">Goals</h4>
<ul>
<li>
<p>Use the Databricks Data Science and Engineering Workspace to perform common code development tasks in a data engineering workflow.</p>
</li>
<li>
<p>Use Spark SQL/PySpark to extract data from a variety of sources, apply common cleaning transformations, and manipulate complex data with advanced functions.</p>
</li>
<li>
<p>Define and schedule data pipelines that incrementally ingest and process data through multiple tables in the lakehouse using Delta Live Tables in Spark SQL/PySpark. </p>
</li>
<li>
<p>Create and manage Databricks jobs with multiple tasks to orchestrate and monitor data workflows.
Configure permissions in Unity Catalog to ensure that users have proper access to databases for analytics and dashboarding.</p>
</li>
</ul>
<h4 id="getting-started-with-the-workspace">Getting Started With the Workspace</h4>
<p><img alt="Alt text" src="../image-47.png" /></p>
<p><strong>Architecture and Services</strong></p>
<p><img alt="Alt text" src="../image-48.png" /></p>
<ul>
<li>
<p>The data plane has the compute resources and clusters that is connected to a cloud storage. It can be single or multiple cloud storage accounts.</p>
</li>
<li>
<p>The Control Plane stores the UI, notebooks and jobs and gives the ability to manage clusters and interact with table metadata.</p>
</li>
<li>
<p>Workflow manager allows us to manage tasks and pipelines.</p>
</li>
<li>
<p>Unity Catalog mostly provides with Data Lineage, Data Quality and Data Discovery</p>
</li>
<li>
<p>There are three personas that Databricks provides : Data Science and Engineering Persona, ML Persona and SQL Analyst Persona</p>
</li>
<li>
<p>Cluster is a set of computational resources where workloads can be run as notebooks or jobs.</p>
</li>
<li>
<p>The clusters live in the data plane in the org cloud account but cluster mgmt is fn of control plane.</p>
</li>
</ul>
<p>🧭 Simple Analogy
Imagine a restaurant:</p>
<p>The control plane is the manager’s office — taking orders, scheduling, planning.</p>
<p>The data plane is the kitchen — where the food (your data) is actually cooked and served.</p>
<p>🧠 In Databricks Terms:
Term    Meaning
Control Plane   The brains of the platform — manages jobs, notebooks, users, UI, APIs
Data Plane  The muscles — where your code runs and your data is processed</p>
<p>🔧 Control Plane
Hosted by Databricks (in their cloud)</p>
<p>Handles:</p>
<p>Notebooks, jobs, clusters UI</p>
<p>User authentication &amp; access control</p>
<p>Job scheduling, monitoring, logging</p>
<p>No access to your data</p>
<p>Think of it as a remote command center</p>
<p>✅ Always outside your VPC</p>
<p>💽 Data Plane
Runs inside your cloud (VPC) — AWS, Azure, or GCP</p>
<p>Handles:</p>
<p>Spark cluster workers</p>
<p>Data access from S3/Blob/GCS</p>
<p>UDFs, jobs, pipelines</p>
<p>✅ This is where your actual data lives and is processed</p>
<p>🛡️ Security Separation
Databricks control plane never sees your actual data.</p>
<p>You can even encrypt traffic between planes or use PrivateLink to limit internet exposure.</p>
<p>🧪 Example:
You submit a notebook in Databricks:</p>
<p>Request hits the control plane (UI/API layer)</p>
<p>The control plane tells the data plane to spin up a cluster</p>
<p>Your code runs on executors in the data plane, accessing your data securely</p>
<h4 id="compute-resources">Compute Resources</h4>
<h5 id="overview">Overview</h5>
<p><img alt="Alt text" src="../image-49.png" /></p>
<h5 id="cluster-types">Cluster Types</h5>
<p><img alt="Alt text" src="../image-50.png" /></p>
<ul>
<li>Job Clusters cannot be restarted if terminated.</li>
<li>All purpose clusters can be started whenever we want it to.</li>
</ul>
<h5 id="cluster-mode">Cluster Mode</h5>
<p><img alt="Alt text" src="../image-51.png" /></p>
<h5 id="databricks-runtime-version">Databricks Runtime Version</h5>
<p><img alt="Alt text" src="../image-52.png" /></p>
<h5 id="access-mode">Access Mode</h5>
<p>Specifies overall security model of the cluster.
<img alt="Alt text" src="../image-53.png" /></p>
<ul>
<li>DBFS mounts are supported by single user clusters.</li>
</ul>
<h5 id="cluster-policies">Cluster Policies</h5>
<p><img alt="Alt text" src="../image-54.png" /></p>
<h5 id="access-control-matrix">Access Control Matrix</h5>
<p><img alt="Alt text" src="../image-55.png" /></p>
<ul>
<li>On shared security mode multiple users can be granted access.</li>
<li>On single user security mode, each user will have their own cluster.</li>
</ul>
<h5 id="why-use-databricks-notebooks">Why Use Databricks Notebooks?</h5>
<p><img alt="Alt text" src="../image-56.png" /></p>
<p><img alt="Alt text" src="../image-57.png" /></p>
<h5 id="databricks-utilities">Databricks Utilities</h5>
<p><img alt="Alt text" src="../image-58.png" /></p>
<h5 id="databricks-repos">Databricks Repos</h5>
<p><img alt="Alt text" src="../image-59.png" /></p>
<p>Some supported operations include:</p>
<ul>
<li>Cloning a repository, pulling and upstream changes.</li>
<li>Adding new items, creating new files, committing and pushing.</li>
<li>Creating a new branch.</li>
<li>Any changes that are made in a Databricks Repo can be tracked in a Git Repo</li>
</ul>
<p>We cannot DELETE branches from repos in databricks. It has to be done using Github/Azure Devops.</p>
<p>Many operations of the control plane can be versioned using Repos feature like keeping track of versions of notebooks and also to test clusters.</p>
<h4 id="transform-data-with-spark">Transform Data With Spark</h4>
<h5 id="data-objects-in-the-lakehouse">Data Objects in the Lakehouse</h5>
<p><img alt="Alt text" src="../image-60.png" /></p>
<ul>
<li>Catalog - Grouping of Databases</li>
<li>Schema - Grouping of Objects in catalog</li>
<li>Every schema has a table that is managed or external</li>
</ul>
<h5 id="managed-vs-external-storage">Managed vs External Storage</h5>
<p><img alt="Alt text" src="../image-61.png" /></p>
<ul>
<li>
<p>Managed Tables are made up of files that are stored in a managed store location configured to the metastore. Dropping the table deletes all the files also.</p>
</li>
<li>
<p>In case of external tables, the data is stored in a cloud storage location. When we drop an external table, this underlying data is retained.</p>
</li>
<li>
<p>View is a saved query against one or more databass. Can be temporary or global. Temp Views are scoped only to the current spark session</p>
</li>
<li>
<p>CTE's only alias the results of the query while that query is being planned or executed.</p>
</li>
</ul>
<h4 id="extracting-data-directly-from-files-with-spark-sql">Extracting Data Directly from Files with Spark SQL</h4>
<p><img alt="Alt text" src="../image-64.png" /></p>
<p><strong>Details in the JSON Clickstream File</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">/</span><span class="mi">001</span><span class="p">.</span><span class="n">json</span><span class="o">`</span>
</code></pre></div>
<img alt="Alt text" src="../image-65.png" /></p>
<p><strong>Querying a Directory of Files</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">`</span>
</code></pre></div>
<img alt="Alt text" src="../image-66.png" /></p>
<p><strong>Create a View for the Files</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">event_view</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">`</span>
</code></pre></div>
<p><strong>Create Temporary References</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">events_temp_view</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">`</span>
</code></pre></div>
<p><strong>Common table expressions</strong></p>
<p>These only exist while running the cell. CTEs only alias the results of the query while the cell is being planned and executed.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="k">WITH</span><span class="w"> </span><span class="n">cte_json</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="k">AS</span><span class="w"> </span><span class="p">(</span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">`</span><span class="p">)</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">cte_json</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">cte_json</span>
</code></pre></div>
<p>The Temp Viws are scoped only to the current spark session. </p>
<h4 id="working-with-binary-files">Working with Binary Files</h4>
<p>Extract the Raw Bytes and Metadata of a File</p>
<p>Some workflows may require working with entire files, such as when dealing with images or unstructured data. Using <strong><code>binaryFile</code></strong> to query a directory will provide file metadata alongside the binary representation of the file contents.</p>
<p>Specifically, the fields created will indicate the <strong><code>path</code></strong>, <strong><code>modificationTime</code></strong>, <strong><code>length</code></strong>, and <strong><code>content</code></strong>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">binaryFile</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">kafka_events</span><span class="err">}</span><span class="o">`</span>
</code></pre></div>
<h4 id="providing-options-when-dealing-with-external-data-sources">Providing Options When Dealing with External Data Sources</h4>
<p><strong>Directly Querying the csv file</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">csv</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">sales_csv</span><span class="err">}</span><span class="o">`</span>
</code></pre></div>
<p>The data is not formatted properly.
<img alt="Alt text" src="../image-67.png" /></p>
<p><strong>Registering Tables on External Data with Read Options</strong></p>
<p>While Spark will extract some self-describing data sources efficiently using default settings, many formats will require declaration of schema or other options.</p>
<p>While there are many <a href="https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-syntax-ddl-create-table-using.html" target="_blank">additional configurations</a> you can set while creating tables against external sources, the syntax below demonstrates the essentials required to extract data from most formats.</p>
<p><strong><code>
CREATE TABLE table_identifier (col_name1 col_type1, ...)<br/>
USING data_source<br/>
OPTIONS (key1 = val1, key2 = val2, ...)<br/>
LOCATION = path<br/>
</code></strong></p>
<p><strong>Creating a table using SQL DDL and Providing Options</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="n">sales_csv</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">    </span><span class="p">(</span><span class="n">order_id</span><span class="w"> </span><span class="n">LONG</span><span class="p">,</span><span class="n">email</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="k">timestamp</span><span class="w"> </span><span class="n">LONG</span><span class="p">,</span><span class="n">total_item_quantity</span><span class="w"> </span><span class="nb">INTEGER</span><span class="p">,</span><span class="n">items</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="k">USING</span><span class="w"> </span><span class="n">CSV</span>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="k">OPTIONS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">    </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;true&#39;</span>
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">    </span><span class="k">delimiter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;|&quot;</span>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="p">)</span>
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a><span class="k">LOCATION</span><span class="w"> </span><span class="ss">&quot;${paths.dba_sales.csv}&quot;</span>
</code></pre></div>
<p>No data will be moved while creating out tables. the data is just called from the files.</p>
<p><strong>NOTE</strong>: When working with CSVs as a data source, it's important to ensure that column order does not change if additional data files will be added to the source directory. Because the data format does not have strong schema enforcement, Spark will load columns and apply column names and data types in the order specified during table declaration.</p>
<p><strong>Checking the Description of the Table</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">EXTENDED</span><span class="w"> </span><span class="n">sales_csv</span>
</code></pre></div>
<p><strong>IMP!!!</strong> : The table that is created using the external source will be in CSV format and not delta.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1318a3f5-8c8c-4493-881b-19bb55e31c01" /></p>
<h4 id="limits-of-tables-with-external-data-sources">Limits of Tables with External Data Sources</h4>
<ul>
<li>
<p>When we are using external data sources other than Delta Lake and Data Lakehouse we can't expect the performance to be good always.</p>
</li>
<li>
<p>Delta Lake will always guarantee that we get the most recent data from the storage.</p>
</li>
</ul>
<p><strong>Example</strong></p>
<p>Here is an example where external file data is being updated in out sales_csv table.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="o">%</span><span class="n">python</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span> <span class="s2">&quot;|&quot;</span><span class="p">)</span>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>      <span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">sales_csv</span><span class="p">)</span>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>      <span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span>
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>      <span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">sales_csv</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">))</span>
</code></pre></div>
<p>The count method on this will not reflect the newly added rows in the dataset.</p>
<p>At the time we previously queried this data source, Spark automatically cached the underlying data in local storage. This ensures that on subsequent queries, Spark will provide the optimal performance by just querying this local cache.</p>
<p>Our external data source is not configured to tell Spark that it should refresh this data. </p>
<p>We <strong>can</strong> manually refresh the cache of our data by running the <strong><code>REFRESH TABLE</code></strong> command.</p>
<p>Note that refreshing the table will invalidate out cache so it needs to be rescanned again. </p>
<h4 id="using-jdbc-to-extract-data-from-sql-databases">Using JDBC to extract data from SQL Databases</h4>
<p>SQL databases are an extremely common data source, and Databricks has a standard JDBC driver for connecting with many flavors of SQL.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">DROP</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="n">users_jdbc</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">users_jdbc</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="k">USING</span><span class="w"> </span><span class="n">jdbc</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="k">OPTIONS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="w">    </span><span class="n">url</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;jdbc:sqllite:paths.ecommerce_db&quot;</span><span class="p">,</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="w">    </span><span class="n">dtable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;users&#39;</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a><span class="p">)</span>
</code></pre></div>
<p><strong>Checking if there are any files in the JDBC</strong></p>
<p>Table Description
<img alt="Alt text" src="../image-68.png" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="o">%</span><span class="n">python</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="n">import</span><span class="w"> </span><span class="n">python</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">functions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">F</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="k">location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="k">sql</span><span class="p">(</span><span class="ss">&quot;DESCRIBE EXTENDED users_jdbc&quot;</span><span class="p">).</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="ss">&quot;col_name&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="ss">&quot;Location&quot;</span><span class="p">).</span><span class="k">first</span><span class="p">[</span><span class="ss">&quot;data_type&quot;</span><span class="p">]</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="n">print</span><span class="p">(</span><span class="k">location</span><span class="p">)</span>
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="n">files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">db</span><span class="p">.</span><span class="n">fs</span><span class="p">.</span><span class="n">ls</span><span class="p">(</span><span class="k">location</span><span class="p">)</span>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="n">print</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;Found {len(files)} files&quot;</span>
</code></pre></div>
<h4 id="how-does-spark-interact-with-external-databases">How does Spark Interact with External Databases</h4>
<ul>
<li>
<p>Move the entire database to Databricks and then execute logic on the currently active cluster.</p>
</li>
<li>
<p>Pushing the query to an external database and only transfer results back to Databricks.</p>
</li>
<li>
<p>There will be network transfer latency while moving data back and forth between databricks and DWH.</p>
</li>
<li>Queries will not run well on big tables. </li>
</ul>
<h3 id="cleaning-data-using-spark">Cleaning Data using Spark</h3>
<p>Data
<img alt="Alt text" src="../image-69.png" /></p>
<p><strong>Check the table counts</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">),</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="n">user_id</span><span class="p">),</span><span class="k">count</span><span class="p">(</span><span class="n">user_first_timestamp</span><span class="p">)</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
</code></pre></div>
<img alt="Alt text" src="../image-70.png" /></p>
<p>We can observe that some data is missing.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span><span class="w"> </span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">email</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NULL</span>
</code></pre></div>
848 records are missing.</p>
<p>Using Python the same might be done </p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">col</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="n">usersDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;users_dirty&quot;</span><span class="p">)</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="n">usersDF</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</code></pre></div>
<h4 id="deduplicating-the-rows-based-on-specific-columns">Deduplicating the Rows Based on Specific Columns</h4>
<p>The code below uses <strong><code>GROUP BY</code></strong> to remove duplicate records based on <strong><code>user_id</code></strong> and <strong><code>user_first_touch_timestamp</code></strong> column values. (Recall that these fields are both generated when a given user is first encountered, thus forming unique tuples.)</p>
<p>Here, we are using the aggregate function <strong><code>max</code></strong> as a hack to:</p>
<ul>
<li>
<p>Keep values from the <strong><code>email</code></strong> and <strong><code>updated</code></strong> columns in the result of our group by</p>
</li>
<li>
<p>Capture non-null emails when multiple records are present</p>
</li>
</ul>
<p><strong>Steps to Deduplicate</strong></p>
<ol>
<li>Fetch All the Records [986 records]</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">deduped_users</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">user_first_touch_timestamp</span><span class="p">,</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="n">email</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="n">updated</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">updated</span>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
</code></pre></div>
<ol>
<li>Filter records where user_id is not null [983 records]</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">deduped_users</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span>
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">user_first_touch_timestamp</span><span class="p">,</span><span class="w"> </span><span class="n">email</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">updated</span>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">user_id</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="p">;</span>
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">deduped_users</span>
</code></pre></div>
<ol>
<li>Group by <code>user_id</code> and <code>user_first_timestamp</code></li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">deduped_users</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">user_first_touch_timestamp</span><span class="p">,</span><span class="w"> </span><span class="k">first</span><span class="p">(</span><span class="n">email</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="k">first</span><span class="p">(</span><span class="n">updated</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">updated</span>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">user_id</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span>
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">user_first_touch_timestamp</span><span class="p">;</span>
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">deduped_users</span>
</code></pre></div>
<p>We can use max also since we dont care which value is grouped by for email and updated</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">deduplicated</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="n">user_timestamp</span><span class="p">,</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="n">email</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="n">updated</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">updated</span>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">user_id</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span>
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="n">user_first_touch_timestamp</span><span class="p">;</span>
</code></pre></div>
<p>In either case we get 917 records.</p>
<p><strong>Check for distinct <code>user_id</code> and <code>user_first_touch_timestamp</code> rows</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">user_first_touch_timestamp</span><span class="p">))</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">users_dirty</span>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">user_id</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span>
</code></pre></div>
We get 917 rows.</p>
<h3 id="validating-duplicates">Validating Duplicates</h3>
<p>Based on our manual review above, we've visually confirmed that our counts are as expected.</p>
<p>We can also programmatically perform validation using simple filters and <strong><code>WHERE</code></strong> clauses.</p>
<p>Validate that the <strong><code>user_id</code></strong> for each row is unique.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="k">row_count</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">no_of_duplicate_ids</span><span class="w"> </span><span class="k">FROM</span><span class="p">(</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">row_count</span>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="w">    </span><span class="k">FROM</span><span class="w"> </span><span class="n">deduped_users</span>
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="w">    </span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="p">)</span>
</code></pre></div>
- true -&gt; if no duplicate ids
- false -&gt; if dup ids are there</p>
<p><strong>Checking if each user has at most one email id</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">max</span><span class="p">(</span><span class="k">row_count</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">no_of_duplicate_email</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="n">email</span><span class="p">,</span><span class="k">COUNT</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">user_id_count</span>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="w">    </span><span class="k">FROM</span><span class="w"> </span><span class="n">deduped_users</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a><span class="w">    </span><span class="k">WHERE</span><span class="w"> </span><span class="n">email</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="w">    </span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">email</span>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="p">)</span>
</code></pre></div>
<p>In Python the same thing is done via:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="n">display</span><span class="p">(</span><span class="n">dedupedDF</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>    <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">isNotNull</span><span class="p">())</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span>
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;user_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;user_id_count&quot;</span><span class="p">))</span>
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>    <span class="o">.</span><span class="n">select</span><span class="p">((</span><span class="nb">max</span><span class="p">(</span><span class="s2">&quot;user_id_count&quot;</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;at_most_one_id&quot;</span><span class="p">)))</span>
</code></pre></div>
<h4 id="working-with-regex">Working with RegEx</h4>
<ul>
<li>Correctly scale and cast the <code>user_first_touch_timestamp</code></li>
<li>Extract the calendar date and time in a human readable format</li>
<li>Use <code>regexp_extract</code> to fetch the email domains. <a href="https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.regexp_extract.html">Docs</a></li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="w">    </span><span class="n">date_format</span><span class="p">(</span><span class="n">first_touch</span><span class="p">,</span><span class="ss">&quot;MM DD,YYYY&quot;</span><span class="p">,</span><span class="n">first_touch_date</span><span class="p">),</span>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="w">    </span><span class="n">date_format</span><span class="p">(</span><span class="n">first_touch</span><span class="p">,</span><span class="ss">&quot;HH:mm:ss&quot;</span><span class="p">,</span><span class="n">first_touch_time</span><span class="p">),</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="w">    </span><span class="n">regexp_extract</span><span class="p">(</span><span class="n">email</span><span class="p">,</span><span class="ss">&quot;?&lt;=@.+&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">email_domain</span>
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="k">FROM</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="w">        </span><span class="k">CAST</span><span class="p">(</span><span class="n">user_first_touch_timestamp</span><span class="o">/</span><span class="mi">1</span><span class="n">e6</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">time_stamp</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">first_touch</span>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="w">    </span><span class="k">FROM</span><span class="w"> </span><span class="n">deduped_users</span>
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="p">)</span>
</code></pre></div>
<p><a href="https://stackoverflow.com/questions/65124408/pyspark-convert-bigint-to-timestamp-with-microseconds#:~:text=Divide%20your%20timestamp%20by%201e6,units%20of%20second%2C%20not%20microsecond.">Why divide by 1e6 to convert timestamp to a date?</a></p>
<p>In Python</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">date_format</span><span class="p">,</span> <span class="n">regexp_extract</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="n">display</span><span class="p">(</span><span class="n">dedupedDF</span>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;first_touch&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;user_first_touch_timestamp&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;timestamp&quot;</span><span class="p">))</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;first_touch_date&quot;</span><span class="p">,</span> <span class="n">date_format</span><span class="p">(</span><span class="s2">&quot;first_touch&quot;</span><span class="p">,</span> <span class="s2">&quot;MMM d, yyyy&quot;</span><span class="p">))</span>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;first_touch_time&quot;</span><span class="p">,</span> <span class="n">date_format</span><span class="p">(</span><span class="s2">&quot;first_touch&quot;</span><span class="p">,</span> <span class="s2">&quot;HH:mm:ss&quot;</span><span class="p">))</span>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;email_domain&quot;</span><span class="p">,</span> <span class="n">regexp_extract</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">,</span> <span class="s2">&quot;(?&lt;=@).+&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="p">)</span>
</code></pre></div>
<h3 id="complex-transformations-on-json-data">Complex Transformations on JSON data</h3>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">col</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="n">events_trigger_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>    <span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;events_raw&quot;</span><span class="p">),</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">),</span>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">))</span>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a><span class="p">)</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a><span class="n">display</span><span class="p">(</span><span class="n">events_trigger_df</span><span class="p">)</span>
</code></pre></div>
<img alt="Alt text" src="../image-72.png" />
The value column in the events data is nested.</p>
<h4 id="working-with-nested-data">Working With Nested Data</h4>
<p><strong>Table</strong>
<img alt="Alt text" src="../image-73.png" /></p>
<p>The code cell below queries the converted strings to view an example JSON object without null fields (we'll need this for the next section).</p>
<p><strong>NOTE:</strong> Spark SQL has built-in functionality to directly interact with nested data stored as JSON strings or struct types.
- Use <strong><code>:</code></strong> syntax in queries to access subfields in JSON strings
- Use <strong><code>.</code></strong> syntax in queries to access subfields in struct types</p>
<p><strong>Task: Check where the event name is finalized</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">events_strings</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="n">value</span><span class="p">:</span><span class="n">event_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;finalize&quot;</span><span class="w"> </span><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="k">key</span><span class="w"> </span><span class="k">LIMIT</span><span class="w"> </span><span class="mi">1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="n">display</span><span class="p">(</span><span class="n">events_string_df</span>
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>    <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&quot;value:event_name = &#39;finalize&#39;&quot;</span><span class="p">)</span>
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>    <span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>    <span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="p">)</span>
</code></pre></div>
<p><strong>Extracting the schema of the JSON</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">schema_of_json</span><span class="p">(</span><span class="s1">&#39;{&quot;device&quot;:&quot;Linux&quot;,&quot;ecommerce&quot;:{&quot;purchase_revenue_in_usd&quot;:1075.5,&quot;total_item_quantity&quot;:1,&quot;unique_items&quot;:1},&quot;event_name&quot;:&quot;finalize&quot;,&quot;event_previous_timestamp&quot;:1593879231210816,&quot;event_timestamp&quot;:1593879335779563,&quot;geo&quot;:{&quot;city&quot;:&quot;Houston&quot;,&quot;state&quot;:&quot;TX&quot;},&quot;items&quot;:[{&quot;coupon&quot;:&quot;NEWBED10&quot;,&quot;item_id&quot;:&quot;M_STAN_K&quot;,&quot;item_name&quot;:&quot;Standard King Mattress&quot;,&quot;item_revenue_in_usd&quot;:1075.5,&quot;price_in_usd&quot;:1195.0,&quot;quantity&quot;:1}],&quot;traffic_source&quot;:&quot;email&quot;,&quot;user_first_touch_timestamp&quot;:1593454417513109,&quot;user_id&quot;:&quot;UA000000106116176&quot;}&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">schema</span>
</code></pre></div>
<img alt="Alt text" src="../image-74.png" /></p>
<p><strong>Task: Convert the JSON data to table/view</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">parsed_events</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span>
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="p">(</span>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="n">from_json</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;&lt;the schemaabove&gt;&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">json</span>
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="w">    </span><span class="k">FROM</span><span class="w"> </span><span class="n">event_strings</span>
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="p">)</span><span class="w"> </span>
</code></pre></div>
Check 3:19 in <img alt="Complex Transformations" src="https://customer-academy.databricks.com/learn/course/1266/play/7856/complex-transformations;lp=10" /> for the result...</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">parsed_events</span><span class="p">;</span>
</code></pre></div>
<p>Some more code examples for <code>from_json</code></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="c1">#Convert JSON string column to Map type</span>
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">MapType</span><span class="p">,</span><span class="n">StringType</span>
<a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">from_json</span>
<a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="n">df2</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span><span class="n">from_json</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">value</span><span class="p">,</span><span class="n">MapType</span><span class="p">(</span><span class="n">StringType</span><span class="p">(),</span><span class="n">StringType</span><span class="p">())))</span>
<a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a><span class="n">df2</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a><span class="n">df2</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
Docs for <a href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.types.MapType.html">Map Type</a></p>
<p>Docs for <a href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.from_json.html">from_json</a></p>
<h4 id="array-manipulation-functions">Array Manipulation Functions</h4>
<ul>
<li>
<p><strong><code>explode()</code></strong> separates the elements of an array into multiple rows; this creates a new row for each element.</p>
</li>
<li>
<p><strong><code>size()</code></strong> provides a count for the number of elements in an array for each row.</p>
</li>
</ul>
<p>The code below explodes the <strong><code>items</code></strong> field (an array of structs) into multiple rows and shows events containing arrays with 3 or more items.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">exploded_events</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">explode</span><span class="p">(</span><span class="n">items</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">item</span>
<a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">parsed_events</span>
</code></pre></div>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="k">SIZE</span><span class="p">(</span><span class="n">items</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">2</span>
</code></pre></div>
Each element of the items column which is in json format is now in a separate row.
<img alt="Alt text" src="../image-75.png" /></p>
<p>In Python,</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">explode</span><span class="p">,</span> <span class="n">size</span>
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="n">exploded_eventsDF</span> <span class="o">=</span> <span class="p">(</span><span class="n">parsed_eventsDF</span>
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;item&quot;</span><span class="p">,</span> <span class="n">explode</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">))</span>
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a><span class="p">)</span>
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a><span class="n">display</span><span class="p">(</span><span class="n">exploded_eventsDF</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">))</span>
</code></pre></div>
<h4 id="complex-array-manipulation-functions">Complex Array Manipulation Functions</h4>
<p><code>collect_set</code> collects unique values for a field including those within arrays also.</p>
<p><code>flatten()</code> combines various values from multiple arrays in a single array.</p>
<p><code>array_distinct()</code> removes duplicate values from the array.</p>
<p><strong>Task: Pull out cart history details from the events table</strong></p>
<p>Step 1 : Collect all event names from the table for each user id</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">collect_set</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">event_history</span>
<a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span>
<a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
</code></pre></div>
<img alt="Alt text" src="../image-76.png" /></p>
<p>Step 2 : Explode event_hiistory</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">explode</span><span class="p">(</span><span class="n">collect_set</span><span class="p">(</span><span class="n">event_name</span><span class="p">))</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">event_history</span>
<a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span>
<a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
</code></pre></div>
<img alt="Alt text" src="../image-77.png" /></p>
<p>Step 3 : Collect all item ids by fetching them from the items json column</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span>
<a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a><span class="w">  </span><span class="n">collect_set</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">event_history</span><span class="p">,</span>
<a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a><span class="w">  </span><span class="n">collect_set</span><span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">item_id</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">cart_history</span>
<a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span>
<a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
</code></pre></div>
<img alt="Alt text" src="../image-78.png" /></p>
<p>Step 4 : Flatten the above cart_history results</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span>
<a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a><span class="w">  </span><span class="n">collect_set</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">event_history</span><span class="p">,</span>
<a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a><span class="w">  </span><span class="n">flatten</span><span class="p">(</span><span class="n">collect_set</span><span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">item_id</span><span class="p">))</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">cart_history</span>
<a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span>
<a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
</code></pre></div>
<img alt="Alt text" src="../image-79.png" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span>
<a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a><span class="w">       </span><span class="n">collect_set</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">event_history</span><span class="p">,</span>
<a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a><span class="w">       </span><span class="n">array_distince</span><span class="p">(</span><span class="n">flatten</span><span class="p">(</span><span class="n">collect_set</span><span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">item_id</span><span class="p">)))</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">cart_history</span>
<a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a><span class="k">FROM</span><span class="w"> </span><span class="n">exploded_events</span>
<a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">user_id</span>
</code></pre></div>
<h3 id="sql-udf-functions">SQL UDF Functions</h3>
<p>User Defined Functions (UDFs) in Spark SQL allow you to register custom SQL logic as functions in a database, making these methods reusable anywhere SQL can be run on Databricks. These functions are registered natively in SQL and maintain all of the optimizations of Spark when applying custom logic to large datasets.</p>
<p>At minimum, creating a SQL UDF requires a function name, optional parameters, the type to be returned, and some custom logic.</p>
<p>Below, a simple function named <strong><code>sale_announcement</code></strong> takes an <strong><code>item_name</code></strong> and <strong><code>item_price</code></strong> as parameters. It returns a string that announces a sale for an item at 80% of its original price.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">sales_announcement</span><span class="p">(</span><span class="n">item_name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="n">item_price</span><span class="w"> </span><span class="nb">INT</span><span class="p">)</span>
<a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a><span class="k">RETURN</span><span class="w"> </span><span class="n">STRING</span>
<a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a><span class="k">RETURN</span><span class="w"> </span><span class="n">concat</span><span class="p">(</span><span class="ss">&quot;The &quot;</span><span class="p">,</span><span class="n">item_name</span><span class="p">,</span><span class="ss">&quot;is on sale for $&quot;</span><span class="p">,</span><span class="n">round</span><span class="p">(</span><span class="n">item_price</span><span class="o">*</span><span class="mi">0</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div>
<p>This function is applied to all the columns at once.</p>
<p>Here is a Jupyter <a href="https://www.databricks.com/wp-content/uploads/notebooks/sql-user-defined-functions.html">notebook</a> with all the common SQL UDF Functions.</p>
<ul>
<li>Persist between execution environments (which can include notebooks, DBSQL queries, and jobs).</li>
<li>Exist as objects in the metastore and are governed by the same Table ACLs as databases, tables, or views.</li>
<li>To <strong>create</strong> a SQL UDF, you need <strong><code>USE CATALOG</code></strong> on the catalog, and <strong><code>USE SCHEMA</code></strong> and <strong><code>CREATE FUNCTION</code></strong> on the schema.</li>
<li>To <strong>use</strong> a SQL UDF, you need <strong><code>USE CATALOG</code></strong> on the catalog, <strong><code>USE SCHEMA</code></strong> on the schema, and <strong><code>EXECUTE</code></strong> on the function.</li>
</ul>
<p>We can use <strong><code>DESCRIBE FUNCTION</code></strong> to see where a function was registered and basic information about expected inputs and what is returned (and even more information with <strong><code>DESCRIBE FUNCTION EXTENDED</code></strong>).</p>
<h4 id="case-when-statements-in-sql-udf">Case When Statements in SQL UDF</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">item_preference</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="n">price</span><span class="w"> </span><span class="nb">INT</span><span class="p">)</span>
<a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a><span class="k">RETURNS</span><span class="w"> </span><span class="n">STRING</span>
<a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a><span class="k">RETURN</span><span class="w"> </span><span class="k">CASE</span><span class="w"> </span>
<a id="__codelineno-42-4" name="__codelineno-42-4" href="#__codelineno-42-4"></a><span class="w">  </span><span class="k">WHEN</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;Standard Queen Mattress&quot;</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="ss">&quot;This is my default mattress&quot;</span>
<a id="__codelineno-42-5" name="__codelineno-42-5" href="#__codelineno-42-5"></a><span class="w">  </span><span class="k">WHEN</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;Premium Queen Mattress&quot;</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="ss">&quot;This is my favorite mattress&quot;</span>
<a id="__codelineno-42-6" name="__codelineno-42-6" href="#__codelineno-42-6"></a><span class="w">  </span><span class="k">WHEN</span><span class="w"> </span><span class="n">price</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="n">concat</span><span class="p">(</span><span class="ss">&quot;I&#39;d wait until the &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot; is on sale for $&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">(</span><span class="n">price</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">0</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-42-7" name="__codelineno-42-7" href="#__codelineno-42-7"></a><span class="w">  </span><span class="k">ELSE</span><span class="w"> </span><span class="n">concat</span><span class="p">(</span><span class="ss">&quot;I don&#39;t need a &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">)</span>
<a id="__codelineno-42-8" name="__codelineno-42-8" href="#__codelineno-42-8"></a><span class="k">END</span><span class="p">;</span>
<a id="__codelineno-42-9" name="__codelineno-42-9" href="#__codelineno-42-9"></a>
<a id="__codelineno-42-10" name="__codelineno-42-10" href="#__codelineno-42-10"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">item_preference</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">price</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">item_lookup</span>
</code></pre></div>
<h3 id="python-udfs">Python UDFs</h3>
<h3 id="user-defined-function-udf">User-Defined Function (UDF)</h3>
<p>A custom column transformation function</p>
<ul>
<li>
<p>Can’t be optimized by Catalyst Optimizer</p>
</li>
<li>
<p>Function is serialized and sent to executors</p>
</li>
<li>
<p>Row data is deserialized from Spark's native binary format to pass to the UDF, and the results are serialized back into Spark's native format</p>
</li>
<li>
<p>For Python UDFs, additional interprocess communication overhead between the executor and a Python interpreter running on each worker node</p>
</li>
</ul>
<p><strong>Define a Function</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">first_letter_function</span><span class="p">(</span><span class="n">email</span><span class="p">):</span>
<a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a>    <span class="k">return</span> <span class="n">email</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<p><strong>Create User Defined Function</strong></p>
<ul>
<li>First serialize the function and then send it to the executors to be applied to the DataFrame records.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="n">first_letter_udf</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="n">first_letter_function</span><span class="p">)</span>
</code></pre></div>
<p><strong>Apply the UDF on the email column</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">col</span>
<a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a><span class="n">display</span><span class="p">(</span><span class="n">sales_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">first_letter_udf</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">))))</span>
</code></pre></div>
<strong>Register UDF to be used in SQL</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="n">sales_df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;sales&quot;</span><span class="p">)</span>
<a id="__codelineno-46-2" name="__codelineno-46-2" href="#__codelineno-46-2"></a><span class="n">first_letter_udf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">udf</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;sql_udf&quot;</span><span class="p">,</span><span class="n">fist_letter_function</span><span class="p">)</span>
</code></pre></div>
<p><strong>Use it in SQL</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">sql_udf</span><span class="p">(</span><span class="n">email</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">first_letter</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">sales</span>
</code></pre></div>
<p><strong>Using Decorator Syntax</strong></p>
<p>Alternatively, you can define and register a UDF using <a href="https://realpython.com/primer-on-python-decorators/" target="_blank">Python decorator syntax</a>. The <strong><code>@udf</code></strong> decorator parameter is the Column datatype the function returns.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="nd">@udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)</span>
<a id="__codelineno-48-2" name="__codelineno-48-2" href="#__codelineno-48-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">first_letter_udf</span><span class="p">(</span><span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-48-3" name="__codelineno-48-3" href="#__codelineno-48-3"></a><span class="k">return</span> <span class="n">email</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<h4 id="normal-python-udfs-vs-pandas-udfs">Normal Python UDFs vs Pandas UDFs</h4>
<p>Pandas UDFs are available in Python to improve the efficiency of UDFs. Pandas UDFs utilize Apache Arrow to speed up computation.</p>
<ul>
<li><a href="https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html" target="_blank">Blog post</a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/user_guide/sql/arrow_pandas.html?highlight=arrow" target="_blank">Documentation</a></li>
</ul>
<p><img src="https://databricks.com/wp-content/uploads/2017/10/image1-4.png" alt="Benchmark" width ="500" height="1500"></p>
<p>The user-defined functions are executed using: 
* <a href="https://arrow.apache.org/" target="_blank">Apache Arrow</a>, an in-memory columnar data format that is used in Spark to efficiently transfer data between JVM and Python processes with near-zero (de)serialization cost
* Pandas inside the function, to work with Pandas instances and APIs</p>
<p>Normal Python UDF</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">udf</span>
<a id="__codelineno-49-2" name="__codelineno-49-2" href="#__codelineno-49-2"></a>
<a id="__codelineno-49-3" name="__codelineno-49-3" href="#__codelineno-49-3"></a><span class="c1"># Use udf to define a row-at-a-time udf</span>
<a id="__codelineno-49-4" name="__codelineno-49-4" href="#__codelineno-49-4"></a><span class="nd">@udf</span><span class="p">(</span><span class="s1">&#39;double&#39;</span><span class="p">)</span>
<a id="__codelineno-49-5" name="__codelineno-49-5" href="#__codelineno-49-5"></a><span class="c1"># Input/output are both a single double value</span>
<a id="__codelineno-49-6" name="__codelineno-49-6" href="#__codelineno-49-6"></a><span class="k">def</span><span class="w"> </span><span class="nf">plus_one</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
<a id="__codelineno-49-7" name="__codelineno-49-7" href="#__codelineno-49-7"></a>      <span class="k">return</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-49-8" name="__codelineno-49-8" href="#__codelineno-49-8"></a>
<a id="__codelineno-49-9" name="__codelineno-49-9" href="#__codelineno-49-9"></a><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">,</span> <span class="n">plus_one</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span><span class="p">))</span>
</code></pre></div>
Pandas UDFs : Row at a time</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">pandas_udf</span><span class="p">,</span> <span class="n">PandasUDFType</span>
<a id="__codelineno-50-2" name="__codelineno-50-2" href="#__codelineno-50-2"></a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s1">&#39;double&#39;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<a id="__codelineno-50-3" name="__codelineno-50-3" href="#__codelineno-50-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">pandas_plus_one</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
<a id="__codelineno-50-4" name="__codelineno-50-4" href="#__codelineno-50-4"></a>    <span class="k">return</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-50-5" name="__codelineno-50-5" href="#__codelineno-50-5"></a><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">,</span> <span class="n">pandas_plus_one</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span><span class="p">))</span>
</code></pre></div>
<p>In the row-at-a-time version, the user-defined function takes a double "v" and returns the result of "v + 1" as a double. In the Pandas version, the user-defined function takes a  <code>pandas.Series</code>  "v" and returns the result of "v + 1" as a  <code>pandas.Series</code>. Because "v + 1" is vectorized on  <code>pandas.Series</code>, the Pandas version is much faster than the row-at-a-time version.</p>
<p><strong>Pandas Vectorized UDF</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="n">import</span><span class="w"> </span><span class="n">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">pd</span>
<a id="__codelineno-51-2" name="__codelineno-51-2" href="#__codelineno-51-2"></a><span class="k">from</span><span class="w"> </span><span class="n">pyspark</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">functions</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">pandas_udf</span>
<a id="__codelineno-51-3" name="__codelineno-51-3" href="#__codelineno-51-3"></a>
<a id="__codelineno-51-4" name="__codelineno-51-4" href="#__codelineno-51-4"></a><span class="o">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="k">input</span><span class="o">/</span><span class="k">output</span>
<a id="__codelineno-51-5" name="__codelineno-51-5" href="#__codelineno-51-5"></a><span class="o">@</span><span class="n">pandas_udf</span><span class="p">(</span><span class="ss">&quot;string&quot;</span><span class="p">)</span>
<a id="__codelineno-51-6" name="__codelineno-51-6" href="#__codelineno-51-6"></a><span class="n">def</span><span class="w"> </span><span class="n">vectorized_udf</span><span class="p">(</span><span class="n">email</span><span class="p">:</span><span class="w"> </span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">:</span>
<a id="__codelineno-51-7" name="__codelineno-51-7" href="#__codelineno-51-7"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">email</span><span class="p">.</span><span class="n">str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<p><strong>Registering UDF for usage in SQL Namespace</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">spark</span><span class="p">.</span><span class="n">udf</span><span class="p">.</span><span class="n">register</span><span class="p">(</span><span class="ss">&quot;sql_vectorized_udf&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">vectorized_udf</span><span class="p">)</span>
</code></pre></div>
<p><strong>Using UDF in SQL Statement</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">sql_vectorized_udf</span><span class="p">(</span><span class="n">email</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">firstLetter</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">sales</span>
</code></pre></div>
<h3 id="managing-data-with-delta-lake">Managing Data with Delta Lake</h3>
<p>Delta Lake enables building a data lakehouse on top of the existing cloud storage. Its not a database service or data warehouse.
It's built for scalable metadata handling.
Delta Lake brings ACID transaction guarantees to object storage.</p>
<p><img alt="Alt text" src="../image-80.png" /></p>
<p><img alt="Alt text" src="../image-81.png" /></p>
<p><img alt="Alt text" src="../image-82.png" /></p>
<p>What is ACID?
<img alt="Alt text" src="../image-83.png" /></p>
<h4 id="problems-solved-by-acid">Problems Solved by ACID</h4>
<ul>
<li>Hard to append data</li>
<li>Modification of existing data is difficult</li>
<li>Jobs fail mid way</li>
<li>Costly to keep historical data versions.</li>
</ul>
<p>Its the default format to create tables in Databricks</p>
<h3 id="schemas-and-tables">Schemas and Tables</h3>
<p>Creating Schema in the default directory <code>dbfs:/user/hive/warehouse</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="n">_default_location</span><span class="p">;</span>
</code></pre></div>
<p>Creating Schema in a custom location </p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="n">_custom_location</span><span class="w"> </span><span class="k">LOCATION</span><span class="w"> </span><span class="s1">&#39;${da.paths.working_dir}/${da.schema_name}_custom_location.db&#39;</span>
</code></pre></div>
<h4 id="creating-managed-tables">Creating Managed Tables</h4>
<p>We dont need to mention the location of the tables.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a><span class="n">USE</span><span class="w"> </span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="n">_default_location</span><span class="p">;</span>
<a id="__codelineno-56-2" name="__codelineno-56-2" href="#__codelineno-56-2"></a>
<a id="__codelineno-56-3" name="__codelineno-56-3" href="#__codelineno-56-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">managed_table</span><span class="w"> </span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="k">length</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="nb">INT</span><span class="p">);</span>
<a id="__codelineno-56-4" name="__codelineno-56-4" href="#__codelineno-56-4"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">managed_table</span><span class="w"> </span>
<a id="__codelineno-56-5" name="__codelineno-56-5" href="#__codelineno-56-5"></a><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<a id="__codelineno-56-6" name="__codelineno-56-6" href="#__codelineno-56-6"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">managed_table</span><span class="p">;</span>
</code></pre></div>
<p>To find the location of the managed table we can use the <code>DESCRIBE DETAIL managed_table</code> command. Output is <code>dbfs:/user/hive/warehouse/rajeevapoornachandrahsbaliga_gnc9_da_delp_default_location.db/managed_table</code></p>
<p>The default format of the table is delta.</p>
<p>If we drop the managed table, only the schema will be there, the table and data will be deleted.</p>
<p>Checking if the schema still exists</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="n">schema_default_location</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DESCRIBE SCHEMA </span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">schema_name</span><span class="si">}</span><span class="s2">_default_location&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">database_description_value</span>
<a id="__codelineno-57-2" name="__codelineno-57-2" href="#__codelineno-57-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">schema_default_location</span><span class="p">)</span>
<a id="__codelineno-57-3" name="__codelineno-57-3" href="#__codelineno-57-3"></a><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">schema_default_location</span><span class="p">)</span>
</code></pre></div>
<p>Output : dbfs:/user/hive/warehouse/rajeevapoornachandrahsbaliga_gnc9_da_delp_default_location.db</p>
<h4 id="creating-external-tables">⚠️ Creating External Tables</h4>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="n">USE</span><span class="w"> </span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="n">_default_location</span><span class="p">;</span>
<a id="__codelineno-58-2" name="__codelineno-58-2" href="#__codelineno-58-2"></a>
<a id="__codelineno-58-3" name="__codelineno-58-3" href="#__codelineno-58-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TEMPORARY</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">temp_delays</span><span class="w"> </span>
<a id="__codelineno-58-4" name="__codelineno-58-4" href="#__codelineno-58-4"></a><span class="k">USING</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="k">OPTIONS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-58-5" name="__codelineno-58-5" href="#__codelineno-58-5"></a><span class="w">    </span><span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;${da.paths.datasets}/flights/delay_departures.csv&quot;</span><span class="p">,</span>
<a id="__codelineno-58-6" name="__codelineno-58-6" href="#__codelineno-58-6"></a><span class="w">    </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;true&quot;</span><span class="p">,</span>
<a id="__codelineno-58-7" name="__codelineno-58-7" href="#__codelineno-58-7"></a><span class="w">    </span><span class="k">mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;FAILFAST&quot;</span>
<a id="__codelineno-58-8" name="__codelineno-58-8" href="#__codelineno-58-8"></a><span class="p">);</span>
<a id="__codelineno-58-9" name="__codelineno-58-9" href="#__codelineno-58-9"></a>
<a id="__codelineno-58-10" name="__codelineno-58-10" href="#__codelineno-58-10"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">EXTERNAL</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">external_table</span><span class="w"> </span><span class="k">LOCATION</span><span class="w"> </span><span class="s1">&#39;${da.path.working_dir}/external_table&#39;</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span>
<a id="__codelineno-58-11" name="__codelineno-58-11" href="#__codelineno-58-11"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">temp_delays</span><span class="p">;</span>
<a id="__codelineno-58-12" name="__codelineno-58-12" href="#__codelineno-58-12"></a>
<a id="__codelineno-58-13" name="__codelineno-58-13" href="#__codelineno-58-13"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">external_table</span>
</code></pre></div>
<img alt="Alt text" src="../image-84.png" /></p>
<p>Dropping the external table deletes the table definition but the data is still there.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a><span class="n">tbl_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">working_dir</span><span class="si">}</span><span class="s2">/external_table&quot;</span>
<a id="__codelineno-59-2" name="__codelineno-59-2" href="#__codelineno-59-2"></a><span class="n">files</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">tbl_path</span><span class="p">)</span>
<a id="__codelineno-59-3" name="__codelineno-59-3" href="#__codelineno-59-3"></a><span class="n">display</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-85.png" /></p>
<p>To drop external table schema use :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="k">DROP</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="err">{</span><span class="n">da</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="n">_custom_location</span><span class="w"> </span><span class="k">CASCADE</span><span class="p">;</span>
</code></pre></div>
<p>If the schema is managed by the workspace-level Hive metastore, dropping a schema using CASCADE recursively deletes all files in the specified location, regardless of the table type (managed or external).</p>
<h3 id="setting-up-delta-tables">Setting Up Delta Tables</h3>
<p>After extracting data from external data sources, load data into the Lakehouse to ensure that all of the benefits of the Databricks platform can be fully leveraged.</p>
<p>While different organizations may have varying policies for how data is initially loaded into Databricks, we typically recommend that early tables represent a mostly raw version of the data, and that validation and enrichment occur in later stages. </p>
<p>This pattern ensures that even if data doesn't match expectations with regards to data types or column names, no data will be dropped, meaning that programmatic or manual intervention can still salvage data in a partially corrupted or invalid state.</p>
<h4 id="ctas-statements">CTAS Statements</h4>
<p>Used to populate the delta tables using data from an input query</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">sales</span><span class="o">-</span><span class="n">historical</span><span class="o">`</span><span class="p">;</span>
<a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>
<a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">EXTENDED</span><span class="w"> </span><span class="n">sales</span><span class="p">;</span>
</code></pre></div>
<p><strong>Note</strong></p>
<p>CTAS statements automatically infer schema information from query results and do <strong>not</strong> support manual schema declaration. </p>
<p>This means that CTAS statements are useful for external data ingestion from sources with well-defined schema, such as Parquet files and tables.</p>
<p>CTAS statements also do not support specifying additional file options.</p>
<h4 id="ingesting-csv-with-ctas">Ingesting csv with CTAS</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales_unparsed</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">csv</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">sales</span><span class="o">-</span><span class="n">csv</span><span class="o">`</span><span class="p">;</span>
<a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a>
<a id="__codelineno-62-4" name="__codelineno-62-4" href="#__codelineno-62-4"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">sales_unparsed</span><span class="p">;</span>
</code></pre></div>
<p>Output is as follows:
<img alt="Alt text" src="../image-86.png" /></p>
<p>To fix this we use a reference to the files that allows us to specify the options.</p>
<p>We will specify options to a temp view and then use this as a source for a CTAS statement to register the Delta Table</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">sales_tmp_vw</span>
<a id="__codelineno-63-2" name="__codelineno-63-2" href="#__codelineno-63-2"></a><span class="w">  </span><span class="p">(</span><span class="n">order_id</span><span class="w"> </span><span class="n">LONG</span><span class="p">,</span><span class="w"> </span><span class="n">email</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="n">transactions_timestamp</span><span class="w"> </span><span class="n">LONG</span><span class="p">,</span><span class="w"> </span><span class="n">total_item_quantity</span><span class="w"> </span><span class="nb">INTEGER</span><span class="p">,</span><span class="w"> </span><span class="n">purchase_revenue_in_usd</span><span class="w"> </span><span class="n">DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">unique_items</span><span class="w"> </span><span class="nb">INTEGER</span><span class="p">,</span><span class="w"> </span><span class="n">items</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span>
<a id="__codelineno-63-3" name="__codelineno-63-3" href="#__codelineno-63-3"></a><span class="k">USING</span><span class="w"> </span><span class="n">CSV</span>
<a id="__codelineno-63-4" name="__codelineno-63-4" href="#__codelineno-63-4"></a><span class="k">OPTIONS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-63-5" name="__codelineno-63-5" href="#__codelineno-63-5"></a><span class="w">  </span><span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;${da.paths.datasets}/ecommerce/raw/sales-csv&quot;</span><span class="p">,</span>
<a id="__codelineno-63-6" name="__codelineno-63-6" href="#__codelineno-63-6"></a><span class="w">  </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;true&quot;</span><span class="p">,</span>
<a id="__codelineno-63-7" name="__codelineno-63-7" href="#__codelineno-63-7"></a><span class="w">  </span><span class="k">delimiter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;|&quot;</span>
<a id="__codelineno-63-8" name="__codelineno-63-8" href="#__codelineno-63-8"></a><span class="p">);</span>
<a id="__codelineno-63-9" name="__codelineno-63-9" href="#__codelineno-63-9"></a>
<a id="__codelineno-63-10" name="__codelineno-63-10" href="#__codelineno-63-10"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales_delta</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-63-11" name="__codelineno-63-11" href="#__codelineno-63-11"></a><span class="w">  </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">sales_tmp_vw</span><span class="p">;</span>
<a id="__codelineno-63-12" name="__codelineno-63-12" href="#__codelineno-63-12"></a>
<a id="__codelineno-63-13" name="__codelineno-63-13" href="#__codelineno-63-13"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">sales_delta</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-87.png" /></p>
<h4 id="filtering-and-renaming-columns-from-existing-tables">Filtering and Renaming columns from existing tables</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">purchases</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-64-2" name="__codelineno-64-2" href="#__codelineno-64-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">order_id</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">transaction_timestamp</span><span class="p">,</span><span class="w"> </span><span class="n">purchase_revenue_in_usd</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">price</span>
<a id="__codelineno-64-3" name="__codelineno-64-3" href="#__codelineno-64-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">sales</span><span class="p">;</span>
<a id="__codelineno-64-4" name="__codelineno-64-4" href="#__codelineno-64-4"></a>
<a id="__codelineno-64-5" name="__codelineno-64-5" href="#__codelineno-64-5"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">purchases</span>
</code></pre></div>
<h3 id="declare-schema-with-generated-columns">Declare Schema with Generated Columns</h3>
<p><img alt="Alt text" src="../image-88.png" />
As noted previously, CTAS statements do not support schema declaration. We note above that the timestamp column appears to be some variant of a Unix timestamp, which may not be the most useful for our analysts to derive insights. This is a situation where generated columns would be beneficial.</p>
<p>Generated columns are a special type of column whose values are automatically generated based on a user-specified function over other columns in the Delta table.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">purchase_dates</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-65-2" name="__codelineno-65-2" href="#__codelineno-65-2"></a><span class="w">  </span><span class="n">id</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-65-3" name="__codelineno-65-3" href="#__codelineno-65-3"></a><span class="w">  </span><span class="n">transaction_timestamp</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-65-4" name="__codelineno-65-4" href="#__codelineno-65-4"></a><span class="w">  </span><span class="n">price</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span>
<a id="__codelineno-65-5" name="__codelineno-65-5" href="#__codelineno-65-5"></a><span class="w">  </span><span class="nb">date</span><span class="w"> </span><span class="nb">DATE</span><span class="w"> </span><span class="k">GENERATED</span><span class="w"> </span><span class="n">ALWAYS</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-65-6" name="__codelineno-65-6" href="#__codelineno-65-6"></a><span class="w">    </span><span class="k">cast</span><span class="p">(</span><span class="k">cast</span><span class="p">(</span><span class="n">transaction_timestamp</span><span class="o">/</span><span class="mi">1</span><span class="n">e6</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">TIMESTAMP</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="nb">DATE</span><span class="p">))</span>
<a id="__codelineno-65-7" name="__codelineno-65-7" href="#__codelineno-65-7"></a><span class="w">    </span><span class="k">COMMENT</span><span class="w"> </span><span class="ss">&quot;generated based on `transactions_timestamp` column&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="mergin-data">Mergin Data</h4>
<p>Check how many records are in purchase_dates?</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">purchase_dates</span><span class="p">;</span>
</code></pre></div>
There are no records in the table.</p>
<p>Check how many records are in purchases?</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">purchases</span><span class="p">;</span>
</code></pre></div>
There are 10,510 records.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a><span class="k">SET</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">databricks</span><span class="p">.</span><span class="n">delta</span><span class="p">.</span><span class="k">schema</span><span class="p">.</span><span class="n">autoMerge</span><span class="p">.</span><span class="n">enabled</span><span class="o">=</span><span class="k">true</span><span class="p">;</span><span class="w"> </span>
<a id="__codelineno-68-2" name="__codelineno-68-2" href="#__codelineno-68-2"></a>
<a id="__codelineno-68-3" name="__codelineno-68-3" href="#__codelineno-68-3"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">purchase_dates</span><span class="w"> </span><span class="n">a</span>
<a id="__codelineno-68-4" name="__codelineno-68-4" href="#__codelineno-68-4"></a><span class="k">USING</span><span class="w"> </span><span class="n">purchases</span><span class="w"> </span><span class="n">b</span>
<a id="__codelineno-68-5" name="__codelineno-68-5" href="#__codelineno-68-5"></a><span class="k">ON</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">id</span>
<a id="__codelineno-68-6" name="__codelineno-68-6" href="#__codelineno-68-6"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">THEN</span>
<a id="__codelineno-68-7" name="__codelineno-68-7" href="#__codelineno-68-7"></a><span class="w">  </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span>
</code></pre></div>
<p>The SET command ensures that autoMerge is enabled we dont need to <code>REFRESH</code> after merging into the purchase_dates table.</p>
<p>It's important to note that if a field that would otherwise be generated is included in an insert to a table, this insert will fail if the value provided does not exactly match the value that would be derived by the logic used to define the generated column.</p>
<h3 id="adding-constraints">Adding Constraints</h3>
<p><strong>CHECK</strong> constraint</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a><span class="k">ALTER</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">purchase_dates</span><span class="w"> </span><span class="k">ADD</span><span class="w"> </span><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_date</span><span class="w"> </span><span class="k">CHECK</span><span class="w"> </span><span class="p">(</span><span class="nb">date</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="s1">&#39;2020-01-01&#39;</span><span class="p">);</span>
</code></pre></div>
<img alt="Alt text" src="../image-89.png" /></p>
<h3 id="additional-options-and-metadata">Additional Options and Metadata</h3>
<p>Our <strong><code>SELECT</code></strong> clause leverages two built-in Spark SQL commands useful for file ingestion:
* <strong><code>current_timestamp()</code></strong> records the timestamp when the logic is executed
* <strong><code>input_file_name()</code></strong> records the source data file for each record in the table</p>
<p>We also include logic to create a new date column derived from timestamp data in the source.</p>
<p>The <strong><code>CREATE TABLE</code></strong> clause contains several options:
* A <strong><code>COMMENT</code></strong> is added to allow for easier discovery of table contents
* A <strong><code>LOCATION</code></strong> is specified, which will result in an external (rather than managed) table
* The table is <strong><code>PARTITIONED BY</code></strong> a date column; this means that the data from each data will exist within its own directory in the target storage location.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">users_pii</span>
<a id="__codelineno-70-2" name="__codelineno-70-2" href="#__codelineno-70-2"></a><span class="k">COMMENT</span><span class="w"> </span><span class="ss">&quot;Contains PII&quot;</span>
<a id="__codelineno-70-3" name="__codelineno-70-3" href="#__codelineno-70-3"></a><span class="k">LOCATION</span><span class="w"> </span><span class="ss">&quot;${da.paths.working_dir}/tmp/users_pii&quot;</span>
<a id="__codelineno-70-4" name="__codelineno-70-4" href="#__codelineno-70-4"></a><span class="n">PARTITIONED</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">first_touch_date</span><span class="p">)</span>
<a id="__codelineno-70-5" name="__codelineno-70-5" href="#__codelineno-70-5"></a><span class="k">AS</span>
<a id="__codelineno-70-6" name="__codelineno-70-6" href="#__codelineno-70-6"></a><span class="w">  </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-70-7" name="__codelineno-70-7" href="#__codelineno-70-7"></a><span class="w">    </span><span class="k">cast</span><span class="p">(</span><span class="k">cast</span><span class="p">(</span><span class="n">user_first_touch_timestamp</span><span class="o">/</span><span class="mi">1</span><span class="n">e6</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">TIMESTAMP</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="nb">DATE</span><span class="p">)</span><span class="w"> </span><span class="n">first_touch_date</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-70-8" name="__codelineno-70-8" href="#__codelineno-70-8"></a><span class="w">    </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="n">updated</span><span class="p">,</span>
<a id="__codelineno-70-9" name="__codelineno-70-9" href="#__codelineno-70-9"></a><span class="w">    </span><span class="n">input_file_name</span><span class="p">()</span><span class="w"> </span><span class="n">source_file</span>
<a id="__codelineno-70-10" name="__codelineno-70-10" href="#__codelineno-70-10"></a><span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">users</span><span class="o">-</span><span class="n">historical</span><span class="o">/`</span><span class="p">;</span>
<a id="__codelineno-70-11" name="__codelineno-70-11" href="#__codelineno-70-11"></a>
<a id="__codelineno-70-12" name="__codelineno-70-12" href="#__codelineno-70-12"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">users_pii</span><span class="p">;</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-90.png" /></p>
<p><strong>Listing all the files</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a><span class="n">files</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">working_dir</span><span class="si">}</span><span class="s2">/tmp/users_pii&quot;</span><span class="p">)</span>
<a id="__codelineno-71-2" name="__codelineno-71-2" href="#__codelineno-71-2"></a><span class="n">display</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-91.png" /></p>
<h3 id="cloning-delta-lake-tables">Cloning Delta Lake Tables</h3>
<p>Delta Lake has two options for efficiently copying Delta Lake tables.</p>
<p><strong><code>DEEP CLONE</code></strong> fully copies data and metadata from a source table to a target. This copy occurs incrementally, so executing this command again can sync changes from the source to the target location.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">purchases_clone</span>
<a id="__codelineno-72-2" name="__codelineno-72-2" href="#__codelineno-72-2"></a><span class="n">DEEP</span><span class="w"> </span><span class="n">CLONE</span><span class="w"> </span><span class="n">purchases</span>
</code></pre></div>
<p>If you wish to create a copy of a table quickly to test out applying changes without the risk of modifying the current table, <strong><code>SHALLOW CLONE</code></strong> can be a good option. Shallow clones just copy the Delta transaction logs, meaning that the data doesn't move.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">purchases_shallow_clone</span>
<a id="__codelineno-73-2" name="__codelineno-73-2" href="#__codelineno-73-2"></a><span class="n">SHALLOW</span><span class="w"> </span><span class="n">CLONE</span><span class="w"> </span><span class="n">purchases</span>
</code></pre></div>
<h3 id="loading-data-into-tables">Loading Data Into Tables</h3>
<h4 id="complete-overwrites">Complete Overwrites</h4>
<p>We can use overwrites to atomically replace all of the data in a table. There are multiple benefits to overwriting tables instead of deleting and recreating tables:</p>
<ul>
<li>
<p>Overwriting a table is much faster because it doesn’t need to list the directory recursively or delete any files.</p>
</li>
<li>
<p>The old version of the table still exists; can easily retrieve the old data using Time Travel.</p>
</li>
<li>
<p>It’s an atomic operation. Concurrent queries can still read the table while you are deleting the table.</p>
</li>
<li>
<p>Due to ACID transaction guarantees, if overwriting the table fails, the table will be in its previous state.</p>
</li>
</ul>
<p>Spark SQL provides two easy methods to accomplish complete overwrites.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">events</span><span class="w"> </span><span class="k">AS</span>
<a id="__codelineno-74-2" name="__codelineno-74-2" href="#__codelineno-74-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">events</span><span class="o">-</span><span class="n">historical</span><span class="o">`</span>
</code></pre></div>
<p><strong>Reviewing the Table History</strong></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">HISTORY</span><span class="w"> </span><span class="n">events</span>
</code></pre></div>
<img alt="Alt text" src="../image-92.png" /></p>
<h4 id="insert-overwrite">Insert Overwrite</h4>
<p><strong><code>INSERT OVERWRITE</code></strong> provides a nearly identical outcome as above: data in the target table will be replaced by data from the query. </p>
<ul>
<li>
<p>Can only overwrite an existing table, not create a new one like our CRAS statement.</p>
</li>
<li>
<p>Can overwrite only with new records that match the current table schema -- and thus can be a "safer" technique for overwriting an existing table without disrupting downstream consumers.</p>
</li>
<li>
<p>Can overwrite individual partitions.</p>
</li>
</ul>
<p>Metrics that are defined during Insert Overwrite on running <code>DESCRIBE HISTORY SALES</code> is different.</p>
<p>Whereas a CRAS statement will allow us to completely redefine the contents of our target table, <strong><code>INSERT OVERWRITE</code></strong> will fail if we try to change our schema (unless we provide optional settings). </p>
<p>Uncomment and run the cell below to generate an expected error message.</p>
<p>This gives an error</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a><span class="k">INSERT</span><span class="w"> </span><span class="n">OVERWRITE</span><span class="w"> </span><span class="n">sales</span>
<a id="__codelineno-76-2" name="__codelineno-76-2" href="#__codelineno-76-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">sales</span><span class="o">-</span><span class="n">historical</span><span class="o">`</span>
</code></pre></div>
<h4 id="appending-data">Appending Data</h4>
<p>We can use <strong><code>INSERT INTO</code></strong> to atomically append new rows to an existing Delta table. This allows for incremental updates to existing tables, which is much more efficient than overwriting each time.</p>
<p>Append new sale records to the <strong><code>sales</code></strong> table using <strong><code>INSERT INTO</code></strong></p>
<p>Note that <strong><code>INSERT INTO</code></strong> does not have any built-in guarantees to prevent inserting the same records multiple times. Re-executing the above cell would write the same records to the target table, resulting in duplicate records.</p>
<h4 id="merging-updates">Merging Updates</h4>
<p><strong><code>
MERGE INTO target a<br/>
USING source b<br/>
ON {merge_condition}<br/>
WHEN MATCHED THEN {matched_action}<br/>
WHEN NOT MATCHED THEN {not_matched_action}<br/>
</code></strong></p>
<p>We will use the <strong><code>MERGE</code></strong> operation to update historic users data with updated emails and new users.</p>
<p>Step 1 : Check <code>users_30m</code> parquet</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">PARQUET</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">users</span><span class="o">-</span><span class="mi">30</span><span class="n">m</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-93.png" /></p>
<p>Step 2 : Create view <code>users_update</code> and add data from <code>users_30m</code> dataset</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">users_update</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span>
<a id="__codelineno-78-2" name="__codelineno-78-2" href="#__codelineno-78-2"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span>
<a id="__codelineno-78-3" name="__codelineno-78-3" href="#__codelineno-78-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="err">${</span><span class="n">da</span><span class="p">.</span><span class="n">paths</span><span class="p">.</span><span class="n">datasets</span><span class="err">}</span><span class="o">/</span><span class="n">ecommerce</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">users</span><span class="o">-</span><span class="mi">30</span><span class="n">m</span><span class="o">`</span>
</code></pre></div>
<p>Step 3 : Check <code>users</code> and <code>users_updated</code> dataset</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">users</span><span class="p">;</span>
</code></pre></div>
<img alt="Alt text" src="../image-94.png" /></p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-80-1" name="__codelineno-80-1" href="#__codelineno-80-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">users_update</span><span class="p">;</span>
</code></pre></div>
<img alt="Alt text" src="../image-95.png" /></p>
<p>Step 4 : If the email in <code>users</code> is null and in <code>users_update</code> is not null then set email in users to <code>users.email</code> and <code>users.updated</code> to <code>users_updated.updated</code> , else insert whatever record is in users_update.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-81-1" name="__codelineno-81-1" href="#__codelineno-81-1"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">users</span><span class="w"> </span><span class="n">a</span>
<a id="__codelineno-81-2" name="__codelineno-81-2" href="#__codelineno-81-2"></a><span class="k">USING</span><span class="w"> </span><span class="n">users_update</span><span class="w"> </span><span class="n">b</span>
<a id="__codelineno-81-3" name="__codelineno-81-3" href="#__codelineno-81-3"></a><span class="k">ON</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">user_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">user_id</span>
<a id="__codelineno-81-4" name="__codelineno-81-4" href="#__codelineno-81-4"></a><span class="k">WHEN</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">email</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">email</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">THEN</span>
<a id="__codelineno-81-5" name="__codelineno-81-5" href="#__codelineno-81-5"></a><span class="w">  </span><span class="k">UPDATE</span><span class="w"> </span><span class="k">SET</span><span class="w"> </span><span class="n">email</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">updated</span>
<a id="__codelineno-81-6" name="__codelineno-81-6" href="#__codelineno-81-6"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-96.png" /></p>
<h4 id="insert-only-merge-for-data-deduplication">Insert-Only Merge For Data Deduplication ⚠️</h4>
<p>A common ETL use case is to collect logs or other every-appending datasets into a Delta table through a series of append operations. </p>
<p>Many source systems can generate duplicate records. With merge, you can avoid inserting the duplicate records by performing an insert-only merge.</p>
<p>This optimized command uses the same <strong><code>MERGE</code></strong> syntax but only provided a <strong><code>WHEN NOT MATCHED</code></strong> clause.</p>
<p>Below, we use this to confirm that records with the same <strong><code>user_id</code></strong> and <strong><code>event_timestamp</code></strong> aren't already in the <strong><code>events</code></strong> table.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-82-1" name="__codelineno-82-1" href="#__codelineno-82-1"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">events</span><span class="w"> </span><span class="n">a</span>
<a id="__codelineno-82-2" name="__codelineno-82-2" href="#__codelineno-82-2"></a><span class="k">USING</span><span class="w"> </span><span class="n">events_update</span><span class="w"> </span><span class="n">b</span>
<a id="__codelineno-82-3" name="__codelineno-82-3" href="#__codelineno-82-3"></a><span class="k">ON</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">user_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">user_id</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">event_timestamp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">event_timestamp</span>
<a id="__codelineno-82-4" name="__codelineno-82-4" href="#__codelineno-82-4"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">traffic_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;email&#39;</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span>
<a id="__codelineno-82-5" name="__codelineno-82-5" href="#__codelineno-82-5"></a><span class="w">  </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span>
</code></pre></div>
<p><strong>Logs Example</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-83-1" name="__codelineno-83-1" href="#__codelineno-83-1"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">logs</span>
<a id="__codelineno-83-2" name="__codelineno-83-2" href="#__codelineno-83-2"></a><span class="k">USING</span><span class="w"> </span><span class="n">newDedupedLogs</span>
<a id="__codelineno-83-3" name="__codelineno-83-3" href="#__codelineno-83-3"></a><span class="k">ON</span><span class="w"> </span><span class="n">logs</span><span class="p">.</span><span class="n">uniqueId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">newDedupedLogs</span><span class="p">.</span><span class="n">uniqueId</span>
<a id="__codelineno-83-4" name="__codelineno-83-4" href="#__codelineno-83-4"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span>
<a id="__codelineno-83-5" name="__codelineno-83-5" href="#__codelineno-83-5"></a><span class="w">  </span><span class="k">THEN</span><span class="w"> </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span>
</code></pre></div>
<p>The dataset containing the new logs needs to be deduplicated within itself. By the SQL semantics of merge, it matches and deduplicates the new data with the existing data in the table, but if there is duplicate data within the new dataset, it is inserted. Hence, deduplicate the new data before merging into the table.</p>
<p>If you know that you may get duplicate records only for a few days, you can optimize your query further by partitioning the table by date, and then specifying the date range of the target table.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-84-1" name="__codelineno-84-1" href="#__codelineno-84-1"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">logs</span>
<a id="__codelineno-84-2" name="__codelineno-84-2" href="#__codelineno-84-2"></a><span class="k">USING</span><span class="w"> </span><span class="n">newDedupedLogs</span>
<a id="__codelineno-84-3" name="__codelineno-84-3" href="#__codelineno-84-3"></a><span class="k">ON</span><span class="w"> </span><span class="n">logs</span><span class="p">.</span><span class="n">uniqueId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">newDedupedLogs</span><span class="p">.</span><span class="n">uniqueId</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">logs</span><span class="p">.</span><span class="nb">date</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="k">current_date</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">INTERVAL</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="n">DAYS</span>
<a id="__codelineno-84-4" name="__codelineno-84-4" href="#__codelineno-84-4"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">newDedupedLogs</span><span class="p">.</span><span class="nb">date</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="k">current_date</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">INTERVAL</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="n">DAYS</span>
<a id="__codelineno-84-5" name="__codelineno-84-5" href="#__codelineno-84-5"></a><span class="w">  </span><span class="k">THEN</span><span class="w"> </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span>
</code></pre></div>
<h3 id="incremental-loading">Incremental Loading</h3>
<p><strong><code>COPY INTO</code></strong> provides SQL engineers an idempotent option to incrementally ingest data from external systems.</p>
<p>Note that this operation does have some expectations:
- Data schema should be consistent
- Duplicate records should try to be excluded or handled downstream</p>
<p>This operation is potentially much cheaper than full table scans for data that grows predictably.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-85-1" name="__codelineno-85-1" href="#__codelineno-85-1"></a><span class="k">COPY</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">sales</span>
<a id="__codelineno-85-2" name="__codelineno-85-2" href="#__codelineno-85-2"></a><span class="k">FROM</span><span class="w"> </span><span class="ss">&quot;${da.paths.datasets}/ecommerce/raw/sales-30m&quot;</span>
<a id="__codelineno-85-3" name="__codelineno-85-3" href="#__codelineno-85-3"></a><span class="n">FILEFORMAT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">PARQUET</span>
</code></pre></div>
<h3 id="versioning-optimizing-and-vacuuming">Versioning, Optimizing and Vacuuming</h3>
<p>Create an example table with operations</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-86-1" name="__codelineno-86-1" href="#__codelineno-86-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">students</span>
<a id="__codelineno-86-2" name="__codelineno-86-2" href="#__codelineno-86-2"></a><span class="w">  </span><span class="p">(</span><span class="n">id</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">DOUBLE</span><span class="p">);</span>
<a id="__codelineno-86-3" name="__codelineno-86-3" href="#__codelineno-86-3"></a>
<a id="__codelineno-86-4" name="__codelineno-86-4" href="#__codelineno-86-4"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Yve&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">);</span>
<a id="__codelineno-86-5" name="__codelineno-86-5" href="#__codelineno-86-5"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Omar&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">.</span><span class="mi">5</span><span class="p">);</span>
<a id="__codelineno-86-6" name="__codelineno-86-6" href="#__codelineno-86-6"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Elia&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">.</span><span class="mi">3</span><span class="p">);</span>
<a id="__codelineno-86-7" name="__codelineno-86-7" href="#__codelineno-86-7"></a>
<a id="__codelineno-86-8" name="__codelineno-86-8" href="#__codelineno-86-8"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">students</span>
<a id="__codelineno-86-9" name="__codelineno-86-9" href="#__codelineno-86-9"></a><span class="k">VALUES</span><span class="w"> </span>
<a id="__codelineno-86-10" name="__codelineno-86-10" href="#__codelineno-86-10"></a><span class="w">  </span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Ted&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">.</span><span class="mi">7</span><span class="p">),</span>
<a id="__codelineno-86-11" name="__codelineno-86-11" href="#__codelineno-86-11"></a><span class="w">  </span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Tiffany&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span>
<a id="__codelineno-86-12" name="__codelineno-86-12" href="#__codelineno-86-12"></a><span class="w">  </span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Vini&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">.</span><span class="mi">3</span><span class="p">);</span>
<a id="__codelineno-86-13" name="__codelineno-86-13" href="#__codelineno-86-13"></a>
<a id="__codelineno-86-14" name="__codelineno-86-14" href="#__codelineno-86-14"></a><span class="k">UPDATE</span><span class="w"> </span><span class="n">students</span><span class="w"> </span>
<a id="__codelineno-86-15" name="__codelineno-86-15" href="#__codelineno-86-15"></a><span class="k">SET</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="__codelineno-86-16" name="__codelineno-86-16" href="#__codelineno-86-16"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="k">LIKE</span><span class="w"> </span><span class="ss">&quot;T%&quot;</span><span class="p">;</span>
<a id="__codelineno-86-17" name="__codelineno-86-17" href="#__codelineno-86-17"></a>
<a id="__codelineno-86-18" name="__codelineno-86-18" href="#__codelineno-86-18"></a><span class="k">DELETE</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">students</span><span class="w"> </span>
<a id="__codelineno-86-19" name="__codelineno-86-19" href="#__codelineno-86-19"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">6</span><span class="p">;</span>
<a id="__codelineno-86-20" name="__codelineno-86-20" href="#__codelineno-86-20"></a>
<a id="__codelineno-86-21" name="__codelineno-86-21" href="#__codelineno-86-21"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="n">TEMP</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">updates</span><span class="p">(</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="k">type</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">VALUES</span>
<a id="__codelineno-86-22" name="__codelineno-86-22" href="#__codelineno-86-22"></a><span class="w">  </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Omar&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">15</span><span class="p">.</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;update&quot;</span><span class="p">),</span>
<a id="__codelineno-86-23" name="__codelineno-86-23" href="#__codelineno-86-23"></a><span class="w">  </span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">null</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;delete&quot;</span><span class="p">),</span>
<a id="__codelineno-86-24" name="__codelineno-86-24" href="#__codelineno-86-24"></a><span class="w">  </span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">.</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;insert&quot;</span><span class="p">),</span>
<a id="__codelineno-86-25" name="__codelineno-86-25" href="#__codelineno-86-25"></a><span class="w">  </span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Diya&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;update&quot;</span><span class="p">);</span>
<a id="__codelineno-86-26" name="__codelineno-86-26" href="#__codelineno-86-26"></a>
<a id="__codelineno-86-27" name="__codelineno-86-27" href="#__codelineno-86-27"></a><span class="n">MERGE</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="n">b</span>
<a id="__codelineno-86-28" name="__codelineno-86-28" href="#__codelineno-86-28"></a><span class="k">USING</span><span class="w"> </span><span class="n">updates</span><span class="w"> </span><span class="n">u</span>
<a id="__codelineno-86-29" name="__codelineno-86-29" href="#__codelineno-86-29"></a><span class="k">ON</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="o">=</span><span class="n">u</span><span class="p">.</span><span class="n">id</span>
<a id="__codelineno-86-30" name="__codelineno-86-30" href="#__codelineno-86-30"></a><span class="k">WHEN</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">u</span><span class="p">.</span><span class="k">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;update&quot;</span>
<a id="__codelineno-86-31" name="__codelineno-86-31" href="#__codelineno-86-31"></a><span class="w">  </span><span class="k">THEN</span><span class="w"> </span><span class="k">UPDATE</span><span class="w"> </span><span class="k">SET</span><span class="w"> </span><span class="o">*</span>
<a id="__codelineno-86-32" name="__codelineno-86-32" href="#__codelineno-86-32"></a><span class="k">WHEN</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">u</span><span class="p">.</span><span class="k">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;delete&quot;</span>
<a id="__codelineno-86-33" name="__codelineno-86-33" href="#__codelineno-86-33"></a><span class="w">  </span><span class="k">THEN</span><span class="w"> </span><span class="k">DELETE</span>
<a id="__codelineno-86-34" name="__codelineno-86-34" href="#__codelineno-86-34"></a><span class="k">WHEN</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="n">MATCHED</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">u</span><span class="p">.</span><span class="k">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;insert&quot;</span>
<a id="__codelineno-86-35" name="__codelineno-86-35" href="#__codelineno-86-35"></a><span class="w">  </span><span class="k">THEN</span><span class="w"> </span><span class="k">INSERT</span><span class="w"> </span><span class="o">*</span><span class="p">;</span>
</code></pre></div>
<p>This table gets stored in <code>dbfs:/user/hive/warehouse/students</code></p>
<p>The table is not a relational entity but a set of files stored in the cloud object storage.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-87-1" name="__codelineno-87-1" href="#__codelineno-87-1"></a><span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">user_db</span><span class="si">}</span><span class="s2">/students&quot;</span><span class="p">))</span>
</code></pre></div>
<img alt="Alt text" src="../image-97.png" /></p>
<p>There is a directory called <code>_delta_log</code> where transactions on the Delta Lake Tables are stored</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-88-1" name="__codelineno-88-1" href="#__codelineno-88-1"></a><span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">user_db</span><span class="si">}</span><span class="s2">/students/_delta_log&quot;</span><span class="p">))</span>
</code></pre></div>
There are a total of 8 transaction logs in json format
<img alt="Alt text" src="../image-98.png" /></p>
<p>For large datasets we would have more parquet files. We can see that there are 4 files currently in students.
<img alt="Alt text" src="../image-99.png" /></p>
<p>So what are the other files present for?</p>
<p>Rather than overwriting or immediately deleting files containing changed data, Delta Lake uses the transaction log to indicate whether or not files are valid in a current version of the table.</p>
<p>Here, we'll look at the transaction log corresponding the <strong><code>MERGE</code></strong> statement above, where records were inserted, updated, and deleted.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-89-1" name="__codelineno-89-1" href="#__codelineno-89-1"></a><span class="n">display</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SELECT * FROM json.`</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">user_db</span><span class="si">}</span><span class="s2">/students/_delta_log/00000000000000000007.json`&quot;</span><span class="p">))</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-100.png" /></p>
<p>The <strong><code>add</code></strong> column contains a list of all the new files written to our table; the <strong><code>remove</code></strong> column indicates those files that no longer should be included in our table.</p>
<p>When we query a Delta Lake table, the query engine uses the transaction logs to resolve all the files that are valid in the current version, and ignores all other data files.</p>
<h3 id="optimizing-and-indexing">Optimizing and Indexing</h3>
<p>When we use large datasets, we may run into problems of a large number of files.</p>
<p>Here since we did many operations that only changed/modified a small number of rows, there were more number of files.</p>
<p>Files will be combined toward an optimal size (scaled based on the size of the table) by using the <strong><code>OPTIMIZE</code></strong> command.</p>
<p><strong><code>OPTIMIZE</code></strong> will replace existing data files by combining records and rewriting the results.</p>
<p>When executing <strong><code>OPTIMIZE</code></strong>, users can optionally specify one or several fields for <strong><code>ZORDER</code></strong> indexing. While the specific math of Z-order is unimportant, it speeds up data retrieval when filtering on provided fields by colocating data with similar values within data files.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-90-1" name="__codelineno-90-1" href="#__codelineno-90-1"></a><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">students</span>
<a id="__codelineno-90-2" name="__codelineno-90-2" href="#__codelineno-90-2"></a><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">id</span>
</code></pre></div>
<p>By looking at the output we can motice that 1 file was added and 4 were removed. 
<img alt="Alt text" src="../image-101.png" /></p>
<p>As expected, <strong><code>OPTIMIZE</code></strong> created another version of our table, meaning that version 8 is our most current version.</p>
<p>Remember all of those extra data files that had been marked as removed in our transaction log? These provide us with the ability to query previous versions of our table.</p>
<p>These time travel queries can be performed by specifying either the integer version or a timestamp.</p>
<p><strong>NOTE</strong>: In most cases, you'll use a timestamp to recreate data at a time of interest. For our demo we'll use version, as this is deterministic (whereas you may be running this demo at any time in the future).</p>
<p><strong>Going back to a previous state</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-91-1" name="__codelineno-91-1" href="#__codelineno-91-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span>
<a id="__codelineno-91-2" name="__codelineno-91-2" href="#__codelineno-91-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="k">VERSION</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">OF</span><span class="w"> </span><span class="mi">3</span>
</code></pre></div>
<p>What's important to note about time travel is that we're not recreating a previous state of the table by undoing transactions against our current version; rather, we're just querying all those data files that were indicated as valid as of the specified version.</p>
<h3 id="rollback-to-previous-version">Rollback to Previous Version</h3>
<p>Suppose we are typing a query to manually delete some records from the table and by mistake delete the entire table. We can rollback to the previous version by rolling back the commit.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-92-1" name="__codelineno-92-1" href="#__codelineno-92-1"></a><span class="n">RESTORE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="k">VERSION</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">OF</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span>
</code></pre></div>
<h3 id="cleaning-up-stale-files-and-vacuum">Cleaning Up Stale Files and Vacuum</h3>
<p>Databricks will automatically clean up stale log files (&gt; 30 days by default) in Delta Lake tables.
Each time a checkpoint is written, Databricks automatically cleans up log entries older than this retention interval.</p>
<p>While Delta Lake versioning and time travel are great for querying recent versions and rolling back queries, keeping the data files for all versions of large production tables around indefinitely is very expensive (and can lead to compliance issues if PII is present).</p>
<p>If you wish to manually purge old data files, this can be performed with the <strong><code>VACUUM</code></strong> operation.</p>
<p>Uncomment the following cell and execute it with a retention of <strong><code>0 HOURS</code></strong> to keep only the current version:</p>
<p>By default, <strong><code>VACUUM</code></strong> will prevent you from deleting files less than 7 days old, just to ensure that no long-running operations are still referencing any of the files to be deleted. If you run <strong><code>VACUUM</code></strong> on a Delta table, you lose the ability time travel back to a version older than the specified data retention period.  In our demos, you may see Databricks executing code that specifies a retention of <strong><code>0 HOURS</code></strong>. This is simply to demonstrate the feature and is not typically done in production.  </p>
<p>In the following cell, we:
1. Turn off a check to prevent premature deletion of data files
2. Make sure that logging of <strong><code>VACUUM</code></strong> commands is enabled
3. Use the <strong><code>DRY RUN</code></strong> version of vacuum to print out all records to be deleted</p>
<p>To disable the retention duration of 0 safety mechanism just enable these parameters to false and true.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-93-1" name="__codelineno-93-1" href="#__codelineno-93-1"></a><span class="k">SET</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">databricks</span><span class="p">.</span><span class="n">delta</span><span class="p">.</span><span class="n">retentionDurationCheck</span><span class="p">.</span><span class="n">enabled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">false</span><span class="p">;</span>
<a id="__codelineno-93-2" name="__codelineno-93-2" href="#__codelineno-93-2"></a><span class="k">SET</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">databricks</span><span class="p">.</span><span class="n">delta</span><span class="p">.</span><span class="k">vacuum</span><span class="p">.</span><span class="n">logging</span><span class="p">.</span><span class="n">enabled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">true</span><span class="p">;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-94-1" name="__codelineno-94-1" href="#__codelineno-94-1"></a><span class="k">VACUUM</span><span class="w"> </span><span class="n">students</span><span class="w"> </span><span class="n">RETAIN</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">HOURS</span><span class="w"> </span><span class="n">DRY</span><span class="w"> </span><span class="n">RUN</span>
</code></pre></div>
<p>By vacuuming the files, we are permanantly deleting the versions of the files and we cannot get it back.</p>
<p>After deletion, only the delta file with log of transactions remains.</p>
<h3 id="data-pipelines-with-delta-live-tables">Data Pipelines with Delta Live Tables</h3>
<h4 id="the-medallion-architecture">The Medallion Architecture</h4>
<p><img alt="Alt text" src="../image-102.png" /></p>
<h5 id="the-bronze-layer">The Bronze Layer</h5>
<p><img alt="Alt text" src="../image-103.png" /></p>
<h5 id="the-silver-layer">The Silver Layer</h5>
<p><img alt="Alt text" src="../image-104.png" /></p>
<h5 id="the-gold-layer">The Gold Layer</h5>
<p><img alt="Alt text" src="../image-105.png" /></p>
<h4 id="the-multi-hop-architecture">The Multi Hop Architecture</h4>
<p><img alt="Alt text" src="../image-106.png" /></p>
<h4 id="how-dlt-solves-problems">How DLT Solves Problems</h4>
<p>Usually the bronze, silver and gold layers will not be in a linear dependency format.
<img alt="Alt text" src="../image-107.png" /></p>
<h4 id="what-exactly-is-a-live-table">What exactly is a live table?</h4>
<p><img alt="Alt text" src="../image-108.png" /></p>
<p><strong>Streaming Live Tables</strong>
<img alt="Alt text" src="../image-109.png" /></p>
<h4 id="steps-to-create-a-dlt-pipeline">Steps to Create a DLT Pipeline</h4>
<p><img alt="Alt text" src="../image-110.png" /></p>
<h4 id="development-vs-production-pipelines">Development Vs Production pipelines</h4>
<p><img alt="Alt text" src="../image-111.png" /></p>
<p>We use job clusters in prod pipelines.</p>
<p>Hence if the pipeline in the prod needs to be run multiple times, then the cluster object has to be created multiple times.</p>
<p>But in the case of dev pipeines, we can keep the clusters running for faster debugging.</p>
<h4 id="dependencies-in-the-pipeline">Dependencies in the Pipeline</h4>
<p><img alt="Alt text" src="../image-112.png" /></p>
<p>All the tables in the pipeline have the same LIVE schema, so we need to mention the keyword <code>LIVE.events</code></p>
<p>This feature allows us to migrate the pipelines between databases in the environment.</p>
<p>When we are moving from dev to prod, then just change the schema from dev to prod and we can migrate very quickly.</p>
<h4 id="data-quality-with-expectations">Data Quality with Expectations</h4>
<p><img alt="Alt text" src="../image-113.png" /></p>
<h4 id="why-event-logs-are-important">Why Event Logs are Important</h4>
<p><img alt="Alt text" src="../image-114.png" /></p>
<h4 id="spark-structured-streaming-ingest-from-cloud">Spark Structured Streaming [Ingest From Cloud]</h4>
<p><img alt="Alt text" src="../image-115.png" /></p>
<h4 id="streaming-from-an-existing-table">Streaming from an existing table</h4>
<p><img alt="Alt text" src="../image-116.png" />
Usally the table that we are streaming from has data coming in from Kafka/Kinesis.</p>
<h4 id="parameters-in-dlt">Parameters in DLT</h4>
<p><img alt="Alt text" src="../image-117.png" /></p>
<h4 id="change-data-capture">Change Data Capture</h4>
<p><img alt="Alt text" src="../image-118.png" />
Here the source is <code>city_updates</code> and it must be a stream.</p>
<p>We need unique key like id that can idenitify the data that can be included in teh updates
A sequence no is required to apply changes in the current order.</p>
<p><strong>Example</strong>
<img alt="Alt text" src="../image-119.png" />
Initially cities table is empty, here we can see that berkley was misspelled in the first entry of city_updates table, so when we fix it by keeping the same id and different timestamp its updated in the cities table also.</p>
<h4 id="what-does-dlt-automate">What does DLT automate?</h4>
<p><img alt="Alt text" src="../image-120.png" /></p>
<h3 id="creating-pipelines">Creating Pipelines</h3>
<ol>
<li>
<p>Setup the parameters like in the <a href="">Delta Live Tables UI Notebook</a>.</p>
</li>
<li>
<p>Then click '+' -&gt; New DLT Pipeline.</p>
</li>
<li>
<p>Create the pipeline using the steps mentioned <a href="https://adb-6109119110541327.7.azuredatabricks.net/?o=6109119110541327#notebook/2951115793282683/command/2951115793282684">here</a></p>
</li>
<li>
<p>This is the final pipeline config <a href="https://adb-6109119110541327.7.azuredatabricks.net/?o=6109119110541327#joblist/pipelines/create">link</a></p>
</li>
<li>
<p>This is the final dashboard
<img alt="Alt text" src="../image-121.png" /></p>
</li>
</ol>
<p>In prod mode we delete the cluster resources after the pipeline completes.</p>
<p>I cannot run the pipelines due to restrictions in student account.
<img alt="Alt text" src="../image-122.png" /></p>
<p>Here is the snapshot of the running pipeline from the course.
<img alt="Alt text" src="../image-123.png" /></p>
<h3 id="fundamental-dlt-sql-syntax">Fundamental DLT SQL Syntax</h3>
<p>This notebook demonstrates using Delta Live Tables (DLT) to process raw data from JSON files landing in cloud object storage through a series of tables to drive analytic workloads in the lakehouse. Here we demonstrate a medallion architecture, where data is incrementally transformed and enriched as it flows through a pipeline. This notebook focuses on the SQL syntax of DLT rather than this architecture, but a brief overview of the design:</p>
<ul>
<li>The bronze table contains raw records loaded from JSON enriched with data describing how records were ingested</li>
<li>The silver table validates and enriches the fields of interest</li>
<li>The gold table contains aggregate data to drive business insights and dashboarding</li>
</ul>
<p>DLT syntax is not intended for interactive execution in a notebook. This notebook will need to be scheduled as part of a DLT pipeline for proper execution. </p>
<p>If you do execute a DLT notebook cell interactively, you should see a message that your statement is syntactically valid. Note that while some syntax checks are performed before returning this message, it is not a guarantee that your query will perform as desired. We'll discuss developing and troubleshooting DLT code later in the course.</p>
<p>Delta Live Tables adapts standard SQL queries to combine DDL (data definition language) and DML (data manipulation language) into a unified declarative syntax.</p>
<h4 id="table-as-query-results">Table as Query Results</h4>
<p>There are two distinct types of persistent tables that can be created with DLT:
* <strong>Live tables</strong> are materialized views for the lakehouse; they will return the current results of any query with each refresh
* <strong>Streaming live tables</strong> are designed for incremental, near-real time data processing</p>
<p>Note that both of these objects are persisted as tables stored with the Delta Lake protocol (providing ACID transactions, versioning, and many other benefits). We'll talk more about the differences between live tables and streaming live tables later in the notebook.</p>
<h4 id="auto-loader">Auto Loader</h4>
<p>Databricks has developed the <a href="https://docs.databricks.com/ingestion/auto-loader/index.html">Auto Loader</a> functionality to provide optimized execution for incrementally loading data from cloud object storage into Delta Lake. Using Auto Loader with DLT is simple: just configure a source data directory, provide a few configuration settings, and write a query against your source data. </p>
<p>Auto Loader will automatically detect new data files as they land in the source cloud object storage location, incrementally processing new records without the need to perform expensive scans and recomputing results for infinitely growing datasets.</p>
<p>The <strong><code>cloud_files()</code></strong> method enables Auto Loader to be used natively with SQL. This method takes the following positional parameters:</p>
<ul>
<li>The source location, which should be cloud-based object storage</li>
<li>The source data format, which is JSON in this case</li>
<li>An arbitrarily sized comma-separated list of optional reader options. In this case, we set <strong><code>cloudFiles.inferColumnTypes</code></strong> to <strong><code>true</code></strong></li>
</ul>
<p>In the query below, in addition to the fields contained in the source, Spark SQL functions for the <strong><code>current_timestamp()</code></strong> and <strong><code>input_file_name()</code></strong> as used to capture information about when the record was ingested and the specific file source for each record.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-95-1" name="__codelineno-95-1" href="#__codelineno-95-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">orders_bronze</span>
<a id="__codelineno-95-2" name="__codelineno-95-2" href="#__codelineno-95-2"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="n">processing_time</span><span class="p">,</span><span class="w"> </span><span class="n">input_file_name</span><span class="p">()</span><span class="w"> </span><span class="n">source_file</span><span class="p">,</span><span class="w"> </span><span class="o">*</span>
<a id="__codelineno-95-3" name="__codelineno-95-3" href="#__codelineno-95-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span><span class="ss">&quot;${source}/orders&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;json&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">map</span><span class="p">(</span><span class="ss">&quot;cloudFiles.inferColumnTypes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;true&quot;</span><span class="p">))</span>
</code></pre></div>
<h3 id="validating-and-enriching-the-data">Validating and Enriching the Data</h3>
<p>The select statement contains the core logic of your query. In this example, we:
* Cast the field <strong><code>order_timestamp</code></strong> to the timestamp type
* Select all of the remaining fields (except a list of 3 we're not interested in, including the original <strong><code>order_timestamp</code></strong>)</p>
<p>Note that the <strong><code>FROM</code></strong> clause has two constructs that you may not be familiar with:
* The <strong><code>LIVE</code></strong> keyword is used in place of the schema name to refer to the target schema configured for the current DLT pipeline
* The <strong><code>STREAM</code></strong> method allows users to declare a streaming data source for SQL queries</p>
<p>Note that if no target schema is declared during pipeline configuration, your tables won't be published (that is, they won't be registered to the metastore and made available for queries elsewhere). </p>
<p>The target schema can be easily changed when moving between different execution environments, meaning the same code can easily be deployed against regional workloads or promoted from a dev to prod environment without needing to hard-code schema names.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-96-1" name="__codelineno-96-1" href="#__codelineno-96-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">orders_silver</span>
<a id="__codelineno-96-2" name="__codelineno-96-2" href="#__codelineno-96-2"></a><span class="p">(</span><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_date</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span><span class="n">order_timestamp</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="ss">&quot;2021-01-01&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">VIOLATION</span><span class="w"> </span><span class="n">FAIL</span><span class="w"> </span><span class="k">UPDATE</span><span class="p">)</span>
<a id="__codelineno-96-3" name="__codelineno-96-3" href="#__codelineno-96-3"></a><span class="k">COMMENT</span><span class="w"> </span><span class="ss">&quot;Append only orders with valid timestamps&quot;</span>
<a id="__codelineno-96-4" name="__codelineno-96-4" href="#__codelineno-96-4"></a><span class="n">TBLPROPERTIES</span><span class="w"> </span><span class="p">(</span><span class="ss">&quot;quality&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;silver&quot;</span><span class="p">)</span>
<a id="__codelineno-96-5" name="__codelineno-96-5" href="#__codelineno-96-5"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="k">timestamp</span><span class="p">(</span><span class="n">order_timestamp</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">order_timestamp</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">EXCEPT</span><span class="w"> </span><span class="p">(</span><span class="n">order_timestamp</span><span class="p">,</span><span class="w"> </span><span class="n">source_file</span><span class="p">,</span><span class="w"> </span><span class="n">_rescued_data</span><span class="p">)</span>
<a id="__codelineno-96-6" name="__codelineno-96-6" href="#__codelineno-96-6"></a><span class="k">FROM</span><span class="w"> </span><span class="n">STREAM</span><span class="p">(</span><span class="n">LIVE</span><span class="p">.</span><span class="n">orders_bronze</span><span class="p">)</span>
</code></pre></div>
<p>Here, in the end of the statement, we have <code>LIVE.orders_bronze</code>. We have to specify <code>LIVE.</code> because it refers to the target schema that we defined before in the configuration settings.</p>
<p>The table <code>order_silver</code> is a STREAMING table becuase it takes in data from another streaming table <code>orders_bronze</code></p>
<p>If the expectation fails, then we can have two main choices <code>UPDATE</code> will drop all the rows that were part of the insertion even if only one row fails the constraint.</p>
<p>If we use <code>ROW</code> then it drops only the row that failed the update</p>
<h3 id="live-tables-vs-streaming-live-tables">Live Tables vs. Streaming Live Tables ⚠️</h3>
<p>Below are some of the differences between these types of tables.</p>
<p>Live Tables</p>
<ul>
<li>Always "correct", meaning their contents will match their definition after any update.</li>
<li>Return same results as if table had just been defined for first time on all data.</li>
<li>Should not be modified by operations external to the DLT Pipeline (you'll either get undefined answers or your change will just be undone).</li>
</ul>
<p>Streaming Live Tables</p>
<ul>
<li>Only supports reading from "append-only" streaming sources.</li>
<li>Only reads each input batch once, no matter what (even if joined dimensions change, or if the query definition changes, etc).</li>
<li>Can perform operations on the table outside the managed DLT Pipeline (append data, perform GDPR, etc).</li>
</ul>
<p>A live table or view always reflects the results of the query that defines it, including when the query defining the table or view is updated, or an input data source is updated. Like a traditional materialized view, a live table or view may be entirely computed when possible to optimize computation resources and time.</p>
<p>A streaming live table or view processes data that has been added only since the last pipeline update. Streaming tables and views are stateful; if the defining query changes, new data will be processed based on the new query and existing data is not recomputed.</p>
<h3 id="creating-the-gold-layer">Creating The Gold Layer</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-97-1" name="__codelineno-97-1" href="#__codelineno-97-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">orders_by_date</span>
<a id="__codelineno-97-2" name="__codelineno-97-2" href="#__codelineno-97-2"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="nb">date</span><span class="p">(</span><span class="n">order_timestamp</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">order_date</span><span class="p">,</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">total_daily_orders</span>
<a id="__codelineno-97-3" name="__codelineno-97-3" href="#__codelineno-97-3"></a><span class="k">FROM</span><span class="w"> </span><span class="n">LIVE</span><span class="p">.</span><span class="n">orders_silver</span>
<a id="__codelineno-97-4" name="__codelineno-97-4" href="#__codelineno-97-4"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="nb">date</span><span class="p">(</span><span class="n">order_timestamp</span><span class="p">)</span>
</code></pre></div>
<h3 id="orders-pipeline-in-python">Orders Pipeline in Python</h3>
<h4 id="importing-the-libraries">Importing the libraries</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-98-1" name="__codelineno-98-1" href="#__codelineno-98-1"></a><span class="n">import</span><span class="w"> </span><span class="n">dlt</span>
<a id="__codelineno-98-2" name="__codelineno-98-2" href="#__codelineno-98-2"></a><span class="n">import</span><span class="w"> </span><span class="n">pyspark</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">functions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">F</span>
<a id="__codelineno-98-3" name="__codelineno-98-3" href="#__codelineno-98-3"></a>
<a id="__codelineno-98-4" name="__codelineno-98-4" href="#__codelineno-98-4"></a><span class="k">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">conf</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="ss">&quot;source&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="creating-the-bronze-table">Creating the Bronze Table</h4>
<p>Delta Live Tables introduces a number of new Python functions that extend familiar PySpark APIs.</p>
<p>At the heart of this design, the decorator <strong><code>@dlt.table</code></strong> is added to any Python function that returns a Spark DataFrame. (<strong>NOTE</strong>: This includes Koalas DataFrames, but these won't be covered in this course.)</p>
<p>If you're used to working with Spark and/or Structured Streaming, you'll recognize the majority of the syntax used in DLT. The big difference is that you'll never see any methods or options for DataFrame writers, as this logic is handled by DLT.</p>
<p>As such, the basic form of a DLT table definition will look like:</p>
<p><strong><code>@dlt.table</code></strong><br/>
<strong><code>def &lt;function-name&gt;():</code></strong><br/>
<strong><code>return (&lt;query&gt;)</code></strong></br></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-99-1" name="__codelineno-99-1" href="#__codelineno-99-1"></a><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<a id="__codelineno-99-2" name="__codelineno-99-2" href="#__codelineno-99-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">orders_bronze</span><span class="p">():</span>
<a id="__codelineno-99-3" name="__codelineno-99-3" href="#__codelineno-99-3"></a>    <span class="k">return</span> <span class="p">(</span>
<a id="__codelineno-99-4" name="__codelineno-99-4" href="#__codelineno-99-4"></a>        <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span>
<a id="__codelineno-99-5" name="__codelineno-99-5" href="#__codelineno-99-5"></a>            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
<a id="__codelineno-99-6" name="__codelineno-99-6" href="#__codelineno-99-6"></a>            <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span>
<a id="__codelineno-99-7" name="__codelineno-99-7" href="#__codelineno-99-7"></a>            <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.inferColumnTypes&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-99-8" name="__codelineno-99-8" href="#__codelineno-99-8"></a>            <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">/orders&quot;</span><span class="p">)</span>
<a id="__codelineno-99-9" name="__codelineno-99-9" href="#__codelineno-99-9"></a>            <span class="o">.</span><span class="n">select</span><span class="p">(</span>
<a id="__codelineno-99-10" name="__codelineno-99-10" href="#__codelineno-99-10"></a>                <span class="n">F</span><span class="o">.</span><span class="n">current_timestamp</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;processing_time&quot;</span><span class="p">),</span> 
<a id="__codelineno-99-11" name="__codelineno-99-11" href="#__codelineno-99-11"></a>                <span class="n">F</span><span class="o">.</span><span class="n">input_file_name</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;source_file&quot;</span><span class="p">),</span> 
<a id="__codelineno-99-12" name="__codelineno-99-12" href="#__codelineno-99-12"></a>                <span class="s2">&quot;*&quot;</span>
<a id="__codelineno-99-13" name="__codelineno-99-13" href="#__codelineno-99-13"></a>            <span class="p">)</span>
<a id="__codelineno-99-14" name="__codelineno-99-14" href="#__codelineno-99-14"></a>    <span class="p">)</span>
</code></pre></div>
<h4 id="creating-the-silver-table">Creating the Silver Table</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-100-1" name="__codelineno-100-1" href="#__codelineno-100-1"></a><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">(</span>
<a id="__codelineno-100-2" name="__codelineno-100-2" href="#__codelineno-100-2"></a>    <span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;Append only orders with valid timestamps&quot;</span><span class="p">,</span>
<a id="__codelineno-100-3" name="__codelineno-100-3" href="#__codelineno-100-3"></a>    <span class="n">table_properties</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;quality&quot;</span><span class="p">:</span> <span class="s2">&quot;silver&quot;</span><span class="p">})</span>
<a id="__codelineno-100-4" name="__codelineno-100-4" href="#__codelineno-100-4"></a><span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_or_fail</span><span class="p">(</span><span class="s2">&quot;valid_date&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;order_timestamp&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="s2">&quot;2021-01-01&quot;</span><span class="p">)</span>
<a id="__codelineno-100-5" name="__codelineno-100-5" href="#__codelineno-100-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">orders_silver</span><span class="p">():</span>
<a id="__codelineno-100-6" name="__codelineno-100-6" href="#__codelineno-100-6"></a>    <span class="k">return</span> <span class="p">(</span>
<a id="__codelineno-100-7" name="__codelineno-100-7" href="#__codelineno-100-7"></a>        <span class="n">dlt</span><span class="o">.</span><span class="n">read_stream</span><span class="p">(</span><span class="s2">&quot;orders_bronze&quot;</span><span class="p">)</span>
<a id="__codelineno-100-8" name="__codelineno-100-8" href="#__codelineno-100-8"></a>            <span class="o">.</span><span class="n">select</span><span class="p">(</span>
<a id="__codelineno-100-9" name="__codelineno-100-9" href="#__codelineno-100-9"></a>                <span class="s2">&quot;processing_time&quot;</span><span class="p">,</span>
<a id="__codelineno-100-10" name="__codelineno-100-10" href="#__codelineno-100-10"></a>                <span class="s2">&quot;customer_id&quot;</span><span class="p">,</span>
<a id="__codelineno-100-11" name="__codelineno-100-11" href="#__codelineno-100-11"></a>                <span class="s2">&quot;notifications&quot;</span><span class="p">,</span>
<a id="__codelineno-100-12" name="__codelineno-100-12" href="#__codelineno-100-12"></a>                <span class="s2">&quot;order_id&quot;</span><span class="p">,</span>
<a id="__codelineno-100-13" name="__codelineno-100-13" href="#__codelineno-100-13"></a>                <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;order_timestamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;timestamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;order_timestamp&quot;</span><span class="p">)</span>
<a id="__codelineno-100-14" name="__codelineno-100-14" href="#__codelineno-100-14"></a>            <span class="p">)</span>
<a id="__codelineno-100-15" name="__codelineno-100-15" href="#__codelineno-100-15"></a>    <span class="p">)</span>
</code></pre></div>
<h4 id="defining-the-gold-table">Defining the Gold Table</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-101-1" name="__codelineno-101-1" href="#__codelineno-101-1"></a><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<a id="__codelineno-101-2" name="__codelineno-101-2" href="#__codelineno-101-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">orders_by_date</span><span class="p">():</span>
<a id="__codelineno-101-3" name="__codelineno-101-3" href="#__codelineno-101-3"></a>    <span class="k">return</span> <span class="p">(</span>
<a id="__codelineno-101-4" name="__codelineno-101-4" href="#__codelineno-101-4"></a>        <span class="n">dlt</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;orders_silver&quot;</span><span class="p">)</span>
<a id="__codelineno-101-5" name="__codelineno-101-5" href="#__codelineno-101-5"></a>            <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;order_timestamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;order_date&quot;</span><span class="p">))</span>
<a id="__codelineno-101-6" name="__codelineno-101-6" href="#__codelineno-101-6"></a>            <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_daily_orders&quot;</span><span class="p">))</span>
<a id="__codelineno-101-7" name="__codelineno-101-7" href="#__codelineno-101-7"></a>    <span class="p">)</span>
</code></pre></div>
<h3 id="customers-pipeline">Customers Pipeline</h3>
<h3 id="objectives">Objectives</h3>
<ul>
<li>Raw records represent change data capture (CDC) information about customers </li>
<li>The bronze table again uses Auto Loader to ingest JSON data from cloud object storage</li>
<li>A table is defined to enforce constraints before passing records to the silver layer</li>
<li><strong><code>APPLY CHANGES INTO</code></strong> is used to automatically process CDC data into the silver layer as a Type 1 <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank">slowly changing dimension (SCD) table<a/></li>
<li>A gold table is defined to calculate an aggregate from the current version of this Type 1 table</li>
<li>A view is defined that joins with tables defined in another notebook</li>
</ul>
<h4 id="what-are-slowly-changing-dimensions">What are Slowly Changing Dimensions?</h4>
<p>A slowly changing dimension (SCD) in data management and data warehousing is a dimension which contains relatively static data which can change slowly but unpredictably, rather than according to a regular schedule. Some examples of typical slowly changing dimensions are entities such as names of geographical locations, customers, or products.</p>
<h4 id="type-1-scd">Type 1 SCD</h4>
<p><img alt="Alt text" src="../image-124.png" /></p>
<h4 id="ingest-data-with-auto-loader">Ingest Data with Auto Loader</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-102-1" name="__codelineno-102-1" href="#__codelineno-102-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers_bronze</span>
<a id="__codelineno-102-2" name="__codelineno-102-2" href="#__codelineno-102-2"></a><span class="k">COMMENT</span><span class="w"> </span><span class="ss">&quot;Raw data from customers CDC feed&quot;</span>
<a id="__codelineno-102-3" name="__codelineno-102-3" href="#__codelineno-102-3"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="n">processing_time</span><span class="p">,</span><span class="w"> </span><span class="n">input_file_name</span><span class="p">()</span><span class="w"> </span><span class="n">source_file</span><span class="p">,</span><span class="w"> </span><span class="o">*</span>
<a id="__codelineno-102-4" name="__codelineno-102-4" href="#__codelineno-102-4"></a><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span><span class="ss">&quot;${source}/customers&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;json&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="quality-checks">Quality Checks</h4>
<p>The query below demonstrates:
* The 3 options for behavior when constraints are violated
* A query with multiple constraints
* Multiple conditions provided to one constraint
* Using a built-in SQL function in a constraint</p>
<p>About the data source:
* Data is a CDC feed that contains <strong><code>INSERT</code></strong>, <strong><code>UPDATE</code></strong>, and <strong><code>DELETE</code></strong> operations. 
* Update and insert operations should contain valid entries for all fields.
* Delete operations should contain <strong><code>NULL</code></strong> values for all fields other than the timestamp, <strong><code>customer_id</code></strong>, and operation fields.</p>
<p>In order to ensure only good data makes it into our silver table, we'll write a series of quality enforcement rules that ignore the expected null values in delete operations.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-103-1" name="__codelineno-103-1" href="#__codelineno-103-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers_bronze_clean</span>
<a id="__codelineno-103-2" name="__codelineno-103-2" href="#__codelineno-103-2"></a><span class="p">(</span><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_id</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span><span class="n">customer_id</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="p">)</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">VIOLATION</span><span class="w"> </span><span class="n">FAIL</span><span class="w"> </span><span class="k">UPDATE</span><span class="p">,</span>
<a id="__codelineno-103-3" name="__codelineno-103-3" href="#__codelineno-103-3"></a><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_operation</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span><span class="k">operation</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="p">)</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">VIOLATION</span><span class="w"> </span><span class="k">DROP</span><span class="w"> </span><span class="k">ROW</span><span class="p">,</span>
<a id="__codelineno-103-4" name="__codelineno-103-4" href="#__codelineno-103-4"></a><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_name</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;DELETE&quot;</span><span class="p">),</span>
<a id="__codelineno-103-5" name="__codelineno-103-5" href="#__codelineno-103-5"></a><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_address</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-103-6" name="__codelineno-103-6" href="#__codelineno-103-6"></a><span class="w">  </span><span class="p">(</span><span class="n">address</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">and</span><span class="w"> </span>
<a id="__codelineno-103-7" name="__codelineno-103-7" href="#__codelineno-103-7"></a><span class="w">  </span><span class="n">city</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">and</span><span class="w"> </span>
<a id="__codelineno-103-8" name="__codelineno-103-8" href="#__codelineno-103-8"></a><span class="w">  </span><span class="k">state</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="w"> </span><span class="k">and</span><span class="w"> </span>
<a id="__codelineno-103-9" name="__codelineno-103-9" href="#__codelineno-103-9"></a><span class="w">  </span><span class="n">zip_code</span><span class="w"> </span><span class="k">IS</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">NULL</span><span class="p">)</span><span class="w"> </span><span class="k">or</span>
<a id="__codelineno-103-10" name="__codelineno-103-10" href="#__codelineno-103-10"></a><span class="w">  </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;DELETE&quot;</span><span class="p">),</span>
<a id="__codelineno-103-11" name="__codelineno-103-11" href="#__codelineno-103-11"></a><span class="k">CONSTRAINT</span><span class="w"> </span><span class="n">valid_email</span><span class="w"> </span><span class="n">EXPECT</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-103-12" name="__codelineno-103-12" href="#__codelineno-103-12"></a><span class="w">  </span><span class="n">rlike</span><span class="p">(</span><span class="n">email</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;^([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})$&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">or</span><span class="w"> </span>
<a id="__codelineno-103-13" name="__codelineno-103-13" href="#__codelineno-103-13"></a><span class="w">  </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;DELETE&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">VIOLATION</span><span class="w"> </span><span class="k">DROP</span><span class="w"> </span><span class="k">ROW</span><span class="p">)</span>
<a id="__codelineno-103-14" name="__codelineno-103-14" href="#__codelineno-103-14"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span>
<a id="__codelineno-103-15" name="__codelineno-103-15" href="#__codelineno-103-15"></a><span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">STREAM</span><span class="p">(</span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_bronze</span><span class="p">)</span>
</code></pre></div>
<h4 id="requirements-that-apply-changes-into-provides">Requirements that <code>APPLY CHANGES INTO</code> Provides</h4>
<ul>
<li>
<p>Performs incremental/streaming ingestion of CDC data.</p>
</li>
<li>
<p>Provides simple syntax to specify one or many fields as the primary key for a table.</p>
</li>
<li>
<p>Default assumption is that rows will contain inserts and updates.</p>
</li>
<li>
<p>Can optionally apply deletes.</p>
</li>
<li>
<p>Automatically orders late-arriving records using user-provided sequencing key.</p>
</li>
<li>
<p>Uses a simple syntax for specifying columns to ignore with the <strong><code>EXCEPT</code></strong> keyword.</p>
</li>
<li>
<p>Will default to applying changes as Type 1 SCD.</p>
</li>
</ul>
<h4 id="processing-cdc-data-from-bronze_cleaned-to-customers_silver-table">Processing CDC Data From <code>bronze_cleaned</code> to <code>customers_silver</code> table</h4>
<ul>
<li>
<p>Creates the <strong><code>customers_silver</code></strong> table; <strong><code>APPLY CHANGES INTO</code></strong> requires the target table to be declared in a separate statement.</p>
</li>
<li>
<p>Identifies the <strong><code>customers_silver</code></strong> table as the target into which the changes will be applied.</p>
</li>
<li>
<p>Specifies the table <strong><code>customers_bronze_clean</code></strong> as the streaming source.</p>
</li>
<li>
<p>Identifies the <strong><code>customer_id</code></strong> as the primary key.</p>
</li>
<li>
<p>Specifies that records where the <strong><code>operation</code></strong> field is <strong><code>DELETE</code></strong> should be applied as deletes.</p>
</li>
<li>
<p>Specifies the <strong><code>timestamp</code></strong> field for ordering how operations should be applied.</p>
</li>
<li>
<p>Indicates that all fields should be added to the target table except <strong><code>operation</code></strong>, <strong><code>source_file</code></strong>, and <strong><code>_rescued_data</code></strong>.</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-104-1" name="__codelineno-104-1" href="#__codelineno-104-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers_silver</span><span class="p">;</span>
<a id="__codelineno-104-2" name="__codelineno-104-2" href="#__codelineno-104-2"></a>
<a id="__codelineno-104-3" name="__codelineno-104-3" href="#__codelineno-104-3"></a><span class="n">APPLY</span><span class="w"> </span><span class="n">CHANGES</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_silver</span><span class="o">`</span><span class="w"> </span><span class="o">`</span>
<a id="__codelineno-104-4" name="__codelineno-104-4" href="#__codelineno-104-4"></a><span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">STREAM</span><span class="p">(</span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_bronze_clean</span><span class="p">)</span>
<a id="__codelineno-104-5" name="__codelineno-104-5" href="#__codelineno-104-5"></a><span class="w">  </span><span class="n">KEYS</span><span class="w"> </span><span class="p">(</span><span class="n">customer_id</span><span class="p">)</span>
<a id="__codelineno-104-6" name="__codelineno-104-6" href="#__codelineno-104-6"></a><span class="w">  </span><span class="n">APPLY</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">DELETE</span><span class="w"> </span><span class="k">WHEN</span><span class="w"> </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;DELETE&quot;</span>
<a id="__codelineno-104-7" name="__codelineno-104-7" href="#__codelineno-104-7"></a><span class="w">  </span><span class="n">SEQUENCE</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="k">timestamp</span>
<a id="__codelineno-104-8" name="__codelineno-104-8" href="#__codelineno-104-8"></a><span class="w">  </span><span class="n">COLUMNS</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">EXCEPT</span><span class="w"> </span><span class="p">(</span><span class="k">operation</span><span class="p">,</span><span class="w"> </span><span class="n">source_file</span><span class="p">,</span><span class="w"> </span><span class="n">_rescued_data</span><span class="p">)</span>
</code></pre></div>
<h3 id="querying-tables-with-applied-changes">Querying Tables with Applied Changes</h3>
<h4 id="why-downstream-table-cant-perform-streaming-operations">Why Downstream Table Can't Perform Streaming Operations?</h4>
<p>While the target of our operation in the previous cell was defined as a streaming live table, data is being updated and deleted in this table (and so breaks the append-only requirements for streaming live table sources). As such, downstream operations cannot perform streaming queries against this table. </p>
<p>This pattern ensures that if any updates arrive out of order, downstream results can be properly recomputed to reflect updates. It also ensures that when records are deleted from a source table, these values are no longer reflected in tables later in the pipeline.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-105-1" name="__codelineno-105-1" href="#__codelineno-105-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="n">LIVE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customer_counts_state</span>
<a id="__codelineno-105-2" name="__codelineno-105-2" href="#__codelineno-105-2"></a><span class="w">  </span><span class="k">COMMENT</span><span class="w"> </span><span class="ss">&quot;Total active customers per state&quot;</span>
<a id="__codelineno-105-3" name="__codelineno-105-3" href="#__codelineno-105-3"></a><span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="k">state</span><span class="p">,</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">customer_count</span><span class="p">,</span><span class="w"> </span><span class="k">current_timestamp</span><span class="p">()</span><span class="w"> </span><span class="n">updated_at</span>
<a id="__codelineno-105-4" name="__codelineno-105-4" href="#__codelineno-105-4"></a><span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">LIVE</span><span class="p">.</span><span class="n">customers_silver</span>
<a id="__codelineno-105-5" name="__codelineno-105-5" href="#__codelineno-105-5"></a><span class="w">  </span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="k">state</span>
</code></pre></div>
<h3 id="views-in-dlt">Views in DLT</h3>
<p>The query below defines a DLT view by replacing <strong><code>TABLE</code></strong> with the <strong><code>VIEW</code></strong> keyword.</p>
<p>Views in DLT differ from persisted tables, and can optionally be defined as <strong><code>STREAMING</code></strong>.</p>
<p>Views have the same update guarantees as live tables, but the results of queries are not stored to disk.</p>
<p>Unlike views used elsewhere in Databricks, DLT views are not persisted to the metastore, meaning that they can only be referenced from within the DLT pipeline they are a part of. (This is similar scoping to temporary views in most SQL systems.)</p>
<p>Views can still be used to enforce data quality, and metrics for views will be collected and reported as they would be for tables.</p>
<h3 id="joining-and-referencing-tables">Joining and Referencing Tables</h3>
<p>In the query below, we create a new view by joining the silver tables from our <strong><code>orders</code></strong> and <strong><code>customers</code></strong> datasets. Note that this view is not defined as streaming; as such, we will always capture the current valid <strong><code>email</code></strong> for each customer, and will automatically drop records for customers after they've been deleted from the <strong><code>customers_silver</code></strong> table.</p>
<h3 id="final-pipeline">Final Pipeline</h3>
<p><img alt="Alt text" src="../image-125.png" /></p>
<h3 id="python-vs-sql">Python vs SQL</h3>
<p><img alt="Alt text" src="../image-126.png" /></p>
<h3 id="pipeline-results-and-internals-of-dlt">Pipeline Results and Internals of DLT</h3>
<h4 id="checking-list-of-all-tables">Checking List of All Tables</h4>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-106-1" name="__codelineno-106-1" href="#__codelineno-106-1"></a><span class="n">USE</span><span class="w"> </span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="k">schema_name</span><span class="err">}</span><span class="p">;</span>
<a id="__codelineno-106-2" name="__codelineno-106-2" href="#__codelineno-106-2"></a>
<a id="__codelineno-106-3" name="__codelineno-106-3" href="#__codelineno-106-3"></a><span class="k">SHOW</span><span class="w"> </span><span class="n">TABLES</span><span class="p">;</span>
</code></pre></div>
<img alt="Alt text" src="../image-127.png" /></p>
<h4 id="querying-orders-bronze-table">Querying Orders Bronze Table</h4>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-107-1" name="__codelineno-107-1" href="#__codelineno-107-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">orders_bronze</span>
</code></pre></div>
<img alt="Alt text" src="../image-128.png" />
Recall that <strong><code>orders_bronze</code></strong> was defined as a streaming live table in DLT, but our results here are static.</p>
<p>Because DLT uses Delta Lake to store all tables, each time a query is executed, we will always return the most recent version of the table. But queries outside of DLT will return snapshot results from DLT tables, regardless of how they were defined.</p>
<h4 id="querying-customers_silver-table">Querying <code>customers_silver</code> table</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-108-1" name="__codelineno-108-1" href="#__codelineno-108-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">customers_silver</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-129.png" /></p>
<p>This table dowes not have the additional fields like <code>__TimeStamp</code>, <code>__deleteVersion</code> and <code>__updateVersion</code>.</p>
<p>The customers_silver table is actually a view oof another hidden table called <code>__apply_changes_storage_customer_silver</code>.</p>
<p>This is seen when we run the describe command.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-109-1" name="__codelineno-109-1" href="#__codelineno-109-1"></a><span class="k">DESCRIBE</span><span class="w"> </span><span class="n">EXTENDED</span><span class="w"> </span><span class="n">customers_silver</span>
</code></pre></div>
<p>Its being read from the <code>__apply_changes_storage_customer_silver</code> table
<img alt="Alt text" src="../image-130.png" /></p>
<h4 id="checking-the-__apply_changes_storage_customer_silver-table-records">Checking the <code>__apply_changes_storage_customer_silver</code> table records</h4>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-110-1" name="__codelineno-110-1" href="#__codelineno-110-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">__apply_changes_storage_customers_silver</span>
</code></pre></div>
<img alt="Alt text" src="../image-131.png" /></p>
<h3 id="what-is-in-the-storage-location">What is in the storage location?</h3>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-111-1" name="__codelineno-111-1" href="#__codelineno-111-1"></a><span class="n">files</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">storage_location</span><span class="p">)</span>
<a id="__codelineno-111-2" name="__codelineno-111-2" href="#__codelineno-111-2"></a><span class="n">display</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div>
<img alt="Alt text" src="../image-132.png" /></p>
<p>The <strong>autoloader</strong> and <strong>checkpoint</strong> directories contain data used to manage incremental data processing with Structured Streaming.</p>
<p>The <strong>system</strong> directory captures events associated with the pipeline.</p>
<h4 id="event-logs">Event Logs</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-112-1" name="__codelineno-112-1" href="#__codelineno-112-1"></a><span class="n">files</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">storage_location</span><span class="si">}</span><span class="s2">/system/events&quot;</span><span class="p">)</span>
<a id="__codelineno-112-2" name="__codelineno-112-2" href="#__codelineno-112-2"></a><span class="n">display</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-133.png" /></p>
<p>Querying the Event Logs gives us lot of information</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-113-1" name="__codelineno-113-1" href="#__codelineno-113-1"></a><span class="n">display</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SELECT * FROM delta.`</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">storage_location</span><span class="si">}</span><span class="s2">/system/events`&quot;</span><span class="p">))</span>
</code></pre></div>
<img alt="Alt text" src="../image-134.png" /></p>
<p><img alt="Alt text" src="../image-135.png" /></p>
<h3 id="pipeline-event-logs-deep-dive">Pipeline Event Logs Deep Dive</h3>
<h4 id="query-the-event-log">Query the Event Log</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-114-1" name="__codelineno-114-1" href="#__codelineno-114-1"></a><span class="n">event_log_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DA</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">storage_location</span><span class="si">}</span><span class="s2">/system/events&quot;</span>
<a id="__codelineno-114-2" name="__codelineno-114-2" href="#__codelineno-114-2"></a>
<a id="__codelineno-114-3" name="__codelineno-114-3" href="#__codelineno-114-3"></a><span class="n">event_log</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;delta&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">event_log_path</span><span class="p">)</span>
<a id="__codelineno-114-4" name="__codelineno-114-4" href="#__codelineno-114-4"></a><span class="n">event_log</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;event_log_raw&quot;</span><span class="p">)</span>
<a id="__codelineno-114-5" name="__codelineno-114-5" href="#__codelineno-114-5"></a>
<a id="__codelineno-114-6" name="__codelineno-114-6" href="#__codelineno-114-6"></a><span class="n">display</span><span class="p">(</span><span class="n">event_log</span><span class="p">)</span>
</code></pre></div>
<p>The dataset includes an id for each transaction performed. </p>
<h4 id="check-the-latest-update-id">Check the Latest Update Id</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-115-1" name="__codelineno-115-1" href="#__codelineno-115-1"></a><span class="n">latest_update_id</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<a id="__codelineno-115-2" name="__codelineno-115-2" href="#__codelineno-115-2"></a><span class="s2">    SELECT origin.update_id</span>
<a id="__codelineno-115-3" name="__codelineno-115-3" href="#__codelineno-115-3"></a><span class="s2">    FROM event_log_raw</span>
<a id="__codelineno-115-4" name="__codelineno-115-4" href="#__codelineno-115-4"></a><span class="s2">    WHERE event_type = &#39;create_update&#39;</span>
<a id="__codelineno-115-5" name="__codelineno-115-5" href="#__codelineno-115-5"></a><span class="s2">    ORDER BY timestamp DESC LIMIT 1&quot;&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span><span class="o">.</span><span class="n">update_id</span>
<a id="__codelineno-115-6" name="__codelineno-115-6" href="#__codelineno-115-6"></a>
<a id="__codelineno-115-7" name="__codelineno-115-7" href="#__codelineno-115-7"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Latest Update ID: </span><span class="si">{</span><span class="n">latest_update_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-115-8" name="__codelineno-115-8" href="#__codelineno-115-8"></a>
<a id="__codelineno-115-9" name="__codelineno-115-9" href="#__codelineno-115-9"></a><span class="c1"># Push back into the spark config so that we can use it in a later query.</span>
<a id="__codelineno-115-10" name="__codelineno-115-10" href="#__codelineno-115-10"></a><span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s1">&#39;latest_update.id&#39;</span><span class="p">,</span> <span class="n">latest_update_id</span><span class="p">)</span>
</code></pre></div>
<h4 id="perform-audit-logging">Perform Audit Logging</h4>
<p>Events related to running pipelines and editing configurations are captured as <strong><code>user_action</code></strong>.</p>
<p>Yours should be the only <strong><code>user_name</code></strong> for the pipeline you configured during this lesson.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-116-1" name="__codelineno-116-1" href="#__codelineno-116-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="k">timestamp</span><span class="p">,</span><span class="w"> </span><span class="n">details</span><span class="p">:</span><span class="n">user_action</span><span class="p">:</span><span class="n">action</span><span class="p">,</span><span class="w"> </span><span class="n">details</span><span class="p">:</span><span class="n">user_action</span><span class="p">:</span><span class="n">user_name</span>
<a id="__codelineno-116-2" name="__codelineno-116-2" href="#__codelineno-116-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">event_log_raw</span><span class="w"> </span>
<a id="__codelineno-116-3" name="__codelineno-116-3" href="#__codelineno-116-3"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">event_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;user_action&#39;</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-136.png" /></p>
<h4 id="examining-data-lineage">Examining Data Lineage</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-117-1" name="__codelineno-117-1" href="#__codelineno-117-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">details</span><span class="p">:</span><span class="n">flow_definition</span><span class="p">.</span><span class="n">output_dataset</span><span class="p">,</span><span class="w"> </span><span class="n">details</span><span class="p">:</span><span class="n">flow_definition</span><span class="p">.</span><span class="n">input_datasets</span><span class="w"> </span>
<a id="__codelineno-117-2" name="__codelineno-117-2" href="#__codelineno-117-2"></a><span class="k">FROM</span><span class="w"> </span><span class="n">event_log_raw</span><span class="w"> </span>
<a id="__codelineno-117-3" name="__codelineno-117-3" href="#__codelineno-117-3"></a><span class="k">WHERE</span><span class="w"> </span><span class="n">event_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;flow_definition&#39;</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span>
<a id="__codelineno-117-4" name="__codelineno-117-4" href="#__codelineno-117-4"></a><span class="w">      </span><span class="n">origin</span><span class="p">.</span><span class="n">update_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;${latest_update.id}&#39;</span>
</code></pre></div>
<p>DLT provides built-in lineage information for how data flows through your table.</p>
<p>While the query below only indicates the direct predecessors for each table, this information can easily be combined to trace data in any table back to the point it entered the lakehouse.</p>
<p><img alt="Alt text" src="../image-137.png" /></p>
<p><img alt=" " src="../image-138.png" /></p>
<h4 id="checking-data-quality-metrics">Checking Data Quality Metrics ⚠️</h4>
<p>If you define expectations on datasets in your pipeline, the data quality metrics are stored in the details:flow_progress.data_quality.expectations object. Events containing information about data quality have the event type flow_progress. The following example queries the data quality metrics for the last pipeline update:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-118-1" name="__codelineno-118-1" href="#__codelineno-118-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">row_expectations</span><span class="p">.</span><span class="n">dataset</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">dataset</span><span class="p">,</span>
<a id="__codelineno-118-2" name="__codelineno-118-2" href="#__codelineno-118-2"></a><span class="w">       </span><span class="n">row_expectations</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">expectation</span><span class="p">,</span>
<a id="__codelineno-118-3" name="__codelineno-118-3" href="#__codelineno-118-3"></a><span class="w">       </span><span class="k">SUM</span><span class="p">(</span><span class="n">row_expectations</span><span class="p">.</span><span class="n">passed_records</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">passing_records</span><span class="p">,</span>
<a id="__codelineno-118-4" name="__codelineno-118-4" href="#__codelineno-118-4"></a><span class="w">       </span><span class="k">SUM</span><span class="p">(</span><span class="n">row_expectations</span><span class="p">.</span><span class="n">failed_records</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">failing_records</span>
<a id="__codelineno-118-5" name="__codelineno-118-5" href="#__codelineno-118-5"></a><span class="k">FROM</span>
<a id="__codelineno-118-6" name="__codelineno-118-6" href="#__codelineno-118-6"></a><span class="w">  </span><span class="p">(</span><span class="k">SELECT</span><span class="w"> </span><span class="n">explode</span><span class="p">(</span>
<a id="__codelineno-118-7" name="__codelineno-118-7" href="#__codelineno-118-7"></a><span class="w">            </span><span class="n">from_json</span><span class="p">(</span><span class="n">details</span><span class="w"> </span><span class="p">:</span><span class="n">flow_progress</span><span class="w"> </span><span class="p">:</span><span class="n">data_quality</span><span class="w"> </span><span class="p">:</span><span class="n">expectations</span><span class="p">,</span>
<a id="__codelineno-118-8" name="__codelineno-118-8" href="#__codelineno-118-8"></a><span class="w">                      </span><span class="ss">&quot;array&lt;struct&lt;name: string, dataset: string, passed_records: int, failed_records: int&gt;&gt;&quot;</span><span class="p">)</span>
<a id="__codelineno-118-9" name="__codelineno-118-9" href="#__codelineno-118-9"></a><span class="w">          </span><span class="p">)</span><span class="w"> </span><span class="n">row_expectations</span>
<a id="__codelineno-118-10" name="__codelineno-118-10" href="#__codelineno-118-10"></a><span class="w">   </span><span class="k">FROM</span><span class="w"> </span><span class="n">event_log_raw</span>
<a id="__codelineno-118-11" name="__codelineno-118-11" href="#__codelineno-118-11"></a><span class="w">   </span><span class="k">WHERE</span><span class="w"> </span><span class="n">event_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;flow_progress&#39;</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span>
<a id="__codelineno-118-12" name="__codelineno-118-12" href="#__codelineno-118-12"></a><span class="w">         </span><span class="n">origin</span><span class="p">.</span><span class="n">update_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;${latest_update.id}&#39;</span>
<a id="__codelineno-118-13" name="__codelineno-118-13" href="#__codelineno-118-13"></a><span class="w">  </span><span class="p">)</span>
<a id="__codelineno-118-14" name="__codelineno-118-14" href="#__codelineno-118-14"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">row_expectations</span><span class="p">.</span><span class="n">dataset</span><span class="p">,</span><span class="w"> </span><span class="n">row_expectations</span><span class="p">.</span><span class="n">name</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-139.png" /></p>
<h3 id="databricks-workflows">Databricks Workflows</h3>
<p><img alt="Alt text" src="../image-140.png" /></p>
<h4 id="workflows-vs-dlt-pipelines">Workflows vs DLT Pipelines</h4>
<p>Workflows orchestrate all types of tasks(any kind of sql,spark and ml models)</p>
<p>DLT is used to create streaming data pipelines using Python/SQL. It has quality controls and monitoring.</p>
<p>These two can be integrated. DLT pipeline can be executed as a task in a workflow.</p>
<p><img alt="" src="../image-141.png" /></p>
<h4 id="differences">Differences</h4>
<p><img alt="Alt text" src="../image-142.png" /></p>
<h4 id="use-cases">Use Cases</h4>
<p><img alt="Alt text" src="../image-143.png" /></p>
<h4 id="features-of-workflows">Features of Workflows</h4>
<p><img alt="Alt text" src="../image-144.png" />
<img alt="Alt text" src="../image-145.png" /></p>
<h4 id="how-to-leverage-workflows">How to Leverage Workflows?</h4>
<p><img alt="Alt text" src="../image-146.png" /></p>
<h4 id="common-workflow-patterns">Common Workflow Patterns</h4>
<p><img alt="Alt text" src="../image-147.png" /></p>
<p>The Fan-Out Pattern can be used when we have a single API from which data comes in but there are various data stores that the data must be stored in different shapes.</p>
<h4 id="example-pipeline">Example Pipeline</h4>
<p><img alt="Alt text" src="../image-148.png" /></p>
<h3 id="workflow-job-components">Workflow Job Components</h3>
<p><img alt="Alt text" src="../image-149.png" /></p>
<p>Shared Job Clusters provide flexibility by providing the ability to use same job cluster for more than one task. </p>
<h3 id="defining-tasks">Defining Tasks</h3>
<p><img alt="Alt text" src="../image-150.png" /></p>
<h3 id="scheduling-and-alerts">Scheduling and Alerts</h3>
<p><img alt="Alt text" src="../image-151.png" /></p>
<h3 id="access-controls">Access Controls</h3>
<p><img alt="Alt text" src="../image-152.png" /></p>
<h3 id="job-rrun-history">Job Rrun History</h3>
<p><img alt="Alt text" src="../image-153.png" /></p>
<h3 id="repairing-jobs">Repairing Jobs</h3>
<p><img alt="Alt text" src="../image-154.png" />
In the above figure we can only rerun from the Silvers job and not the bronze one since its executed properly.</p>
<h3 id="demo-of-workflow">Demo of Workflow</h3>
<p>Go to Workflows &gt; Create new workflow</p>
<p><img alt="Alt text" src="../image-155.png" /></p>
<p>Here is the workflow run from the course. I cant run it on my workkspace due to resource constraints.</p>
<p><img alt="Alt text" src="../image-156.png" /></p>
<p>Go to the same notebookDE 5.1.1 and Run the script under <code>Generate Pipeline</code></p>
<p><strong>Creating a DLT Pipeline in the Workflow</strong>
<img alt="Alt text" src="../image-157.png" /></p>
<p>For more info on workflows check <a href="https://adb-6109119110541327.7.azuredatabricks.net/?o=6109119110541327#notebook/2951115793282232/command/2951115793282237">this</a></p>
<h3 id="unity-catalog">Unity Catalog</h3>
<ul>
<li>
<p>There is something called Unity Catalog Metastore that is different from the Hive Metastore and has advanced data lineage, security and auditing capabilities.</p>
</li>
<li>
<p>Metadata like data about the tables, columns and ACL for the objects is stored in the Control Plane</p>
</li>
<li>Data related objects that are managed by the metastore are stored in the Cloud Storage.</li>
<li>Once we connect to Unity Catalog, it connects the Hive Metastore as a special catalog named <code>hive_metastore</code></li>
<li>Assets within the hive metastore can be easily referenced from Unity Catalog.</li>
<li>Unity Catalog won't control access to the hive metastore but we can use the traditional ACLs</li>
</ul>
<h4 id="components-of-unity-catalog">Components of Unity Catalog</h4>
<ul>
<li>Catalogs - Containers that only contain schemas</li>
<li>Schema - Its a container for data bearing assets.</li>
<li>Tables - They have two main information associated with them : data and metadata</li>
<li>Views - perform SQL transformation of other tables or views. They do not have the ability to modify the other tables or views.</li>
<li>Storage Credential - Allows Unity Catalog to access the external cloud storage via access creds.</li>
<li>External Location - Allow users to divide the containers into smaller pieces and exercise control over it, They are mainly used to support external tables.</li>
<li>Shares - They are used to define a read only logical collection of tables. These can be shared with a data reader outside the org.</li>
</ul>
<h4 id="unity-catalog-architecture">Unity Catalog Architecture</h4>
<p><img alt=" " src="https://snipboard.io/3AskyN.jpg" /></p>
<ul>
<li>In case before UC, we should provide different ACL's for each workspace and it must be shared.</li>
<li>If the compute resources are not properly configured then the access rules can be bypassed very easily.</li>
<li>In case of Unity Catalog, we can take out the entire User and Config Management outside workspaces.</li>
<li>We just need to take care of the Compute Resources in the Workspaces. Any changes in the UC is automatically reflected in the Workspaces.</li>
</ul>
<h4 id="query-lifecycle">Query Lifecycle</h4>
<ul>
<li>Queries can be issued via a data warehouse or BI tool. The compute resource begins processing the query.</li>
<li>The UC then accepts the query, logs it and checks the security constraints.</li>
<li>For each object of the query, UC assumes the IAM role or service principal governing the object as provided by a cloud admin.</li>
<li>UC then generates a short term token and returns that token to the principal with the access url.</li>
<li>Now the principal can request data using the URL from the cloud storage with the token.</li>
<li>Data is then sent back from the cloud storage.</li>
<li>Last mile row or column filtering can now be applied on the sql warehouse data.</li>
</ul>
<p><img alt="" src="https://snipboard.io/K3Iinw.jpg" /></p>
<h4 id="compute-resources-and-unity-catalog">Compute Resources and Unity Catalog</h4>
<p><img alt="" src="https://snipboard.io/ONhTE4.jpg" /></p>
<ul>
<li>Dynamic Views are not supported on Single User Cluster.</li>
<li>Cluster level installations don't work on Shared Clusters</li>
<li>Dynamic Views offer row and column protection.</li>
</ul>
<p><img alt="" src="https://snipboard.io/9EtA71.jpg" /></p>
<h4 id="roles-and-admins-in-unity-catalog">Roles and Admins in Unity Catalog</h4>
<p><img alt="" src="https://snipboard.io/3lbvRX.jpg" /></p>
<p>We can assign the roles via access connectors and there is no manual intervention needed.</p>
<p><img alt="" src="https://snipboard.io/LYzWCD.jpg" /></p>
<ul>
<li>Account and Metastore admins have full access to grant privileges and have the access to data objects.</li>
<li>The Metastore admins have same privileges as Cloud Admin but only within the metastore that they own.</li>
<li>There is also a Data Owner that controls and owns only the data objects that they created.</li>
</ul>
<p><img alt="" src="https://snipboard.io/CqZfAW.jpg" /></p>
<h4 id="identities-in-unity-catalog">Identities in Unity Catalog</h4>
<ul>
<li>Service Principal is an individual identity for use with automated tools to run jobs and applications.</li>
<li>They are assigned a name by the creator but are uniquely identified by the Global Unique Identifier ID.</li>
<li>An access token can be used by the Service Principal using an API to access the data or use Databricks workflows.</li>
<li>The Service Principals can be elevated to have admin privileges.</li>
</ul>
<p><img alt="" src="https://snipboard.io/Ys6FPK.jpg" /></p>
<h4 id="groups-in-unity-catalog">Groups in Unity Catalog</h4>
<ul>
<li>Basically its a set of individual users gathered in one place to simplify the access.</li>
<li>
<p>Any grants given to group are inherited by the users.</p>
</li>
<li>
<p>Groups can define who can access what data objects and how simplifying data governance policies.</p>
</li>
</ul>
<p><img alt="" src="https://snipboard.io/lqPd48.jpg" /></p>
<h4 id="multiple-nested-groups">Multiple Nested Groups</h4>
<p><img alt="" src="https://snipboard.io/7COVtL.jpg" /></p>
<h4 id="identity-federation">Identity Federation</h4>
<p><img alt="" src="https://snipboard.io/DYjCip.jpg" /></p>
<ul>
<li>There are two main identities, account identity and workspace identity.</li>
<li>They are linked by a common identity like the email id of a user.</li>
<li>So its important to have the same email in Account and Workspace, otherwise users can login to the workspace using one email but may not be able to access any data.</li>
<li>To simplify this identity federation is used where the users, groups and their access controls are defined once in the Account Console and then they can be assigned to one or more workspaces as needed.</li>
</ul>
<h3 id="data-access-privileges">Data Access Privileges</h3>
<p>The access privileges are not implied or imperative in the case of Databricks.</p>
<p><strong>CREATE</strong> - Allows us to create child data objects like views, table and functions within the catalog.</p>
<p><strong>USAGE</strong> - Allows the person to traverse the child objects. To access a table we need usage access on the containing schema and the catalog.</p>
<p>The privileges are propagated to child objects. For example, granting privileges to a catalog gives us the access to all the tables within the catalog.</p>
<p><strong>SELECT</strong> - allows querying of the table.</p>
<p><strong>MODIFY</strong> - allows modification of the table.</p>
<p><strong>VIEWS</strong> - users don't need access to the underlying source tables to access the view.</p>
<p><strong>EXECUTE</strong> - allows us to use the functions.</p>
<p><strong>STORAGE CREDENTIALS</strong> and <strong>EXTERNAL LOCATION</strong> - support three privileges, READ FILES, WRITE FILES and CREATE TABLE.</p>
<p><strong>SHARE</strong> - supports select statements only.</p>
<p><img alt="" src="https://snipboard.io/Pnif2s.jpg" /></p>
<h4 id="privilege-on-various-objects">Privilege on various objects</h4>
<p><img alt="" src="https://snipboard.io/62nv7V.jpg" /></p>
<p><img alt="" src="https://snipboard.io/6wPrMV.jpg" /></p>
<h4 id="dynamic-views">Dynamic Views</h4>
<p><img alt="" src="https://snipboard.io/6wPrMV.jpg" /></p>
<p>Dropping objects in any scenario can be done only by the owner.</p>
<h4 id="external-locations-and-storage-credentials">External Locations and Storage Credentials</h4>
<p>We can refer to a single storage credential from various external locations.</p>
<p>Because there can be many external locations that use the same storage credentials, DB recommends defining access using the external locations.</p>
<p><img alt="" src="https://snipboard.io/z0n7VP.jpg" /></p>
<h4 id="best-practices-using-unity-catalog">Best Practices using Unity Catalog</h4>
<ol>
<li>One Unity Catalog per region</li>
<li>We can implement table sharing across many regions. But when we are sharing the tables, they appear as read only in the destination metastore.</li>
<li>ACL's are not implemented in Region B, so they need to be setup separately.</li>
<li>It may be costly to do this because data is queried across regions, we can rather ingest the data into region B and then query it.</li>
</ol>
<p><img alt="" src="https://snipboard.io/v0fWkb.jpg" /></p>
<h3 id="data-segregation">Data Segregation</h3>
<ol>
<li>We should not use Metastores to segregate data, because switching metastores needs workspace reassignment so the access and creds get spread across several roles in the workspaces.</li>
<li>Metastores are actually a thin layer that references the meta data cloud storage object. Using UC container constructs [schemas and catalogs], enables the entire access and credentials to be handled by the metastore admins and the other catalog and workspace admins dont need to get involved.</li>
</ol>
<p><img alt="" src="https://snipboard.io/P6tR7E.jpg" /></p>
<h4 id="methods-of-data-segregation">Methods of Data Segregation</h4>
<p><img alt="" src="https://snipboard.io/d4TYhf.jpg" /></p>
<ul>
<li>Workspace only identities will not have access to data access within unity catalog.</li>
<li>But in June 2022, DB elevated all workspace and service principal users to account level privileges.</li>
<li>No one should run     production jobs in the prod environment. This risks overwriting the prod data. Users should never be allowed modify access on prod tables.</li>
</ul>
<h4 id="storage-credential-vs-external-location">Storage Credential vs External Location</h4>
<p>The same access credentials that are part of the storage location is provided to the External Locations.</p>
<p><img alt="" src="https://snipboard.io/4ZsRKG.jpg" /></p>
<h3 id="unity-catalog_1">Unity Catalog</h3>
<ul>
<li>
<p>There is something called Unity Catalog Metastore that is different from the Hive Metastore and has advanced data lineage, security and auditing capabilities.</p>
</li>
<li>
<p>Metadata like data about the tables, columns and ACL for the objects is stored in the Control Plane</p>
</li>
<li>Data related objects that are managed by the metastore are stored in the Cloud Storage.</li>
<li>Once we connect to Unity Catalog, it connects the Hive Metastore as a special catalog named <code>hive_metastore</code></li>
<li>Assets within the hive metastore can be easily referenced from Unity Catalog.</li>
<li>Unity Catalog won't control access to the hive metastore but we can use the traditional ACLs</li>
</ul>
<h4 id="components-of-unity-catalog_1">Components of Unity Catalog</h4>
<ul>
<li>Catalogs - Containers that only contain schemas</li>
<li>Schema - Its a container for data bearing assets.</li>
<li>Tables - They have two main information associated with them : data and metadata</li>
<li>Views - perform SQL transformation of other tables or views. They do not have the ability to modify the other tables or views.</li>
<li>Storage Credential - Allows Unity Catalog to access the external cloud storage via access creds.</li>
<li>External Location - Allow users to divide the containers into smaller pieces and exercise control over it, They are mainly used to support external tables.</li>
<li>Shares - They are used to define a read only logical collection of tables. These can be shared with a data reader outside the org.</li>
</ul>
<h4 id="unity-catalog-architecture_1">Unity Catalog Architecture</h4>
<p><img alt=" " src="https://snipboard.io/3AskyN.jpg" /></p>
<ul>
<li>In case before UC, we should provide different ACL's for each workspace and it must be shared.</li>
<li>If the compute resources are not properly configured then the access rules can be bypassed very easily.</li>
<li>In case of Unity Catalog, we can take out the entire User and Config Management outside workspaces.</li>
<li>We just need to take care of the Compute Resources in the Workspaces. Any changes in the UC is automatically reflected in the Workspaces.</li>
</ul>
<h4 id="query-lifecycle_1">Query Lifecycle</h4>
<ul>
<li>Queries can be issued via a data warehouse or BI tool. The compute resource begins processing the query.</li>
<li>The UC then accepts the query, logs it and checks the security constraints.</li>
<li>For each object of the query, UC assumes the IAM role or service principal governing the object as provided by a cloud admin.</li>
<li>UC then generates a short term token and returns that token to the principal with the access url.</li>
<li>Now the principal can request data using the URL from the cloud storage with the token.</li>
<li>Data is then sent back from the cloud storage.</li>
<li>Last mile row or column filtering can now be applied on the sql warehouse data.</li>
</ul>
<p><img alt="" src="https://snipboard.io/K3Iinw.jpg" /></p>
<h4 id="compute-resources-and-unity-catalog_1">Compute Resources and Unity Catalog</h4>
<p><img alt="" src="https://snipboard.io/ONhTE4.jpg" /></p>
<ul>
<li>Dynamic Views are not supported on Single User Cluster.</li>
<li>Cluster level installations don't work on Shared Clusters</li>
<li>Dynamic Views offer row and column protection.</li>
</ul>
<p><img alt="" src="https://snipboard.io/9EtA71.jpg" /></p>
<h4 id="roles-and-admins-in-unity-catalog_1">Roles and Admins in Unity Catalog</h4>
<p><img alt="" src="https://snipboard.io/3lbvRX.jpg" /></p>
<p>We can assign the roles via access connectors and there is no manual intervention needed.</p>
<p><img alt="" src="https://snipboard.io/LYzWCD.jpg" /></p>
<ul>
<li>Account and Metastore admins have full access to grant privileges and have the access to data objects.</li>
<li>The Metastore admins have same privileges as Cloud Admin but only within the metastore that they own.</li>
<li>There is also a Data Owner that controls and owns only the data objects that they created.</li>
</ul>
<p><img alt="" src="https://snipboard.io/CqZfAW.jpg" /></p>
<h4 id="identities-in-unity-catalog_1">Identities in Unity Catalog</h4>
<ul>
<li>Service Principal is an individual identity for use with automated tools to run jobs and applications.</li>
<li>They are assigned a name by the creator but are uniquely identified by the Global Unique Identifier ID.</li>
<li>An access token can be used by the Service Principal using an API to access the data or use Databricks workflows.</li>
<li>The Service Principals can be elevated to have admin privileges.</li>
</ul>
<p><img alt="" src="https://snipboard.io/Ys6FPK.jpg" /></p>
<h4 id="groups-in-unity-catalog_1">Groups in Unity Catalog</h4>
<ul>
<li>Basically its a set of individual users gathered in one place to simplify the access.</li>
<li>
<p>Any grants given to group are inherited by the users.</p>
</li>
<li>
<p>Groups can define who can access what data objects and how simplifying data governance policies.</p>
</li>
</ul>
<p><img alt="" src="https://snipboard.io/lqPd48.jpg" /></p>
<h4 id="multiple-nested-groups_1">Multiple Nested Groups</h4>
<p><img alt="" src="https://snipboard.io/7COVtL.jpg" /></p>
<h4 id="identity-federation_1">Identity Federation</h4>
<p><img alt="" src="https://snipboard.io/DYjCip.jpg" /></p>
<ul>
<li>There are two main identities, account identity and workspace identity.</li>
<li>They are linked by a common identity like the email id of a user.</li>
<li>So its important to have the same email in Account and Workspace, otherwise users can login to the workspace using one email but may not be able to access any data.</li>
<li>To simplify this identity federation is used where the users, groups and their access controls are defined once in the Account Console and then they can be assigned to one or more workspaces as needed.</li>
</ul>
<h3 id="data-access-privileges_1">Data Access Privileges</h3>
<p>The access privileges are not implied or imperative in the case of Databricks.</p>
<p><strong>CREATE</strong> - Allows us to create child data objects like views, table and functions within the catalog.</p>
<p><strong>USAGE</strong> - Allows the person to traverse the child objects. To access a table we need usage access on the containing schema and the catalog.</p>
<p>The privileges are propagated to child objects. For example, granting privileges to a catalog gives us the access to all the tables within the catalog.</p>
<p><strong>SELECT</strong> - allows querying of the table.</p>
<p><strong>MODIFY</strong> - allows modification of the table.</p>
<p><strong>VIEWS</strong> - users don't need access to the underlying source tables to access the view.</p>
<p><strong>EXECUTE</strong> - allows us to use the functions.</p>
<p><strong>STORAGE CREDENTIALS</strong> and <strong>EXTERNAL LOCATION</strong> - support three privileges, READ FILES, WRITE FILES and CREATE TABLE.</p>
<p><strong>SHARE</strong> - supports select statements only.</p>
<p><img alt="" src="https://snipboard.io/Pnif2s.jpg" /></p>
<h4 id="privilege-on-various-objects_1">Privilege on various objects</h4>
<p><img alt="" src="https://snipboard.io/62nv7V.jpg" /></p>
<p><img alt="" src="https://snipboard.io/6wPrMV.jpg" /></p>
<h4 id="dynamic-views_1">Dynamic Views</h4>
<p><img alt="" src="https://snipboard.io/6wPrMV.jpg" /></p>
<p>Dropping objects in any scenario can be done only by the owner.</p>
<h4 id="external-locations-and-storage-credentials_1">External Locations and Storage Credentials</h4>
<p>We can refer to a single storage credential from various external locations.</p>
<p>Because there can be many external locations that use the same storage credentials, DB recommends defining access using the external locations.</p>
<p><img alt="" src="https://snipboard.io/z0n7VP.jpg" /></p>
<h4 id="best-practices-using-unity-catalog_1">Best Practices using Unity Catalog</h4>
<ol>
<li>One Unity Catalog per region</li>
<li>We can implement table sharing across many regions. But when we are sharing the tables, they appear as read only in the destination metastore.</li>
<li>ACL's are not implemented in Region B, so they need to be setup separately.</li>
<li>It may be costly to do this because data is queried across regions, we can rather ingest the data into region B and then query it.</li>
</ol>
<p><img alt="" src="https://snipboard.io/v0fWkb.jpg" /></p>
<h3 id="data-segregation_1">Data Segregation</h3>
<ol>
<li>We should not use Metastores to segregate data, because switching metastores needs workspace reassignment so the access and creds get spread across several roles in the workspaces.</li>
<li>Metastores are actually a thin layer that references the meta data cloud storage object. Using UC container constructs [schemas and catalogs], enables the entire access and credentials to be handled by the metastore admins and the other catalog and workspace admins dont need to get involved.</li>
</ol>
<p><img alt="" src="https://snipboard.io/P6tR7E.jpg" /></p>
<h4 id="methods-of-data-segregation_1">Methods of Data Segregation</h4>
<p><img alt="" src="https://snipboard.io/d4TYhf.jpg" /></p>
<ul>
<li>Workspace only identities will not have access to data access within unity catalog.</li>
<li>But in June 2022, DB elevated all workspace and service principal users to account level privileges.</li>
<li>No one should run     production jobs in the prod environment. This risks overwriting the prod data. Users should never be allowed modify access on prod tables.</li>
</ul>
<h4 id="storage-credential-vs-external-location_1">Storage Credential vs External Location</h4>
<p>The same access credentials that are part of the storage location is provided to the External Locations.</p>
<p><img alt="" src="https://snipboard.io/4ZsRKG.jpg" /></p>
<h4 id="practical-example">Practical Example</h4>
<p>I cannot create metastore in my account due to privilege problems. Just check the code to understand. Here is a video from the course regarding the <a href="https://customer-academy.databricks.com/learn/course/1266/play/14569/create-and-govern-data-with-unity-catalog;lp=10">example</a>.</p>
<h5 id="create-a-new-catalog">Create a New Catalog</h5>
<p>Let's create a new catalog in our metastore. The variable <strong><code>${DA.my_new_catalog}</code></strong> was displayed by the setup cell above, containing a unique string generated based on your username.</p>
<p>Run the <strong><code>CREATE</code></strong> statement below, and click the <strong>Data</strong> icon in the left sidebar to confirm this new catalog was created.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-119-1" name="__codelineno-119-1" href="#__codelineno-119-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">CATALOG</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">my_new_catalog</span><span class="err">}</span>
</code></pre></div>
<h5 id="selecting-the-default-catalog">Selecting the Default Catalog</h5>
<p>SQL developers will probably also be familiar with the <strong><code>USE</code></strong> statement to select a default schema, thereby shortening queries by not having to specify it all the time. To extend this convenience while dealing with the extra level in the namespace, Unity Catalog augments the language with two additional statements, shown in the examples below:</p>
<div class="highlight"><pre><span></span><code>USE CATALOG mycatalog;
USE SCHEMA myschema;
</code></pre></div>
<p>Let's select the newly created catalog as the default. Now, any schema references will be assumed to be in this catalog unless explicitly overridden by a catalog reference.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-120-1" name="__codelineno-120-1" href="#__codelineno-120-1"></a><span class="n">USE</span><span class="w"> </span><span class="k">CATALOG</span><span class="w"> </span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">my_new_catalog</span><span class="err">}</span>
</code></pre></div>
<h5 id="create-a-new-schema">Create a New Schema</h5>
<p>Next, let's create a schema in this new catalog. We won't need to generate another unique name for this schema, since we're now using a unique catalog that is isolated from the rest of the metastore. Let's also set this as the default schema. Now, any data references will be assumed to be in the catalog and schema we created, unless explicitely overridden by a two- or three-level reference.</p>
<p>Run the code below, and click the <strong>Data</strong> icon in the left sidebar to confirm this schema was created in the new catalog we created.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-121-1" name="__codelineno-121-1" href="#__codelineno-121-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">NOT</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="n">example</span><span class="p">;</span>
<a id="__codelineno-121-2" name="__codelineno-121-2" href="#__codelineno-121-2"></a><span class="n">USE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="n">example</span>
</code></pre></div>
<h5 id="set-up-tables-and-views">Set Up Tables and Views</h5>
<p>With all the necessary containment in place, let's set up tables and views. For this example, we'll use mock data to create and populate a <em>silver</em> managed table with synthetic patient heart rate data and a <em>gold</em> view that averages heart rate data per patient on a daily basis.</p>
<p>Run the cells below, and click the <strong>Data</strong> icon in the left sidebar to explore the contents of the <em>example</em> schema. Note that we don't need to specify three levels when specifying the table or view names below, since we selected a default catalog and schema.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-122-1" name="__codelineno-122-1" href="#__codelineno-122-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">heartrate_device</span><span class="w"> </span><span class="p">(</span><span class="n">device_id</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="n">mrn</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="k">time</span><span class="w"> </span><span class="k">TIMESTAMP</span><span class="p">,</span><span class="w"> </span><span class="n">heartrate</span><span class="w"> </span><span class="n">DOUBLE</span><span class="p">);</span>
<a id="__codelineno-122-2" name="__codelineno-122-2" href="#__codelineno-122-2"></a>
<a id="__codelineno-122-3" name="__codelineno-122-3" href="#__codelineno-122-3"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">heartrate_device</span><span class="w"> </span><span class="k">VALUES</span>
<a id="__codelineno-122-4" name="__codelineno-122-4" href="#__codelineno-122-4"></a><span class="w">  </span><span class="p">(</span><span class="mi">23</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;40580129&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Nicholas Spears&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;2020-02-01T00:01:58.000+0000&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">54</span><span class="p">.</span><span class="mi">0122153343</span><span class="p">),</span>
<a id="__codelineno-122-5" name="__codelineno-122-5" href="#__codelineno-122-5"></a><span class="w">  </span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;52804177&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Lynn Russell&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;2020-02-01T00:02:55.000+0000&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">92</span><span class="p">.</span><span class="mi">5136468131</span><span class="p">),</span>
<a id="__codelineno-122-6" name="__codelineno-122-6" href="#__codelineno-122-6"></a><span class="w">  </span><span class="p">(</span><span class="mi">37</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;65300842&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Samuel Hughes&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;2020-02-01T00:08:58.000+0000&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">52</span><span class="p">.</span><span class="mi">1354807863</span><span class="p">),</span>
<a id="__codelineno-122-7" name="__codelineno-122-7" href="#__codelineno-122-7"></a><span class="w">  </span><span class="p">(</span><span class="mi">23</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;40580129&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Nicholas Spears&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;2020-02-01T00:16:51.000+0000&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">54</span><span class="p">.</span><span class="mi">6477014191</span><span class="p">),</span>
<a id="__codelineno-122-8" name="__codelineno-122-8" href="#__codelineno-122-8"></a><span class="w">  </span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;52804177&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Lynn Russell&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;2020-02-01T00:18:08.000+0000&quot;</span><span class="p">,</span><span class="w"> </span><span class="mi">95</span><span class="p">.</span><span class="mi">033344842</span><span class="p">);</span>
<a id="__codelineno-122-9" name="__codelineno-122-9" href="#__codelineno-122-9"></a>
<a id="__codelineno-122-10" name="__codelineno-122-10" href="#__codelineno-122-10"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">heartrate_device</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-158.png" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-123-1" name="__codelineno-123-1" href="#__codelineno-123-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">agg_heartrate</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-123-2" name="__codelineno-123-2" href="#__codelineno-123-2"></a><span class="w">  </span><span class="k">SELECT</span><span class="w"> </span><span class="n">mrn</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">MEAN</span><span class="p">(</span><span class="n">heartrate</span><span class="p">)</span><span class="w"> </span><span class="n">avg_heartrate</span><span class="p">,</span><span class="w"> </span><span class="n">DATE_TRUNC</span><span class="p">(</span><span class="ss">&quot;DD&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">time</span><span class="p">)</span><span class="w"> </span><span class="nb">date</span>
<a id="__codelineno-123-3" name="__codelineno-123-3" href="#__codelineno-123-3"></a><span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">heartrate_device</span>
<a id="__codelineno-123-4" name="__codelineno-123-4" href="#__codelineno-123-4"></a><span class="w">  </span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">mrn</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">DATE_TRUNC</span><span class="p">(</span><span class="ss">&quot;DD&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">time</span><span class="p">)</span>
<a id="__codelineno-123-5" name="__codelineno-123-5" href="#__codelineno-123-5"></a><span class="p">);</span>
<a id="__codelineno-123-6" name="__codelineno-123-6" href="#__codelineno-123-6"></a><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">agg_heartrate</span>
</code></pre></div>
<p><img alt="Alt text" src="../image-159.png" /></p>
<p>Querying the table above works as expected since we are the data owner. That is, we have ownership of the data object we're querying. Querying the view also works because we are the owner of both the view and the table it's referencing. Thus, no object-level permissions are required to access these resources.</p>
<h5 id="the-accounts_user_group">The <code>accounts_user_group</code></h5>
<p>In accounts with Unity Catalog enabled, there is an <em>account users</em> group. This group contains all users that have been assigned to the workspace from the Databricks account. We are going to use this group to show how data object access can be different for users in different groups.</p>
<h5 id="grant-access-to-data-objects">Grant Access to Data Objects</h5>
<p>Unity Catalog employs an explicit permission model by default; no permissions are implied or inherited from containing elements. Therefore, in order to access any data objects, users will need <strong>USAGE</strong> permission on all containing elements; that is, the containing schema and catalog.</p>
<p>Now let's allow members of the <em>account users</em> group to query the <em>gold</em> view. In order to do this, we need to grant the following permissions:
1. USAGE on the catalog and schema
1. SELECT on the data object (e.g. view)</p>
<p>We need the USAGE command to actually make sure that the user reaches the point through the tree level structure to get to where the catalog is stored.</p>
<p><strong>Grant Privileges</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-124-1" name="__codelineno-124-1" href="#__codelineno-124-1"></a><span class="k">GRANT</span><span class="w"> </span><span class="k">USAGE</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="k">CATALOG</span><span class="w"> </span><span class="err">${</span><span class="n">DA</span><span class="p">.</span><span class="n">my_new_catalog</span><span class="err">}</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="o">`</span><span class="n">account</span><span class="w"> </span><span class="n">users</span><span class="o">`</span><span class="p">;</span>
<a id="__codelineno-124-2" name="__codelineno-124-2" href="#__codelineno-124-2"></a><span class="k">GRANT</span><span class="w"> </span><span class="k">USAGE</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="n">example</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="o">`</span><span class="n">account</span><span class="w"> </span><span class="n">users</span><span class="o">`</span><span class="p">;</span>
<a id="__codelineno-124-3" name="__codelineno-124-3" href="#__codelineno-124-3"></a><span class="k">GRANT</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">agg_heartrate</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="o">`</span><span class="n">account</span><span class="w"> </span><span class="n">users</span><span class="o">`</span>
</code></pre></div>
<h5 id="generate-a-query-and-access-the-data">Generate a Query and access the data</h5>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-125-1" name="__codelineno-125-1" href="#__codelineno-125-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="ss">&quot;SELECT * FROM ${DA.my_new_catalog}.example.agg_heartrate&quot;</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">Query</span>
</code></pre></div>
<img alt="Alt text" src="../image-160.png" /></p>
<h5 id="can-we-query-the-silver-table">Can we query the silver table?</h5>
<p>Back in the same query in the Databricks SQL session, let's replace <em>gold</em> with <em>silver</em> and run the query. This time it fails, because we never set up permissions on the <em>silver</em> table. </p>
<p>Querying <em>gold</em> works because the query represented by a view is essentially executed as the owner of the view. This important property enables some interesting security use cases; in this way, views can provide users with a restricted view of sensitive data, without providing access to the underlying data itself. We will see more of this shortly.</p>
<h5 id="granting-access-to-udf">Granting Access to UDF</h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-126-1" name="__codelineno-126-1" href="#__codelineno-126-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">mask</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span>
<a id="__codelineno-126-2" name="__codelineno-126-2" href="#__codelineno-126-2"></a><span class="w">  </span><span class="k">RETURNS</span><span class="w"> </span><span class="n">STRING</span>
<a id="__codelineno-126-3" name="__codelineno-126-3" href="#__codelineno-126-3"></a><span class="w">  </span><span class="k">RETURN</span><span class="w"> </span><span class="n">CONCAT</span><span class="p">(</span><span class="n">REPEAT</span><span class="p">(</span><span class="ss">&quot;*&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">LENGTH</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="k">RIGHT</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-126-4" name="__codelineno-126-4" href="#__codelineno-126-4"></a><span class="p">);</span><span class="w"> </span>
<a id="__codelineno-126-5" name="__codelineno-126-5" href="#__codelineno-126-5"></a><span class="k">SELECT</span><span class="w"> </span><span class="n">mask</span><span class="p">(</span><span class="s1">&#39;sensitive data&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">data</span>
</code></pre></div>
<p>The above function masks the last two characters of the string <code>sensitive_data</code></p>
<p>Now let's grant access to the function</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-127-1" name="__codelineno-127-1" href="#__codelineno-127-1"></a><span class="k">GRANT</span><span class="w"> </span><span class="k">EXECUTE</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">mask</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="o">`</span><span class="n">account</span><span class="w"> </span><span class="n">users</span><span class="o">`</span>
</code></pre></div>
<p>Run the function using</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-128-1" name="__codelineno-128-1" href="#__codelineno-128-1"></a><span class="k">SELECT</span><span class="w"> </span><span class="ss">&quot;SELECT ${DA.my_new_catalog}.example.mask(&#39;sensitive data&#39;) AS data&quot;</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">Query</span>
</code></pre></div>
<p>Now run the query in the SQL Editor you can see that the last two characters are redacted.</p>
<h1 id="data-engineering-professional-learning-pathway">Data Engineering Professional Learning Pathway</h1>
<h2 id="top-level-concepts">Top Level Concepts</h2>
<p>This is the course material that's part of <a href="https://community.databricks.com/t5/events/dais-2025-virtual-learning-festival-11-june-02-july-2025/ec-p/119323#M3413">Databricks AI Summit Learning Festival</a></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/9db72f39-b76b-4eb1-bebe-18d74491960c" /></p>
<h3 id="advantages-of-stream-processing">Advantages of Stream Processing</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/7b7dd479-9fbc-498a-9afa-f3a2d946e212" /></p>
<h3 id="stream-processing-architecture">Stream Processing Architecture</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/5769cb5d-a6af-410c-b200-4d0ff3480b1d" /></p>
<h3 id="challenges-with-streaming">Challenges with Streaming</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/33886dbd-be99-49c4-82c6-35df5c388fce" /></p>
<h2 id="what-is-structured-streaming">What is Structured Streaming?</h2>
<p><img alt="image" src="https://github.com/user-attachments/assets/b032b0aa-9c6c-4129-a59d-f310472625f9" /></p>
<h3 id="unbounded-tables-for-streaming">Unbounded Tables For Streaming</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/c601d348-2e8f-4cf2-954a-e064066f2c60" /></p>
<h3 id="execution-mode-in-streaming">Execution Mode in Streaming</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/e2b89492-25d3-4433-89ce-c799ea0627a8" /></p>
<h3 id="anatomy-of-a-streaming-query">Anatomy of a Streaming Query</h3>
<p>Source, Input Tables, Result tables and storage layer in streaming.
<img alt="image" src="https://github.com/user-attachments/assets/e6f05ec0-f937-4fa2-9a63-0774e638d1e2" /></p>
<h4 id="step-1-read-data-from-any-streaming-source">Step 1: Read data from any streaming source</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/510359b0-66ee-473d-84d8-cdc2585ec936" /></p>
<h4 id="step-2-transform-the-data">Step 2 : Transform the data</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/c4d80b0f-5f37-4a4b-8bfb-a8dffb9a86e9" /></p>
<h4 id="step-3-sink">Step 3 : Sink</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/4b6231ed-736f-4387-91f3-9af9e842ad71" /></p>
<h4 id="step-4-trigger-mechanism">Step 4 : Trigger Mechanism</h4>
<p>Checkpoint is there to ensure fault tolerance.
<img alt="image" src="https://github.com/user-attachments/assets/3372e246-1416-4909-918f-9f469a7348d7" /></p>
<p>The API definitions for batch and streaming is the same.</p>
<h3 id="types-of-triggers">Types of Triggers</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/6ecd865b-6aed-427d-8efa-26da07e8571f" /></p>
<h3 id="output-modes">Output Modes</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/c5107f77-ce18-40fd-86cb-d11e5f542d05" /></p>
<h3 id="demo-streaming-data-query">Demo : Streaming Data Query</h3>
<p>"readStream" instead of "read" the tranformations are the same. 
<img alt="image" src="https://github.com/user-attachments/assets/c2752817-db9e-43f7-be8f-4772f87cbdd4" /></p>
<p><strong>Data Metrics</strong>
<img alt="image" src="https://github.com/user-attachments/assets/0f0bae4a-56fd-4780-8310-4ed6ecca80db" /></p>
<h4 id="writing-data-to-a-delta-lake-sink">Writing Data to a Delta Lake Sink</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/8f40d051-220a-4452-9229-24fd3aa798e5" /></p>
<p>We can see the status of the query</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/66e58b37-f031-4d01-b622-b6be7f2e618b" /></p>
<p>... and also see the metrics from the previous query</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/53c1967b-ee45-4cd7-a137-845ca788127b" /></p>
<h3 id="using-delta-tables-as-a-streaming-source">Using Delta tables as a Streaming Source</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/86878222-d4f1-4077-bc3c-8824a04bfc23" /></p>
<h4 id="tuning-the-parameters-for-a-delta-streaming-source">Tuning the parameters for a delta streaming source</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/92aef855-c795-4803-aa7c-08625ef77e52" /></p>
<h4 id="streaming-to-a-delta-table">Streaming to a delta table</h4>
<p>For any arbitary aggregations on streaming data, use complete mode.
<img alt="image" src="https://github.com/user-attachments/assets/9551b6a0-2f21-4881-a330-23921faac6e6" /></p>
<h3 id="aggregations-time-windows-and-watermark">Aggregations, Time Windows and Watermark</h3>
<h4 id="types-of-stream-processing">Types of Stream Processing</h4>
<p>There are two types of Stream Processing</p>
<ul>
<li>Stateless</li>
<li>Stateful</li>
</ul>
<p><img alt="image" src="https://github.com/user-attachments/assets/2d4c7d03-acae-4eea-9bea-87488e902a7e" /></p>
<h4 id="intermediate-state-to-keep-track">Intermediate State to Keep Track</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/dbeb035d-1d1b-4e7c-b31e-13435fc39690" /></p>
<h3 id="aggregations-over-time-windows">Aggregations over Time Windows</h3>
<h3 id="event-time-vs-processing-time">Event Time vs Processing Time</h3>
<p>The unbounded tables must always be processed in order.
<img alt="image" src="https://github.com/user-attachments/assets/d68631dc-08cb-4912-8cdb-cd6dcfb49484" /></p>
<h3 id="tumbling-window-vs-sliding-window">Tumbling Window vs Sliding Window</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/f1357050-dd4b-4282-b03e-205b55b6b1a8" /></p>
<h3 id="sliding-window-example">Sliding Window Example</h3>
<p>Here is a 10 min window with 5 min overlap
<img alt="image" src="https://github.com/user-attachments/assets/8b0cd55f-c545-41b7-a27d-3f6340ea16e2" /></p>
<h3 id="challenges-with-sliding-window">Challenges with Sliding Window</h3>
<p>There is a lot of Memory Pressure with using sliding window because all the data is stored in executor memory.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/6af17385-c2f2-487c-b354-4d07d871ce9c" /></p>
<p>We can tackle this by storing the data off heap
<img alt="image" src="https://github.com/user-attachments/assets/f7fc27e9-82fc-4f70-972d-b035b028c654" /></p>
<h3 id="watermarking-late-threshold">Watermarking / Late Threshold</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/ec6db226-7ac3-45df-9bc6-34368a305819" /></p>
<p>Watermarking is a technique that basically tells how long is too late?</p>
<p>For example if data record with id = 100 came in now at 12:05am then if we keep window as 10 min then we will wait until 12:15am and if no data arrives for that id we purge the state.</p>
<p>The dog record in the below pic has eventTime of 12:04 but its beyond our 10 min window (12:05 - 12:15) so we dont consider that record and miss the count.
<img alt="image" src="https://github.com/user-attachments/assets/1c7fddee-b7db-4bfd-953f-71a149973afb" /></p>
<p><strong>Late arriving data state is dropped and we save memory</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/de5ddea3-59df-4070-a38c-82330041d451" /></p>
<h3 id="demo-time-window-aggregations-with-watermarking">Demo : Time window aggregations with Watermarking</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/a53bb105-5743-4d68-bda7-1f6ab8ebd795" /></p>
<h4 id="read-and-process-streaming-source">Read and Process Streaming Source</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/4d8dd3de-7f8c-481d-a16e-34ffafb550fe" /></p>
<p>Output
<img alt="image" src="https://github.com/user-attachments/assets/a7e550d7-0e65-42d4-8e8f-7e5cbbb047ee" /></p>
<p><strong>Windowing</strong></p>
<p>Goal is to find the revenue in USD in a 60 min time window.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/4d559d9e-2133-4794-9edd-b4bf41b8c1f6" /></p>
<ul>
<li>Here the window is of 60 min but we add a watermark of 90 min to cater to any late arriving data.</li>
<li>Then we group by both eventTimestamp and the city to find the revenue.</li>
</ul>
<p>Output
<img alt="image" src="https://github.com/user-attachments/assets/2ab92ade-ca5f-4b4a-9a7d-96339434ff72" /></p>
<h3 id="writing-data-in-append-mode">Writing Data in Append Mode</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/63927321-dc13-46b9-a791-d06f1d5c9423" /></p>
<p>The catch with append mode is that the data is not going to be written into the sink until and unless we finish the hour (window duration)</p>
<p>The <strong>availableNow</strong> trigger processes all the data currently available in the source and then stops. It’s like a one-time cleanup of everything in your inbox.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-129-1" name="__codelineno-129-1" href="#__codelineno-129-1"></a><span class="n">writeStreamAvailableNow</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-129-2" name="__codelineno-129-2" href="#__codelineno-129-2"></a>    <span class="n">df</span><span class="o">.</span><span class="n">writeStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;delta&quot;</span><span class="p">)</span>
<a id="__codelineno-129-3" name="__codelineno-129-3" href="#__codelineno-129-3"></a>    <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">checkpoint_location</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-129-4" name="__codelineno-129-4" href="#__codelineno-129-4"></a>    <span class="o">.</span><span class="n">trigger</span><span class="p">(</span><span class="n">availableNow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-129-5" name="__codelineno-129-5" href="#__codelineno-129-5"></a>    <span class="o">.</span><span class="n">outputMode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span>
<a id="__codelineno-129-6" name="__codelineno-129-6" href="#__codelineno-129-6"></a>    <span class="o">.</span><span class="n">queryName</span><span class="p">(</span><span class="s2">&quot;AvailableNow&quot;</span><span class="p">)</span>
<a id="__codelineno-129-7" name="__codelineno-129-7" href="#__codelineno-129-7"></a>    <span class="o">.</span><span class="n">toTable</span><span class="p">(</span><span class="s2">&quot;default.streaming_circuits&quot;</span><span class="p">)</span>
<a id="__codelineno-129-8" name="__codelineno-129-8" href="#__codelineno-129-8"></a><span class="p">)</span>
</code></pre></div>
<img alt="image" src="https://github.com/user-attachments/assets/867c6d62-ba3e-4a4f-b702-4822de3918e2" /></p>
<p>Result: here, the query processes all data available in the source and then terminates. This is a great choice when you want to process data in a “stream-like” fashion but only once.</p>
<p>There is always some delay between creating streaming table and the commits happening to it.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/bca915cf-eff7-4f2f-84b5-7b75d67bc0b2" /></p>
<h3 id="writing-data-in-update-mode">Writing Data in update mode</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/774d0912-8320-4cf6-8661-69aff779da2e" /></p>
<h4 id="step-1-create-a-table">Step 1 : Create a table</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/15fc2eb0-fa1b-4f5a-bd3b-db8168656f68" /></p>
<h4 id="step-2-write-a-merge-query-to-merge-the-data-based-on-start-and-end-time">Step 2 : Write a MERGE Query to merge the data based on start and end time</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/5e3b04ba-c384-4063-b3cf-e6e9c2e46d6f" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/88cb0e0c-5ab8-42ff-a824-42798ea5fb83" /></p>
<h3 id="data-ingestion-patterns">Data Ingestion Patterns</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/5d535e77-888a-4270-b76f-1954fa2d9f2d" /></p>
<h4 id="how-to-deal-with-ephemeral-data">How to deal with ephemeral data?</h4>
<p>We can deal with transient data by creating STREAMING LIVE tables that contain raw data from source.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/4abf68eb-00ad-4454-a41e-ae7c395c3432" /></p>
<p>Then we can update other tables like silver tables (also live) with transformations.</p>
<h4 id="simplex-vs-multiplex-ingestion">Simplex vs Multiplex Ingestion</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/c9875de5-0eeb-4237-b7cd-6a2c2c7935bc" /></p>
<h4 id="dont-use-kafka-as-bronze-table">Dont use Kafka as bronze table</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/41493a40-8c3b-4377-9b80-a5f3e7197662" /></p>
<h4 id="solution">Solution</h4>
<ul>
<li>First simplex and store data in bronze</li>
<li>Then multiplex it and transform into multiple silver tables.
<img alt="image" src="https://github.com/user-attachments/assets/08ccbccb-7a75-49b4-9876-a1b6fdff0af1" /></li>
</ul>
<h3 id="dlt-demo">DLT Demo</h3>
<h4 id="autoloader-for-bronze-ingestion">Autoloader for bronze ingestion</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/7bf2daae-d9d8-48d6-8c2b-c99dd5a47ba7" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a332af9c-3c77-4a48-883b-3b927313183c" /></p>
<p>Here are the conf parameters</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/4d25b2f0-a7e9-4977-bd68-199d1bbd2eff" /></p>
<p>This is the syntax of a dlt table.</p>
<ul>
<li>we first define the parameters of the table and dont allow reset on it.</li>
</ul>
<p><img alt="image" src="https://github.com/user-attachments/assets/9a3e2e31-0236-49dc-b6e9-6f06de503777" /></p>
<ul>
<li>now we stream data from cloud files using autoloader.
<img alt="image" src="https://github.com/user-attachments/assets/751a3a97-a4f5-4fd0-9394-121b0913d077" /></li>
</ul>
<p>Final dlt pipeline</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1d04b4d9-907f-486b-be91-039f463c9c3e" /></p>
<h4 id="transforming-the-data">Transforming the data</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/7fdb48ce-cbb9-4dda-b5b6-3f3dae99427f" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/0a3af94c-5f8a-4d3d-8ca5-7a30379d88eb" /></p>
<h3 id="quality-enforcement-in-dlt">Quality Enforcement in DLT</h3>
<h4 id="quality-enforcement-in-bronze">Quality enforcement in Bronze</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/12f6f1eb-b6f0-4a9c-bf33-ed8750a71fd8" /></p>
<h4 id="quality-enforcement-in-silver">Quality enforcement in Silver</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/891c851d-f559-4ff2-938a-0ab23e403862" /></p>
<h4 id="schema-enforcement-patterns">Schema Enforcement Patterns</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/3a195349-fa93-4a4b-ab4f-7d7f271472e3" /></p>
<h4 id="alternate-enforcement-methods">Alternate Enforcement Methods</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/7cb727c7-3f13-4fcc-8b82-cce7dfaff70e" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a8c16656-851f-4e89-89ea-c7da544c9662" /></p>
<h4 id="defining-expectations-in-dlt">Defining Expectations in DLT</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/cdc05986-babf-4fdc-9941-433bfba5aa45" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/b5dc377a-57e0-45fa-a13d-a8254dd525fe" /></p>
<h3 id="demo-enforcing-validations-on-the-data">Demo: Enforcing Validations on the Data</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/b90e16fe-3a9b-4c4a-828e-7f841fdf9879" /></p>
<h4 id="quarantining-records">Quarantining Records</h4>
<p>We say expect all or drop which indicates that all rules must pass else drop records.
<img alt="image" src="https://github.com/user-attachments/assets/e1185b24-6610-411c-8030-794f5ac39ea5" /></p>
<p>Now we can use those rules</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a3f5f19f-ca61-46d9-b57a-8439f68e5513" /></p>
<p><strong>The Data Quality metrics in the UI</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/c55d1c20-70c7-47bf-b3a8-241b9ee6f842" /></p>
<h2 id="databricks-data-privacy">Databricks Data Privacy</h2>
<p><img alt="image" src="https://github.com/user-attachments/assets/070b162e-72fd-4467-b647-996c39b37ce8" /></p>
<h3 id="storing-data-securely">Storing Data Securely</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/8fedd040-0992-4103-ab5a-d1c186ba06b2" /></p>
<h4 id="regulatory-compliance">Regulatory Compliance</h4>
<p><strong>GDPR and CCPA</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1529b46b-a014-4060-ac9e-40b18d3a2ef1" /></p>
<h4 id="databricks-simplifying-compliance">Databricks Simplifying Compliance</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/0d42b54c-e211-4818-a52e-410bbac31c22" /></p>
<h4 id="3-key-aspects-of-data-privacy">3 Key Aspects of Data Privacy</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/e3503526-a754-4ea1-a68a-2320b4d29d46" /></p>
<h3 id="advanced-unity-catalog-concepts">Advanced Unity Catalog Concepts</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/74acae4c-6eb1-4a02-afb8-5c026ebf3f01" /></p>
<h4 id="components-of-unity-catalog_2">Components of Unity Catalog</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/1636cd76-8685-41af-94bb-69b3ab7aea5f" /></p>
<p>How unity catalog provides single governance model?
<img alt="image" src="https://github.com/user-attachments/assets/60021532-9034-4dac-9978-ff21c781f15d" /></p>
<h4 id="access-control-lists">Access Control Lists</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/4dabbbe3-3831-4163-9268-e29b3dd695e7" /></p>
<h4 id="managing-acls">Managing ACLs</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/63d763a9-6f2a-477f-9cc8-ba692e12b4fe" /></p>
<h4 id="tagging-and-ai-docs">Tagging and AI Docs</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/105c4fb1-e466-41a5-aae8-38e3e2b43ba4" /></p>
<h4 id="search-objects-with-tags">Search objects with tags</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/1c60f6ad-a7bb-4ec7-a4ed-64e888b2ed29" /></p>
<h4 id="fine-grained-access-control">Fine Grained Access Control</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/02f5bd04-d1b0-44aa-8b51-26ca48e2d48d" /></p>
<p><strong>Dynamic Views Fine Grained Access Control</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/757568fd-e13b-4bf6-b221-9a74e0f0db6e" /></p>
<p><code>current_user</code> </p>
<p><img alt="image" src="https://github.com/user-attachments/assets/f59dce91-85ff-4df9-abf0-374add83b8b0" /></p>
<p><code>is_member()</code></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/aa94a9e0-b603-428f-9e27-ec18d578c3df" /></p>
<h3 id="row-level-security-and-column-masking">Row level security and Column Masking</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/5a9680ca-d8c7-4eb3-b6ba-5aebcfc2a615" /></p>
<p><strong>What are row filters?</strong></p>
<p>Row filters allow you to apply a filter to a table so that queries return only rows that meet the filter criteria. You implement a row filter as a SQL user-defined function (UDF). Python and Scala UDFs are also supported, but only when they are wrapped in SQL UDFs.</p>
<p><strong>What are column masks?</strong>
Column masks let you apply a masking function to a table column. The masking function evaluates at query runtime, substituting each reference of the target column with the results of the masking function. For most use cases, column masks determine whether to return the original column value or redact it based on the identity of the invoking user. Column masks are expressions written as SQL UDFs or as Python or Scala UDFs wrapped in SQL UDFs.</p>
<p>Each table column can have only one masking function applied to it. The masking function takes the unmasked value of the column as input and returns the masked value as its result. The return value of the masking function should be the same type as the column being masked. The masking function can also take additional columns as input parameters and use those in its masking logic.</p>
<h4 id="examples">Examples</h4>
<p>This example creates a SQL user-defined function that applies to members of the group admin in the region US.</p>
<p>When this sample function is applied to the sales table, members of the admin group can access all records in the table. If the function is called by a non-admin, the RETURN_IF condition fails and the region='US' expression is evaluated, filtering the table to only show records in the US region.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-130-1" name="__codelineno-130-1" href="#__codelineno-130-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">us_filter</span><span class="p">(</span><span class="n">region</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span>
<a id="__codelineno-130-2" name="__codelineno-130-2" href="#__codelineno-130-2"></a><span class="k">RETURN</span><span class="w"> </span><span class="k">IF</span><span class="p">(</span><span class="n">IS_ACCOUNT_GROUP_MEMBER</span><span class="p">(</span><span class="s1">&#39;admin&#39;</span><span class="p">),</span><span class="w"> </span><span class="k">true</span><span class="p">,</span><span class="w"> </span><span class="n">region</span><span class="o">=</span><span class="s1">&#39;US&#39;</span><span class="p">);</span>
</code></pre></div>
Use it on a table</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-131-1" name="__codelineno-131-1" href="#__codelineno-131-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales</span><span class="w"> </span><span class="p">(</span><span class="n">region</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="w"> </span><span class="nb">INT</span><span class="p">);</span>
<a id="__codelineno-131-2" name="__codelineno-131-2" href="#__codelineno-131-2"></a><span class="k">ALTER</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales</span><span class="w"> </span><span class="k">SET</span><span class="w"> </span><span class="k">ROW</span><span class="w"> </span><span class="n">FILTER</span><span class="w"> </span><span class="n">us_filter</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="p">(</span><span class="n">region</span><span class="p">);</span>
</code></pre></div>
<h3 id="column-mask-examples">Column Mask Examples</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-132-1" name="__codelineno-132-1" href="#__codelineno-132-1"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">ssn_mask</span><span class="p">(</span><span class="n">ssn</span><span class="w"> </span><span class="n">STRING</span><span class="p">)</span>
<a id="__codelineno-132-2" name="__codelineno-132-2" href="#__codelineno-132-2"></a><span class="w">  </span><span class="k">RETURN</span><span class="w"> </span><span class="k">CASE</span><span class="w"> </span><span class="k">WHEN</span><span class="w"> </span><span class="n">is_account_group_member</span><span class="p">(</span><span class="s1">&#39;HumanResourceDept&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="n">ssn</span><span class="w"> </span><span class="k">ELSE</span><span class="w"> </span><span class="s1">&#39;***-**-****&#39;</span><span class="w"> </span><span class="k">END</span><span class="p">;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-133-1" name="__codelineno-133-1" href="#__codelineno-133-1"></a><span class="c1">--Create the `users` table and apply the column mask in a single step:</span>
<a id="__codelineno-133-2" name="__codelineno-133-2" href="#__codelineno-133-2"></a>
<a id="__codelineno-133-3" name="__codelineno-133-3" href="#__codelineno-133-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">users</span><span class="w"> </span><span class="p">(</span>
<a id="__codelineno-133-4" name="__codelineno-133-4" href="#__codelineno-133-4"></a><span class="w">  </span><span class="n">name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span>
<a id="__codelineno-133-5" name="__codelineno-133-5" href="#__codelineno-133-5"></a><span class="w">  </span><span class="n">ssn</span><span class="w"> </span><span class="n">STRING</span><span class="w"> </span><span class="n">MASK</span><span class="w"> </span><span class="n">ssn_mask</span><span class="p">);</span>
</code></pre></div>
<h3 id="filtering-on-unspecified-columns">Filtering on unspecified columns</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-134-1" name="__codelineno-134-1" href="#__codelineno-134-1"></a><span class="k">DROP</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="n">row_filter</span><span class="p">;</span>
<a id="__codelineno-134-2" name="__codelineno-134-2" href="#__codelineno-134-2"></a>
<a id="__codelineno-134-3" name="__codelineno-134-3" href="#__codelineno-134-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">FUNCTION</span><span class="w"> </span><span class="n">row_filter</span><span class="p">()</span>
<a id="__codelineno-134-4" name="__codelineno-134-4" href="#__codelineno-134-4"></a><span class="w">  </span><span class="k">RETURN</span><span class="w"> </span><span class="k">EXISTS</span><span class="p">(</span>
<a id="__codelineno-134-5" name="__codelineno-134-5" href="#__codelineno-134-5"></a><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">valid_users</span><span class="w"> </span><span class="n">v</span>
<a id="__codelineno-134-6" name="__codelineno-134-6" href="#__codelineno-134-6"></a><span class="w">    </span><span class="k">WHERE</span><span class="w"> </span><span class="n">v</span><span class="p">.</span><span class="n">username</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">CURRENT_USER</span><span class="p">()</span>
<a id="__codelineno-134-7" name="__codelineno-134-7" href="#__codelineno-134-7"></a><span class="p">);</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-135-1" name="__codelineno-135-1" href="#__codelineno-135-1"></a><span class="k">DROP</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="k">IF</span><span class="w"> </span><span class="k">EXISTS</span><span class="w"> </span><span class="n">data_table</span><span class="p">;</span>
<a id="__codelineno-135-2" name="__codelineno-135-2" href="#__codelineno-135-2"></a>
<a id="__codelineno-135-3" name="__codelineno-135-3" href="#__codelineno-135-3"></a><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">data_table</span>
<a id="__codelineno-135-4" name="__codelineno-135-4" href="#__codelineno-135-4"></a><span class="w">  </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="nb">INT</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="nb">INT</span><span class="p">)</span>
<a id="__codelineno-135-5" name="__codelineno-135-5" href="#__codelineno-135-5"></a><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">ROW</span><span class="w"> </span><span class="n">FILTER</span><span class="w"> </span><span class="n">row_filter</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="p">();</span>
<a id="__codelineno-135-6" name="__codelineno-135-6" href="#__codelineno-135-6"></a>
<a id="__codelineno-135-7" name="__codelineno-135-7" href="#__codelineno-135-7"></a><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">data_table</span><span class="w"> </span><span class="k">VALUES</span>
<a id="__codelineno-135-8" name="__codelineno-135-8" href="#__codelineno-135-8"></a><span class="w">  </span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">),</span>
<a id="__codelineno-135-9" name="__codelineno-135-9" href="#__codelineno-135-9"></a><span class="w">  </span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">),</span>
<a id="__codelineno-135-10" name="__codelineno-135-10" href="#__codelineno-135-10"></a><span class="w">  </span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">);</span>
</code></pre></div>
<h3 id="performance-considerations">Performance Considerations</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/1aa032e5-8f19-4d52-883f-f3539bc53846" /></p>
<h3 id="auditing-data">Auditing Data</h3>
<h4 id="table-level-data">Table Level Data</h4>
<p>What was the last updated time?
<img alt="image" src="https://github.com/user-attachments/assets/81e240df-e74f-4cc2-a294-31cff01aa0ea" /></p>
<h4 id="user-level-data">User Level Data</h4>
<p>Who used which tables?
<img alt="image" src="https://github.com/user-attachments/assets/bc14a1bd-896a-44ef-a5d8-1f8047721acf" /></p>
<h4 id="lineage-data">Lineage Data</h4>
<p>What is the lineage of the tables?
<img alt="image" src="https://github.com/user-attachments/assets/9514444a-47d4-4671-955f-f2422fc43277" /></p>
<h4 id="data-isolation">Data Isolation</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/b6d37361-dd6e-49e5-9f92-e4ad3b6d9bfe" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ca5ce0d4-b9c0-4321-a8ab-d6a8c67f90ed" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/18c1dbbe-b351-4874-aaca-ed1d3625aec9" /></p>
<h4 id="centralized-and-distributed-metastore-models">Centralized and Distributed Metastore Models</h4>
<p><strong>Centralized</strong></p>
<p>The metastore owners govern all the objects.
<img alt="image" src="https://github.com/user-attachments/assets/030a303e-f33e-4610-859d-da54e6febdd6" /></p>
<p><strong>Distributed</strong></p>
<p>The governance is at the catalog level.</p>
<h3 id="external-locations-and-storage-credentials_2">External Locations and Storage Credentials</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/f20d648b-1d31-4a7e-8f71-2611daaa27da" /></p>
<h3 id="unity-catalog-model-to-access-data">Unity Catalog Model to Access data</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/df8afbbd-b936-4afc-90c8-6e8e551562f0" /></p>
<ul>
<li>The data comes from the cloud storage to the user, not from the table. Unity catalog only checks the permissions and audit log.</li>
</ul>
<h3 id="encryption-by-default">Encryption by Default</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/5c50d189-1bff-430c-a725-8b870dc0d8c2" /></p>
<h3 id="managing-access-to-pii">Managing Access to PII</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/9f10da3b-f2bd-44a3-b70d-159181c54e26" /></p>
<h3 id="best-practices">Best Practices</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/3b2eb9be-233a-4e51-b0f6-efb0e930b5d8" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/2c6a4fc6-51cb-4495-a43a-52499aa40c1e" /></p>
<h3 id="demo">Demo</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/263f67f0-0dfd-491f-9d90-f051a10ef6fb" /></p>
<h4 id="protecting-columns-and-rows">Protecting Columns and Rows</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/62f6f009-ddc0-4056-babf-3cb81fa61906" /></p>
<h4 id="dynamic-views_2">Dynamic Views</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/c6f970da-65e0-4a8a-b9db-8a27189970b8" /></p>
<h4 id="example">Example</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/4c98f1bc-c2d4-4b4f-9f81-b017da46adfa" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a15ecb9f-61ca-46f2-8879-061bce5f47ed" /></p>
<h4 id="row-filters-and-column-mask">Row filters and Column Mask</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/5c6256a8-4415-4832-9f35-75056a6e3775" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/54a04825-efda-46d9-ab5b-5363c2ed31c5" /></p>
<p><strong>Applying the filter</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/70bee76e-16de-4638-a543-c64121bda8d3" /></p>
<p><strong>Creating Column Mask</strong></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/441284a7-d308-4a01-8f9a-8007b52a78e1" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/b1784190-14b6-4b7a-b420-126a5dfcd487" /></p>
<p><strong>Table Tags</strong>
<img alt="image" src="https://github.com/user-attachments/assets/cb106ba9-40d4-4b8a-a9e8-7b096418fc92" /></p>
<h3 id="pii-data-security">PII Data security</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/e3eb60ce-1f49-4bbd-9c25-3b3261114a06" /></p>
<h4 id="pseudonymization">Pseudonymization</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/d1686fb8-2c05-44db-9b38-d97ec1cf5188" /></p>
<h5 id="hashing">Hashing</h5>
<p><img alt="image" src="https://github.com/user-attachments/assets/e11e3829-c2b2-4eeb-91d5-59773eb08bf0" /></p>
<h5 id="tokenization">Tokenization</h5>
<p><img alt="image" src="https://github.com/user-attachments/assets/aacc1dca-6278-42a7-97ac-1a7e69eae745" /></p>
<h4 id="anonymization">Anonymization</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/bb0e0707-e787-4a72-b6c8-b1cb2564cfaf" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/8fcfa59d-6b5e-4f94-83d3-a63a0d1e3a95" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/07e3288b-e548-47e7-8d9b-909001f179e0" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/2054c309-964a-411b-93c0-46b6c94c2067" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/de10d8e8-c0ab-44ed-b55c-89985dfa2d48" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/d07338eb-650d-4100-a6a3-5968ec4b13f0" /></p>
<h3 id="pii-data-security-demo">PII Data Security : Demo</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/8d770564-597d-47e8-9edd-941f5ccc2b52" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/683c5b83-f065-4dd2-b7a2-9cc036065c05" /></p>
<p>Two methods hashing and tokenization.</p>
<h4 id="hashing_1">Hashing</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/c363833d-d5c9-4f11-aea6-57052f393967" /></p>
<p>Create a dlt table
<img alt="image" src="https://github.com/user-attachments/assets/ff1eb5c3-bd53-4359-99e6-74bd88c6a627" /></p>
<p>Create a salt and hash
<img alt="image" src="https://github.com/user-attachments/assets/0f769c0b-19e2-4757-8674-d5715ec87b5e" /></p>
<p>Create user lookup table with alt id generated from above.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/cb5532bc-f1a7-4d21-8c5b-e4d83ef51fe6" /></p>
<p>Now check user_id_hashed table</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/2703663f-02d3-42b0-a099-3031450be8b4" /></p>
<h4 id="tokenization_1">Tokenization</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/6ed1200d-ab1c-48a4-ace3-b02c4cdbf0c1" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/e59ee9f8-85a5-47c6-9b7d-c17ab1766906" /></p>
<p>Create a join with real and pseudo lookup table.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1cccb1d9-385e-4e62-bf26-cf9aebdbf422" /></p>
<p>The lookup table
<img alt="image" src="https://github.com/user-attachments/assets/35a1c0c0-45cf-45b9-9dfe-fd55e271115d" /></p>
<p>The tokennized joined table
<img alt="image" src="https://github.com/user-attachments/assets/dc976954-17a5-4476-bc92-6c4e364705f9" /></p>
<h4 id="anonymization_1">Anonymization</h4>
<p>Irreversible </p>
<p><img alt="image" src="https://github.com/user-attachments/assets/22997ad6-5dce-47ee-bf07-81e70002f113" /></p>
<p>Setting up tables</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/e1404394-b31f-4ad2-9d6f-687353a0fe84" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/47c63253-d576-48ce-b651-3d976c63250a" /></p>
<h4 id="schema-for-users-bronze-table">Schema for users bronze table</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/8baf8aba-aede-4df2-96e3-d9d6ba0413aa" /></p>
<p>Age bins function</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1055dff2-ac20-4962-b0b0-46644c79bd09" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ddea3155-a97a-4d7a-8b37-673f4e171c62" /></p>
<h3 id="change-data-feed">Change Data Feed</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/5b476a51-ce25-4ea1-9640-9591e00e7217" /></p>
<h4 id="solution-i-ignore-deletes-and-updates">Solution I : Ignore deletes and updates</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/8eca1d9c-0dc7-4308-bec1-53cf558dae19" /></p>
<h4 id="benefits-of-change-data-feed">Benefits of Change Data Feed</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/6ede58fd-cb8b-4055-92e3-11cac49f9d28" /></p>
<h4 id="cdc-vs-cdf">CDC vs CDF</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/cbeabc31-0509-441f-a1e4-c99fcc39de71" /></p>
<h4 id="how-cdf-works">How CDF works?</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/d96a48d9-4d7a-42a8-87ee-5f2a2e05ecc5" /></p>
<h4 id="consuming-delta-cdf">Consuming Delta CDF</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/c230ae8c-e6b7-41ce-9fef-2b0860a86228" /></p>
<p>If multiple updates come in one micro batch we need to select 1 of them.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/8df258aa-56f8-4316-88e4-54e60f4b802e" /></p>
<h4 id="how-to-collect-changes">How to collect changes?</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/d3464e27-80c2-4b67-8c13-acc5ea450e9c" /></p>
<h3 id="deleting-pii-data">Deleting PII data</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/710cebd9-30e4-4ea2-93be-b29b37b767e9" /></p>
<h4 id="data-vacuuming">Data Vacuuming</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/3b82b950-a44e-46db-9df5-678f2b7debc3" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/75574df8-fb68-4f6b-9ee9-edf4d20d473c" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/06b3ba80-03bc-4c93-bec3-27712325d9f1" /></p>
<p>Materialized views cannot be used for DML ops, we need to REFRESH manually</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/abcced24-8205-4f83-811d-733ecd926fe0" /></p>
<h3 id="cdf-demo">CDF Demo</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/63cea16e-db43-4b9f-86ea-b9258e329ce0" /></p>
<p>Step 1 : Create stream from source</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/f67b83a7-53c3-4866-855b-73932f78bf73" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1a36268b-c0c3-4464-951d-bc4be78aaa9f" /></p>
<p>Step 2 : Create silver and upsert_to_delta function</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/745e89bb-5864-4566-a245-f7f68323a79d" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/7ad38ea2-230f-4252-8ea1-0aa1c7c98172" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/96a281ec-2ea4-4f03-86cf-b4daa7454ef6" /></p>
<p>Step 3 : Initiate the stream and check history</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/f18150d2-faea-4019-9815-9463314235d5" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/d20e3b22-e61d-4faf-bc54-5a161e71abff" /></p>
<p>We will have two images for any updates
<img alt="image" src="https://github.com/user-attachments/assets/6b6b7c05-8cad-4d10-bc0b-bd6591a0bf75" /></p>
<p>Step 4 : Insert New data</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/2bf361d0-408d-42ee-a293-3aba7f0b69ed" /></p>
<p>Step 5 : Check what is changed</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/dbf81f81-b893-4a2a-aaa1-f0b96082a118" /></p>
<p>We can get operational metrics also</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/319fe9ce-3213-42ca-9e21-a40167531dac" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a2871164-b988-4184-a674-775cbdedb537" /></p>
<p>Check all rows that were updated</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/e9f2d4c6-ab55-4b71-bd70-46d774e7794f" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ef66e6ad-7906-4592-8553-4857df330b9d" /></p>
<p>Adding commit messages in history</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/7a25c178-f99d-4599-a322-e820d2fbac12" /></p>
<p>Create a table called delete_requests</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/3f3d8058-c8fc-4ec2-8df6-3df673a76c0a" /></p>
<p>How to process delete requests?</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/04bc5b7f-17c9-4a46-8d95-d31c32c4da84" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/7db97a05-4814-4783-8d3a-ebb769f95e30" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/2fb73671-71a1-474a-9258-663bcc6d1440" /></p>
<p>Collect Deleted silver users to process with CDF</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/fd0ef6ce-8554-4917-8804-173e10617079" /></p>
<p>Propogate deletes to gold tables</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/d9b58a0e-966e-4254-8ecc-daa9a8ce6160" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/94fc9f47-7566-4627-9209-494c872b1269" /></p>
<p>Are deletes fully commited?</p>
<p>No, we can see them in previous versions of the data.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/cd48eb47-d44a-4c00-b442-accd3b64d867" /></p>
<h2 id="performance-optimization-in-databricks">Performance Optimization in Databricks</h2>
<p>Some common problems</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ab027890-e70a-4c8f-b1ef-0f14426c5943" /></p>
<p>Avoiding small files problem</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/530b1b7b-df5e-4d42-8948-3d622167d705" /></p>
<h3 id="demo-file-explosion">Demo : File Explosion</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/9bac5ef3-ce31-4764-92cf-0b2d274efb06" /></p>
<p>Partitioning by Id</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ace2cd16-1152-484e-9412-31b117d637c1" /></p>
<p>Now we do some aggregation on non partitioned columns. It takes 7 seconds to compute.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/49dfd811-7c49-447e-a31d-152520442f7e" /></p>
<p>Because we partitioned by Id the query is looking into 2500 files</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/04f62386-fd3b-4dcd-b31e-4c74b082c3da" /></p>
<p>Instead if we dont add partitioning then the reads are much faster.</p>
<h3 id="data-skipping">Data Skipping</h3>
<h4 id="z-ordering">Z-Ordering</h4>
<p>We have stored data in min and max column basis.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/c5ad3219-06e5-47cf-ac4e-9e775512ad5d" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/8cef39dd-dbed-4bff-9597-2b1f4d99cc4f" /></p>
<h4 id="some-considerations">Some Considerations</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/a3344680-0d51-4e29-933f-31a259f26795" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/44ea568f-0d75-4cd6-957b-2237bf973fb5" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/5a24c2c4-b21f-48f4-8094-d850ba3c0e31" /></p>
<h4 id="liquid-clustering">Liquid Clustering</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/26a57521-5120-4109-9de5-094401d06e35" /></p>
<p>🧱 <strong>Partitioning</strong>
Partitioning physically organizes data into separate folders on storage based on the values of one or more columns. For example, partitioning a sales table by region and year results in directories like /region=US/year=2024/. This allows partition pruning: when queries filter on those columns, Databricks reads only relevant partitions, improving performance.</p>
<p>Partitioning works best when:</p>
<ul>
<li>
<p>You have low-cardinality columns (few unique values).</p>
</li>
<li>
<p>You know the access patterns ahead of time.</p>
</li>
<li>
<p>You want predictable file organization.</p>
</li>
</ul>
<p>However, partitioning becomes problematic with high-cardinality columns (e.g., user_id or product_id) because it creates too many folders. This is called partition explosion, which leads to small files, slow queries, and high metadata overhead.</p>
<p>🌊 <strong>Liquid Clustering</strong>
Liquid Clustering is a newer, automatic file organization technique that clusters data logically, not physically. Instead of creating folders, it reorganizes data within Delta files based on specified columns (like user_id, timestamp). It improves filtering performance without the downsides of static partitioning.</p>
<ul>
<li>
<p>It works incrementally—Databricks automatically reclusters the data in the background using OPTIMIZE jobs. This makes it ideal for:</p>
</li>
<li>
<p>High-cardinality columns.</p>
</li>
<li>
<p>Streaming or frequently updated datasets.</p>
</li>
<li>
<p>Situations where partitioning would be too rigid or hard to manage.</p>
</li>
</ul>
<p>With Liquid Clustering, you just define the clustering columns using table properties, and Databricks takes care of the rest. It’s flexible, scalable, and low-maintenance.</p>
<p>If we want to change liquid clustering columns, we dont need to rewrite whole table.</p>
<p>Liquid clustering intelligently makes sure the files are of same size.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/ff77944e-8802-4d4e-aecb-96984714139d" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a3ed0d5b-f98f-488a-aa99-5d75a43e6128" /></p>
<h3 id="predictive-optimization">Predictive Optimization</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/e8f50298-f3e6-44c5-ada9-b2b1c229517c" /></p>
<h3 id="code-optimizations">Code Optimizations</h3>
<h4 id="data-skew">Data Skew</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/80fba07d-d6ab-44fd-99fd-fdd730afb451" /></p>
<p>Salting approach by adding some suffix to each key</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/58c34045-1691-4921-a970-2b45b84d65dc" /></p>
<h4 id="data-shuffling">Data Shuffling</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/216049d2-6c0e-4b5a-b03d-fb1ef49900ad" /></p>
<p>Mitigate Shuffling</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/5d475878-5192-42db-879a-2ccea870a2cf" /></p>
<h3 id="demo-of-shuffling">Demo of Shuffling</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/69218692-d222-4fb1-b449-6564760385cd" /></p>
<p>This data shows the shuffling of data, we can see that around 1.5 G of shuffling happenend.
<img alt="image" src="https://github.com/user-attachments/assets/3100b6d3-0dd5-4874-b058-4e7f5aa02744" /></p>
<h4 id="broadcast-join">Broadcast Join</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/907c03a6-4c8b-4f6f-99a3-40eaf15c94fb" /></p>
<p>After enabling broadcast join there are only few Kb worth of shuffling
<img alt="image" src="https://github.com/user-attachments/assets/c5dd8fd4-7363-4c8e-85a2-16fdbe9f8aac" /></p>
<h3 id="spill">Spill</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/a38e5bf1-a223-49f0-8522-e3e72b3d3c8b" /></p>
<p>When does skew occur</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/cf4757a7-901b-41fe-9086-a93ee8eeebb5" /></p>
<p>Spilling to memory and disk</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/d569c1c0-b917-4c18-9413-996d083df408" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/93084d07-2943-4b2b-bef2-e2139cc84979" /></p>
<h4 id="mitigating-serialization-issues">Mitigating Serialization Issues</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/84c86f53-21b0-4e4f-a6d0-65d27d2fbaff" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/850455a3-da3c-4412-87dc-a2d97749c306" /></p>
<h4 id="demo-udf">Demo : UDF</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/9d88fc47-0985-40bb-84a3-4b26c25da1c1" /></p>
<p>For 60 records it takes one minute because the data is not being run on diff cores, its being run one after another.</p>
<p>Solution: We repartition the data</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/303bebf8-250a-495c-be5f-246c36bdc3d2" /></p>
<h4 id="how-sql-udf-is-better">How SQL UDF is better?</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/24b8b526-5c82-48c5-bfce-90c8d2de3bd9" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/5892e02a-dd60-4aef-a4e2-98a0756c90c4" /></p>
<p>Query is supported by Photon
<img alt="image" src="https://github.com/user-attachments/assets/c175a88d-4be8-4ea3-a8e3-ce6663abc40b" /></p>
<h3 id="cluster-optimization">Cluster Optimization</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/4484eb70-c258-4f59-bf9e-dffdd3643b1e" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/1e68a793-9501-43d8-b239-1e10e72a4afd" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/c1f164fd-b5e1-4231-9933-5013753302cc" /></p>
<h4 id="photon_1">Photon</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/0e34471f-e119-4281-9e38-c588506ee4fd" /></p>
<h4 id="cluster-optimization-techniques">Cluster Optimization Techniques</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/7558639d-b779-4ab8-af77-9d66677dbc03" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/17b4eeeb-c877-4871-b06a-b45fd9a0960c" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/a377a5fd-a854-4084-a4e7-f9043fec1659" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/f5393b71-c294-4fcc-b661-14c5539b20f7" /></p>
<p>🎈 Imagine you're at a birthday party...</p>
<p>There are 200 kids playing a game where they all have to sort their candies by color. But there’s a rule:
All the red candies go to one basket, all the green to another, and so on.</p>
<p>Now, to do this, the kids need to share and move candies around — this is like a shuffle in Spark. It’s when data (candies) gets moved around to be grouped or sorted.</p>
<p>🧺 Now, what is spark.sql.shuffle.partitions?</p>
<p>It’s like saying:</p>
<p>“How many baskets should we use to sort all the candies?”</p>
<p>So if we set:</p>
<p>spark.sql.shuffle.partitions = 200 → Spark uses 200 baskets</p>
<p>spark.sql.shuffle.partitions = 50 → Uses 50 baskets</p>
<p>🎨 Why it matters:</p>
<p>Too many baskets (e.g. 1000): Some baskets might only get 1 candy, but the kids still have to carry them — too much work!</p>
<p>Too few baskets (e.g. 5): Baskets get too full, hard to carry — some kids may drop candies 😬</p>
<p>So we need a good number of baskets so all the kids can sort fast, without making a mess!</p>
<p>🧠 What Spark does:</p>
<p>When Spark runs a big job (like sorting, grouping, or joining), it shuffles data. Then it needs to know:</p>
<p>“Into how many parts (baskets) should I split the shuffled data?”</p>
<p>That’s what spark.sql.shuffle.partitions controls.</p>
<p>🧁 In short:</p>
<p>It's like how many baskets Spark uses to sort data after mixing it.</p>
<p>Default is 200 baskets.</p>
<p>If your job is small → use fewer baskets.</p>
<p>If your job is huge → maybe more baskets help.</p>
<p>Or better yet, let Spark decide by itself using Adaptive Query Execution — like having a smart friend who picks the perfect number of baskets for each game 🎯</p>
<h3 id="databricks-ci-cd">Databricks CI / CD</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/82563c16-8480-4c2b-90bd-f2c1874b0bd0" /></p>
<h4 id="databricks-asset-bundles">Databricks Asset Bundles</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/5d78774b-c68a-4e2a-9a25-b21a2e9f8242" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/915a2a8f-6731-4811-a17a-4133370ec03f" /></p>
<h4 id="typical-ci-cd-overview">Typical CI CD Overview</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/133e07e0-7044-4dda-8adc-621b35d7b049" /></p>
<h4 id="how-are-dabs-structured">How are DAB's structured?</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/4ae022d9-460f-4b9f-976d-4274557599d9" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/8ec783b4-6b26-4b2b-9787-61d81750624f" /></p>
<h4 id="keys-in-the-mapping-yaml-file">Keys in the Mapping yaml file</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/6153b152-1e29-49f3-b1f6-7aa446cffa6e" /></p>
<p><code>target</code> keys</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/968e5712-a4e2-444f-9bcb-7473911eeaed" /></p>
<h4 id="steps-to-deploy">Steps to Deploy</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/d17bd19a-c192-47a9-bfdf-f8e3a09cc0d5" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/c1489a87-5438-4ab2-b1bb-eb92223df621" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/30c07bb2-eee3-4ae2-a384-a2946668dab9" /></p>
<h4 id="variables-in-dabs">Variables in DABs</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/7d41aa8f-c64d-44e1-bb4e-3c0ec9f59709" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/9e1f7324-323d-4ade-b021-42fb7f6e9683" /></p>
<p>Lookup Variables</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/25ef969a-e14c-4d6f-bcba-4cfa11fd5122" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/fb728ade-dd3a-4b52-9abc-d13bf9373489" /></p>
<p>By default the DAB deployed jobs will have this name in dev</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/f3b5772f-af73-4d1d-98b9-ecdd52001fd3" /></p>
<h4 id="defining-the-dab">Defining the DAB</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/484a232f-887f-40be-86a3-3ea8ce424f86" /></p>
<h4 id="running-the-job-from-the-dab">Running the job from the DAB</h4>
<p><code>databricks bundle run -t development demo01_simple_dab</code></p>
<h4 id="destryoing-the-bundle">Destryoing the Bundle</h4>
<p><code>databricks bundle destory --auto-approve</code></p>
<h4 id="modularizing-the-code">Modularizing the code</h4>
<ul>
<li>In the resources folder we can keep the config for the jobs and use it as an include in <code>databricks.yml</code></li>
</ul>
<p><img alt="image" src="https://github.com/user-attachments/assets/691c66ab-5be4-4048-ae84-776e2e209bbd" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/e583e70a-fdd1-4e9d-ae03-cc72c4a8a929" /></p>
<p>Using lookup variable for cluster</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-136-1" name="__codelineno-136-1" href="#__codelineno-136-1"></a>    my-cluster-id:
<a id="__codelineno-136-2" name="__codelineno-136-2" href="#__codelineno-136-2"></a>        description: Get lab user id using lookup variable
<a id="__codelineno-136-3" name="__codelineno-136-3" href="#__codelineno-136-3"></a>        lookup:
<a id="__codelineno-136-4" name="__codelineno-136-4" href="#__codelineno-136-4"></a>            cluster: Rajeeva
</code></pre></div>
The above code will fetch the cluster_id automatically</p>
<p>Now remember we have defined our job yml in the resources folder, we are going to add existing_cluster_id (override) it using our lookup variable</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/8452100e-0f68-4bc8-bf92-2c22da6f9c3a" /></p>
<p>For production we want to use serverless so we dont override.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/6b1ebcc5-8c34-4579-8a33-f3e6e3674154" /></p>
<p>How to check json version?</p>
<p><code>databricks bundle validate --output json</code></p>
<p>Each environment will have separate folder in <code>.bundle</code> folder.</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/3686eaf7-05dc-4921-857a-eca55d5cae70" /></p>
<h3 id="dab-project-templates">DAB Project Templates</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/9854fe15-d1a3-4e83-9c0e-cbdc85ff64ac" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/4dbb35fc-ddeb-42b1-8500-01bcf6ba9467" /></p>
<h3 id="ci-cd-with-databricks-asset-bundles">CI CD with Databricks Asset Bundles</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/2dfc77e4-3e91-43d9-9c3c-a3f5f4beef96" /></p>
<h3 id="expectations-for-integration-tests">Expectations for Integration Tests</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/be381db3-a728-4ad5-ae04-5e19e2ba4369" /></p>
<h3 id="demo-full-project-with-dab">Demo : Full Project with DAB</h3>
<p><img alt="image" src="https://github.com/user-attachments/assets/e3f94f54-6f34-4bd8-ab4d-2561c49c328c" /></p>
<p>Project Architecture</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/4c71f5ff-5a6a-4081-8bb9-7911a2c54076" /></p>
<p>Folder Structure</p>
<p>Top Level structure</p>
<p><img alt="image" src="https://github.com/user-attachments/assets/03b4131f-d1d1-412e-914c-e8dc7fcc28a6" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/99986a4f-8259-4347-a8b8-9d220d1db702" /></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/7e0db6f0-5812-450e-b53b-ef98d6973ee2" /></p>
<p><code>variables.yaml</code></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/42ec2d25-0d1a-4d93-911d-52344a9ea9d2" /></p>
<p><code>workflow_job.yaml</code></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/de29e1bf-fe4a-49d2-b2f1-7e1f5c013ecd" /></p>
<p><code>health_etl_pipeline.yml</code></p>
<p><img alt="image" src="https://github.com/user-attachments/assets/51540fde-9a83-4301-b444-690727ad9563" /></p>
<h4 id="deployment-with-github-actions">Deployment with GitHub Actions</h4>
<p><img alt="image" src="https://github.com/user-attachments/assets/e490fb6f-cec0-4348-b289-a052c7e2267b" /></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2023 <a href="https://github.com/rajeevapoornachandrahs"  target="_blank" rel="noopener">rajeevapoornachandrahs</a>

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>
